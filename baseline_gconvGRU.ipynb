{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = np.load('datasets/oasis_data.npy')\n",
    "# dataset = torch.from_numpy(dataset).squeeze()\n",
    "# dataset = dataset.type(torch.FloatTensor)\n",
    "# dataset = np.delete(dataset,88,axis=0)\n",
    "\n",
    "dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=5, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help=\"Learninng rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/real_and_predicted_graphs' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/train_losses/mae_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/train_losses/reservoir_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/train_losses/bio_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/train_losses/tp_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/train_losses/total_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/test_mae_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/test_tp_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/test_memcap_losses' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/test_predicted' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/test_original' was created.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_oasis/trained_models' was created.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.033068847755203024, TP Loss: 1.352059509884566\n",
      "[Validate] MAE Loss Across Timepoints: [0.03423421 0.0355597 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.82703409 1.10710392]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06322118 1.11018118]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.024494266504189, TP Loss: 0.6195840244647115\n",
      "[Validate] MAE Loss Across Timepoints: [0.03337488 0.03450525]\n",
      "[Validate] TP Loss Across Timepoints: [0.75867491 0.96995907]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04347421 1.09638035]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023662832070840523, TP Loss: 0.5931328468956053\n",
      "[Validate] MAE Loss Across Timepoints: [0.03298601 0.03409452]\n",
      "[Validate] TP Loss Across Timepoints: [0.73872356 0.94422188]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03309759 1.11182071]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02316112394910306, TP Loss: 0.5789857522118836\n",
      "[Validate] MAE Loss Across Timepoints: [0.03275496 0.03381957]\n",
      "[Validate] TP Loss Across Timepoints: [0.72567859 0.93403358]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03792534 1.14226867]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02291103880852461, TP Loss: 0.5705859552603215\n",
      "[Validate] MAE Loss Across Timepoints: [0.03262671 0.03371329]\n",
      "[Validate] TP Loss Across Timepoints: [0.71773181 0.92341518]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05234695 1.12248765]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022667166095925496, TP Loss: 0.5610354288481176\n",
      "[Validate] MAE Loss Across Timepoints: [0.03252531 0.03355535]\n",
      "[Validate] TP Loss Across Timepoints: [0.70925798 0.90255022]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03873348 1.11651505]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.022564436501124874, TP Loss: 0.560013725515455\n",
      "[Validate] MAE Loss Across Timepoints: [0.03242897 0.0334875 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.70515881 0.90431356]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99533308 1.08871391]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022431104158749805, TP Loss: 0.5557600619737059\n",
      "[Validate] MAE Loss Across Timepoints: [0.03240692 0.03335624]\n",
      "[Validate] TP Loss Across Timepoints: [0.70180969 0.87250509]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97314842 1.07806001]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02234596495400183, TP Loss: 0.550658403383568\n",
      "[Validate] MAE Loss Across Timepoints: [0.03230459 0.03325529]\n",
      "[Validate] TP Loss Across Timepoints: [0.69837337 0.87488298]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97503281 1.07557564]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022256205609301104, TP Loss: 0.5484545706771314\n",
      "[Validate] MAE Loss Across Timepoints: [0.03225695 0.03331928]\n",
      "[Validate] TP Loss Across Timepoints: [0.6963388  0.88401661]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97119164 1.05805497]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02215904339682311, TP Loss: 0.5435428052209318\n",
      "[Validate] MAE Loss Across Timepoints: [0.03220325 0.03311056]\n",
      "[Validate] TP Loss Across Timepoints: [0.69347906 0.86589108]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97302835 1.06191545]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02209969795658253, TP Loss: 0.5412093551363796\n",
      "[Validate] MAE Loss Across Timepoints: [0.03217117 0.0330664 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.69119296 0.86037331]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.955389   1.05326017]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022026114171603696, TP Loss: 0.5353653777390719\n",
      "[Validate] MAE Loss Across Timepoints: [0.03211278 0.03294081]\n",
      "[Validate] TP Loss Across Timepoints: [0.68906102 0.84852581]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92999918 1.03357646]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.021970905439229683, TP Loss: 0.5350814224220812\n",
      "[Validate] MAE Loss Across Timepoints: [0.03209864 0.03292862]\n",
      "[Validate] TP Loss Across Timepoints: [0.68744235 0.84537401]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93765128 1.02266849]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02190626360825263, TP Loss: 0.5293317552655935\n",
      "[Validate] MAE Loss Across Timepoints: [0.03206804 0.03287452]\n",
      "[Validate] TP Loss Across Timepoints: [0.68592463 0.84449282]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93386071 1.03320458]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.021923986467299983, TP Loss: 0.5322553024161607\n",
      "[Validate] MAE Loss Across Timepoints: [0.03203358 0.03275469]\n",
      "[Validate] TP Loss Across Timepoints: [0.68410349 0.83178034]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93493087 1.03514375]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021808412997052072, TP Loss: 0.5224090658593923\n",
      "[Validate] MAE Loss Across Timepoints: [0.03202322 0.0327263 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.68313141 0.82667303]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94491204 1.02984965]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021786946232896297, TP Loss: 0.5261262140702456\n",
      "[Validate] MAE Loss Across Timepoints: [0.03198535 0.03263805]\n",
      "[Validate] TP Loss Across Timepoints: [0.68132234 0.82156973]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95531616 1.04385614]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02176290732459165, TP Loss: 0.5237474068067968\n",
      "[Validate] MAE Loss Across Timepoints: [0.03192652 0.03261687]\n",
      "[Validate] TP Loss Across Timepoints: [0.67832599 0.82367907]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96056193 1.03084088]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02173417349695228, TP Loss: 0.5223311838693917\n",
      "[Validate] MAE Loss Across Timepoints: [0.03192453 0.03259814]\n",
      "[Validate] TP Loss Across Timepoints: [0.67755609 0.81648703]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96002315 1.03961129]\n",
      "\n",
      "epochs finished with time:1091.5966482162476\n",
      "\n",
      "Current memory usage: 3432.67 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03208271 0.03236139]\n",
      "[Test] TP Loss Across Timepoints: [0.80470795 0.75410568]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.95628863 0.9913248 ]\n",
      "------------------------------------Fold [2/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03177589186816476, TP Loss: 1.1642694987356663\n",
      "[Validate] MAE Loss Across Timepoints: [0.03439729 0.03608004]\n",
      "[Validate] TP Loss Across Timepoints: [0.87072296 1.12602854]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.10962411 1.12785626]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.024383327504619957, TP Loss: 0.6296904547140002\n",
      "[Validate] MAE Loss Across Timepoints: [0.03344922 0.03478245]\n",
      "[Validate] TP Loss Across Timepoints: [0.79081864 0.98158627]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02911873 1.08759799]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023540541651891546, TP Loss: 0.604747825441882\n",
      "[Validate] MAE Loss Across Timepoints: [0.03309983 0.03444624]\n",
      "[Validate] TP Loss Across Timepoints: [0.76730399 0.96271973]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99089302 1.08856036]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.023163128935266286, TP Loss: 0.5895518498495221\n",
      "[Validate] MAE Loss Across Timepoints: [0.03286096 0.0340557 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.74333329 0.92325354]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99891497 1.09200797]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02285469716298394, TP Loss: 0.5789031866937876\n",
      "[Validate] MAE Loss Across Timepoints: [0.0327316  0.03396305]\n",
      "[Validate] TP Loss Across Timepoints: [0.73585811 0.92281704]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02153114 1.09917573]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022658894356573, TP Loss: 0.5695534993894398\n",
      "[Validate] MAE Loss Across Timepoints: [0.03265008 0.03397185]\n",
      "[Validate] TP Loss Across Timepoints: [0.73324218 0.92893496]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06502756 1.11197194]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02251946771866642, TP Loss: 0.5674663166049868\n",
      "[Validate] MAE Loss Across Timepoints: [0.03254411 0.03369279]\n",
      "[Validate] TP Loss Across Timepoints: [0.72446408 0.8987958 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04122332 1.09786686]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022429499571444467, TP Loss: 0.5643553871195763\n",
      "[Validate] MAE Loss Across Timepoints: [0.03247616 0.03368545]\n",
      "[Validate] TP Loss Across Timepoints: [0.72364893 0.90494576]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00064018 1.08063499]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02232227082713507, TP Loss: 0.5583438684232533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03235593 0.03339263]\n",
      "[Validate] TP Loss Across Timepoints: [0.71147099 0.86399841]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97791238 1.06872068]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022247341863112523, TP Loss: 0.5568135394714773\n",
      "[Validate] MAE Loss Across Timepoints: [0.03231352 0.03335611]\n",
      "[Validate] TP Loss Across Timepoints: [0.71226339 0.86371622]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97570465 1.06125302]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022165256505832075, TP Loss: 0.5507242814637721\n",
      "[Validate] MAE Loss Across Timepoints: [0.03228022 0.03337918]\n",
      "[Validate] TP Loss Across Timepoints: [0.71343651 0.87023544]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96523505 1.04914367]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022103034902829676, TP Loss: 0.5497219605371356\n",
      "[Validate] MAE Loss Across Timepoints: [0.03221599 0.0332196 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.70823421 0.85172739]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97665102 1.04998351]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022017376677831636, TP Loss: 0.5448048220016062\n",
      "[Validate] MAE Loss Across Timepoints: [0.03216555 0.03308042]\n",
      "[Validate] TP Loss Across Timepoints: [0.70543442 0.84082479]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97714363 1.04298841]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.021966770937433468, TP Loss: 0.5417586280032992\n",
      "[Validate] MAE Loss Across Timepoints: [0.03211505 0.03307279]\n",
      "[Validate] TP Loss Across Timepoints: [0.70377584 0.83902149]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97750347 1.04591691]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02193219161708839, TP Loss: 0.5401720665860921\n",
      "[Validate] MAE Loss Across Timepoints: [0.03209186 0.03300775]\n",
      "[Validate] TP Loss Across Timepoints: [0.70258064 0.82974958]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98445757 1.04619383]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.021879788994556292, TP Loss: 0.5383263489231467\n",
      "[Validate] MAE Loss Across Timepoints: [0.0320601  0.03298402]\n",
      "[Validate] TP Loss Across Timepoints: [0.70054698 0.82809181]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9875664 1.0473741]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02182383500621654, TP Loss: 0.5356299874838442\n",
      "[Validate] MAE Loss Across Timepoints: [0.0320341  0.03291012]\n",
      "[Validate] TP Loss Across Timepoints: [0.69918809 0.82321692]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98822966 1.04197147]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021804551815148444, TP Loss: 0.533005642844364\n",
      "[Validate] MAE Loss Across Timepoints: [0.03198081 0.03279697]\n",
      "[Validate] TP Loss Across Timepoints: [0.69592409 0.80900478]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97157801 1.02664332]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.021765588014386595, TP Loss: 0.531549062859267\n",
      "[Validate] MAE Loss Across Timepoints: [0.03198327 0.03286866]\n",
      "[Validate] TP Loss Across Timepoints: [0.69811549 0.8197773 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97934356 1.0411327 ]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02174080439726822, TP Loss: 0.5303353310562671\n",
      "[Validate] MAE Loss Across Timepoints: [0.0319425 0.0327161]\n",
      "[Validate] TP Loss Across Timepoints: [0.69406548 0.7968904 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98384345 1.0407544 ]\n",
      "\n",
      "epochs finished with time:1100.2780542373657\n",
      "\n",
      "Current memory usage: 3399.82 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.0318649  0.03206314]\n",
      "[Test] TP Loss Across Timepoints: [0.72816162 0.74746864]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.97905544 1.04400712]\n",
      "------------------------------------Fold [3/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03362720660516061, TP Loss: 1.3042485556565224\n",
      "[Validate] MAE Loss Across Timepoints: [0.03486931 0.03682368]\n",
      "[Validate] TP Loss Across Timepoints: [0.9095088  1.20690203]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.30985733 1.62310799]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.024333346233470367, TP Loss: 0.6168087958358228\n",
      "[Validate] MAE Loss Across Timepoints: [0.03378322 0.03532486]\n",
      "[Validate] TP Loss Across Timepoints: [0.82739553 1.04793968]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96361048 1.08108732]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023522701632464303, TP Loss: 0.5861675242893398\n",
      "[Validate] MAE Loss Across Timepoints: [0.03339459 0.03497585]\n",
      "[Validate] TP Loss Across Timepoints: [0.80647259 1.02708073]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.91482903 1.08032932]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02308952733874321, TP Loss: 0.5760561329312622\n",
      "[Validate] MAE Loss Across Timepoints: [0.03314176 0.03469485]\n",
      "[Validate] TP Loss Across Timepoints: [0.79189563 1.00960989]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89255711 1.06714434]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.022773689270252362, TP Loss: 0.5606590384617448\n",
      "[Validate] MAE Loss Across Timepoints: [0.03296914 0.03446663]\n",
      "[Validate] TP Loss Across Timepoints: [0.77618933 0.98307858]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.86628476 1.07074898]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022611517389304937, TP Loss: 0.557819802314043\n",
      "[Validate] MAE Loss Across Timepoints: [0.03282814 0.0342525 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.76477461 0.95821705]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89650172 1.0625213 ]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02247503331163898, TP Loss: 0.5508058274164795\n",
      "[Validate] MAE Loss Across Timepoints: [0.03272595 0.03418172]\n",
      "[Validate] TP Loss Across Timepoints: [0.76100798 0.95609579]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94245585 1.05844154]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022356252843746916, TP Loss: 0.55167889399454\n",
      "[Validate] MAE Loss Across Timepoints: [0.03262494 0.03412693]\n",
      "[Validate] TP Loss Across Timepoints: [0.75577192 0.95313807]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00042652 1.08284963]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022254179243464022, TP Loss: 0.5453686226159334\n",
      "[Validate] MAE Loss Across Timepoints: [0.03251264 0.03392773]\n",
      "[Validate] TP Loss Across Timepoints: [0.74636669 0.92886267]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0270451  1.07532848]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022143075015628712, TP Loss: 0.5377569919917733\n",
      "[Validate] MAE Loss Across Timepoints: [0.03242971 0.03387567]\n",
      "[Validate] TP Loss Across Timepoints: [0.74348755 0.92996454]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02557008 1.09014537]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022046421945560724, TP Loss: 0.5345897527877241\n",
      "[Validate] MAE Loss Across Timepoints: [0.03238917 0.03380143]\n",
      "[Validate] TP Loss Across Timepoints: [0.742627   0.92623529]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01005167 1.06492032]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02197909221868031, TP Loss: 0.531720881536603\n",
      "[Validate] MAE Loss Across Timepoints: [0.0323105  0.03369787]\n",
      "[Validate] TP Loss Across Timepoints: [0.73611441 0.90880718]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98896673 1.06185909]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02191146324039437, TP Loss: 0.5308921915479005\n",
      "[Validate] MAE Loss Across Timepoints: [0.03227111 0.03367972]\n",
      "[Validate] TP Loss Across Timepoints: [0.73524742 0.91064644]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98467157 1.0500709 ]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.021858793502906336, TP Loss: 0.5252943034283817\n",
      "[Validate] MAE Loss Across Timepoints: [0.03222058 0.03357488]\n",
      "[Validate] TP Loss Across Timepoints: [0.73187547 0.9025032 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97003774 1.05618017]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02180196749395691, TP Loss: 0.5220691836904734\n",
      "[Validate] MAE Loss Across Timepoints: [0.0321769  0.03348963]\n",
      "[Validate] TP Loss Across Timepoints: [0.73015661 0.8939126 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9712813  1.04869584]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02180542834685184, TP Loss: 0.5250706241466105\n",
      "[Validate] MAE Loss Across Timepoints: [0.03216297 0.03350199]\n",
      "[Validate] TP Loss Across Timepoints: [0.73087192 0.90108118]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96314008 1.05485402]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021746351633919404, TP Loss: 0.5225660601630807\n",
      "[Validate] MAE Loss Across Timepoints: [0.03211573 0.03342851]\n",
      "[Validate] TP Loss Across Timepoints: [0.72757912 0.89131804]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97111775 1.05437173]\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.021735618426464497, TP Loss: 0.5219902159180492\n",
      "[Validate] MAE Loss Across Timepoints: [0.03210821 0.0334163 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.72830629 0.89118061]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97411663 1.04526149]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.021669616393046452, TP Loss: 0.5151751734782011\n",
      "[Validate] MAE Loss Across Timepoints: [0.03205425 0.03334386]\n",
      "[Validate] TP Loss Across Timepoints: [0.72342257 0.88291702]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97461804 1.05085199]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02160528547829017, TP Loss: 0.510779916215688\n",
      "[Validate] MAE Loss Across Timepoints: [0.0320008  0.03322378]\n",
      "[Validate] TP Loss Across Timepoints: [0.71918182 0.86807852]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9635036  1.04649531]\n",
      "\n",
      "epochs finished with time:1102.83118724823\n",
      "\n",
      "Current memory usage: 3395.12 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03244604 0.0322082 ]\n",
      "[Test] TP Loss Across Timepoints: [0.79331055 0.78262337]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.96295829 1.00667058]\n",
      "------------------------------------Fold [4/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03517049142392352, TP Loss: 1.5970909798517823\n",
      "[Validate] MAE Loss Across Timepoints: [0.03466359 0.03570548]\n",
      "[Validate] TP Loss Across Timepoints: [0.92663832 1.13635502]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.10706626 1.12857886]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.024536265956703572, TP Loss: 0.6273673783987761\n",
      "[Validate] MAE Loss Across Timepoints: [0.03369503 0.0344838 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.85966301 1.01124048]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04280215 1.10632475]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023660695541184395, TP Loss: 0.6007928504608572\n",
      "[Validate] MAE Loss Across Timepoints: [0.03338212 0.03416137]\n",
      "[Validate] TP Loss Across Timepoints: [0.83861303 0.98391829]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04030498 1.11337063]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.023261014872696252, TP Loss: 0.5905801463406533\n",
      "[Validate] MAE Loss Across Timepoints: [0.03314824 0.03383165]\n",
      "[Validate] TP Loss Across Timepoints: [0.81771374 0.95123873]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0438173  1.13310017]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.022971294802846386, TP Loss: 0.5792743812780827\n",
      "[Validate] MAE Loss Across Timepoints: [0.03301941 0.03371842]\n",
      "[Validate] TP Loss Across Timepoints: [0.80816498 0.94377623]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06421905 1.15272301]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022815222723875195, TP Loss: 0.5758808407001197\n",
      "[Validate] MAE Loss Across Timepoints: [0.03293091 0.03362055]\n",
      "[Validate] TP Loss Across Timepoints: [0.80199394 0.93683138]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04169259 1.14582697]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.022697657468961553, TP Loss: 0.5753990126773715\n",
      "[Validate] MAE Loss Across Timepoints: [0.03284292 0.03359423]\n",
      "[Validate] TP Loss Across Timepoints: [0.80011787 0.94030361]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97915349 1.09286692]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022542377543868498, TP Loss: 0.5654139889869839\n",
      "[Validate] MAE Loss Across Timepoints: [0.032695   0.03328735]\n",
      "[Validate] TP Loss Across Timepoints: [0.78310328 0.89531193]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97873108 1.10971685]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.0224432478134986, TP Loss: 0.5575338622555137\n",
      "[Validate] MAE Loss Across Timepoints: [0.03264033 0.03323049]\n",
      "[Validate] TP Loss Across Timepoints: [0.78219695 0.89226713]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96104593 1.0969728 ]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02232780855265446, TP Loss: 0.5549368421547115\n",
      "[Validate] MAE Loss Across Timepoints: [0.03257276 0.03311028]\n",
      "[Validate] TP Loss Across Timepoints: [0.77744136 0.87826462]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92119848 1.07400652]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022254607977811248, TP Loss: 0.5504456584341824\n",
      "[Validate] MAE Loss Across Timepoints: [0.03254624 0.03309609]\n",
      "[Validate] TP Loss Across Timepoints: [0.77824416 0.88056602]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93845057 1.06924195]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.0221636860165745, TP Loss: 0.5469421493820846\n",
      "[Validate] MAE Loss Across Timepoints: [0.03245689 0.03288437]\n",
      "[Validate] TP Loss Across Timepoints: [0.76852684 0.8537364 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94503262 1.0743711 ]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022137334157014264, TP Loss: 0.5442852783482521\n",
      "[Validate] MAE Loss Across Timepoints: [0.03244272 0.0329112 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.76968412 0.85796747]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95091031 1.06707516]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02207156521617435, TP Loss: 0.5435147379059344\n",
      "[Validate] MAE Loss Across Timepoints: [0.03240536 0.03282296]\n",
      "[Validate] TP Loss Across Timepoints: [0.76789589 0.84972887]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95267712 1.06986463]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.0220060660445597, TP Loss: 0.5366318808402866\n",
      "[Validate] MAE Loss Across Timepoints: [0.03234498 0.0326908 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.76260962 0.83386993]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94564926 1.05140329]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.021970529900863768, TP Loss: 0.5384218201972544\n",
      "[Validate] MAE Loss Across Timepoints: [0.03233671 0.03277967]\n",
      "[Validate] TP Loss Across Timepoints: [0.76550808 0.84665155]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96453967 1.04018227]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02194789100321941, TP Loss: 0.5334743279963732\n",
      "[Validate] MAE Loss Across Timepoints: [0.03230525 0.03273585]\n",
      "[Validate] TP Loss Across Timepoints: [0.76530352 0.84523668]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95949075 1.06016357]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021905762527603657, TP Loss: 0.5338667494244873\n",
      "[Validate] MAE Loss Across Timepoints: [0.0322611  0.03262692]\n",
      "[Validate] TP Loss Across Timepoints: [0.76056991 0.83074722]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94298607 1.05338012]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.021879838884342463, TP Loss: 0.5351414829492569\n",
      "[Validate] MAE Loss Across Timepoints: [0.03224355 0.03261485]\n",
      "[Validate] TP Loss Across Timepoints: [0.75951195 0.82805014]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.966618   1.05522511]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.021805601287633182, TP Loss: 0.5267866416368634\n",
      "[Validate] MAE Loss Across Timepoints: [0.0321688  0.03241486]\n",
      "[Validate] TP Loss Across Timepoints: [0.75074058 0.80382633]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97650824 1.04743981]\n",
      "\n",
      "epochs finished with time:1113.9919810295105\n",
      "\n",
      "Current memory usage: 3391.33 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03123386 0.03311763]\n",
      "[Test] TP Loss Across Timepoints: [0.67548836 0.8418869 ]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.96337506 1.01917661]\n",
      "------------------------------------Fold [5/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.030983670643763617, TP Loss: 1.1244453945197166\n",
      "[Validate] MAE Loss Across Timepoints: [0.03456571 0.0343319 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.86296577 0.95343866]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0593385  1.13133522]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02403135137283243, TP Loss: 0.6027935577090829\n",
      "[Validate] MAE Loss Across Timepoints: [0.03379241 0.03350922]\n",
      "[Validate] TP Loss Across Timepoints: [0.8046916  0.86372051]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96835668 1.09996172]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023296692210715265, TP Loss: 0.5784224533010274\n",
      "[Validate] MAE Loss Across Timepoints: [0.03356359 0.03331559]\n",
      "[Validate] TP Loss Across Timepoints: [0.79097557 0.85040379]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96874003 1.09953887]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02295810392824933, TP Loss: 0.5688053163234145\n",
      "[Validate] MAE Loss Across Timepoints: [0.03344975 0.033236  ]\n",
      "[Validate] TP Loss Across Timepoints: [0.78506083 0.84166803]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00470079 1.11452663]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.022701618185965344, TP Loss: 0.5563161624129862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03334095 0.03315185]\n",
      "[Validate] TP Loss Across Timepoints: [0.7795939 0.8344285]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04241969 1.13145699]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022572169941850007, TP Loss: 0.55834010229446\n",
      "[Validate] MAE Loss Across Timepoints: [0.03324749 0.03307144]\n",
      "[Validate] TP Loss Across Timepoints: [0.77363873 0.82862787]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04944198 1.11493807]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02242442761780694, TP Loss: 0.5509191633667797\n",
      "[Validate] MAE Loss Across Timepoints: [0.03315561 0.03296642]\n",
      "[Validate] TP Loss Across Timepoints: [0.77175007 0.83505478]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02382693 1.11206576]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022306376323103904, TP Loss: 0.5490505740512163\n",
      "[Validate] MAE Loss Across Timepoints: [0.03311713 0.03307849]\n",
      "[Validate] TP Loss Across Timepoints: [0.76785154 0.83129292]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00655287 1.10464143]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022211340442299842, TP Loss: 0.5430822290945798\n",
      "[Validate] MAE Loss Across Timepoints: [0.03302314 0.0328443 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.76418676 0.82124414]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97031967 1.08069265]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022122785466490314, TP Loss: 0.5385773960500956\n",
      "[Validate] MAE Loss Across Timepoints: [0.03295799 0.03283161]\n",
      "[Validate] TP Loss Across Timepoints: [0.75966368 0.8096137 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96429145 1.06699705]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022048343968344854, TP Loss: 0.5349552632775157\n",
      "[Validate] MAE Loss Across Timepoints: [0.032937   0.03280482]\n",
      "[Validate] TP Loss Across Timepoints: [0.75689692 0.80132103]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95611382 1.05363856]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.021995033969869838, TP Loss: 0.5343446843791753\n",
      "[Validate] MAE Loss Across Timepoints: [0.03286414 0.03267969]\n",
      "[Validate] TP Loss Across Timepoints: [0.7550199  0.80145607]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94338596 1.05500079]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.021939796931110322, TP Loss: 0.5342852833680809\n",
      "[Validate] MAE Loss Across Timepoints: [0.03283477 0.0326311 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.75184159 0.79079704]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94799975 1.04445828]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.021849222003947944, TP Loss: 0.5254748400766402\n",
      "[Validate] MAE Loss Across Timepoints: [0.03278828 0.03255275]\n",
      "[Validate] TP Loss Across Timepoints: [0.75016809 0.78808112]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95762865 1.03847536]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02183602973818779, TP Loss: 0.5263289398979396\n",
      "[Validate] MAE Loss Across Timepoints: [0.03275438 0.03246163]\n",
      "[Validate] TP Loss Across Timepoints: [0.74755311 0.78128953]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94003695 1.02252887]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02175310311722569, TP Loss: 0.52081613461487\n",
      "[Validate] MAE Loss Across Timepoints: [0.03273328 0.03243528]\n",
      "[Validate] TP Loss Across Timepoints: [0.7453876  0.77719641]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95820094 1.03457554]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.0217816395976115, TP Loss: 0.5259538637008518\n",
      "[Validate] MAE Loss Across Timepoints: [0.03268807 0.03243985]\n",
      "[Validate] TP Loss Across Timepoints: [0.74396472 0.78318996]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94800022 1.02641818]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021684492443455383, TP Loss: 0.518066417472437\n",
      "[Validate] MAE Loss Across Timepoints: [0.03268385 0.0324008 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.74248061 0.77254391]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94003695 1.00826789]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.021688142855418847, TP Loss: 0.5194823761936277\n",
      "[Validate] MAE Loss Across Timepoints: [0.03263049 0.03233913]\n",
      "[Validate] TP Loss Across Timepoints: [0.74066086 0.77603722]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94199644 0.99717647]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.021643200394464657, TP Loss: 0.5153926177415997\n",
      "[Validate] MAE Loss Across Timepoints: [0.03262716 0.03230784]\n",
      "[Validate] TP Loss Across Timepoints: [0.73935494 0.76993947]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95519712 1.03589778]\n",
      "\n",
      "epochs finished with time:1149.4683742523193\n",
      "\n",
      "Current memory usage: 3391.77 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03129504 0.03284703]\n",
      "[Test] TP Loss Across Timepoints: [0.68058197 0.86603745]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.947112   0.97936341]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_2.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    # Create model instance\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "                # print(pred)\n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
