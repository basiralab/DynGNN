{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data, compute_memory_capacity_vectorized, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=5, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0.0001, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "# dataset_oasis = np.load('datasets/oasis_data.npy')\n",
    "# dataset_oasis = torch.from_numpy(dataset_oasis).squeeze()\n",
    "# dataset_oasis = dataset_oasis.type(torch.FloatTensor)\n",
    "# dataset_oasis = np.delete(dataset_oasis,88,axis=0)\n",
    "\n",
    "dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_oasis/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.033136056718649345, TP Loss: 1.3755161430686713, MAE of Mem Caps Loss: 0.18405302579472296\n",
      "[Validate] MAE Loss Across Timepoints: [0.03424898 0.03563851]\n",
      "[Validate] TP Loss Across Timepoints: [0.83237715 1.12105484]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06354027 1.11300274]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02450143901514821, TP Loss: 0.6244348041713238, MAE of Mem Caps Loss: 0.16387339814917504\n",
      "[Validate] MAE Loss Across Timepoints: [0.03337467 0.03457642]\n",
      "[Validate] TP Loss Across Timepoints: [0.76305962 0.98399849]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03393404 1.09891685]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023672811628784984, TP Loss: 0.5976705302018672, MAE of Mem Caps Loss: 0.21501201466441416\n",
      "[Validate] MAE Loss Across Timepoints: [0.03300608 0.03420666]\n",
      "[Validate] TP Loss Across Timepoints: [0.74345279 0.9603816 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02581029 1.10905663]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.023186431074282154, TP Loss: 0.5837542417924851, MAE of Mem Caps Loss: 0.2760115169895172\n",
      "[Validate] MAE Loss Across Timepoints: [0.03279192 0.03395528]\n",
      "[Validate] TP Loss Across Timepoints: [0.73253994 0.95479584]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03653394 1.12849934]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.022940376633778216, TP Loss: 0.5753377528395504, MAE of Mem Caps Loss: 0.3040451879884264\n",
      "[Validate] MAE Loss Across Timepoints: [0.032665   0.03381917]\n",
      "[Validate] TP Loss Across Timepoints: [0.72389297 0.93836069]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.91065327 1.03070142]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022703772003296763, TP Loss: 0.5649612793698907, MAE of Mem Caps Loss: 0.24285196142854573\n",
      "[Validate] MAE Loss Across Timepoints: [0.03255121 0.03360566]\n",
      "[Validate] TP Loss Across Timepoints: [0.71359119 0.9112999 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74510005 0.98558787]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.022593455464811996, TP Loss: 0.5629697814118118, MAE of Mem Caps Loss: 0.1950038682175806\n",
      "[Validate] MAE Loss Across Timepoints: [0.03243915 0.03353308]\n",
      "[Validate] TP Loss Across Timepoints: [0.70841937 0.91316805]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67056412 0.95818712]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02246326958411373, TP Loss: 0.5586618269328028, MAE of Mem Caps Loss: 0.19368813283476577\n",
      "[Validate] MAE Loss Across Timepoints: [0.03240417 0.03338393]\n",
      "[Validate] TP Loss Across Timepoints: [0.70328503 0.87969656]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63731636 0.92399958]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022376230510417372, TP Loss: 0.55393032040447, MAE of Mem Caps Loss: 0.19122709839081847\n",
      "[Validate] MAE Loss Across Timepoints: [0.0323127  0.03329942]\n",
      "[Validate] TP Loss Across Timepoints: [0.70066571 0.88294678]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59821526 0.90809262]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02228720712591894, TP Loss: 0.551398064289242, MAE of Mem Caps Loss: 0.19566190278959458\n",
      "[Validate] MAE Loss Across Timepoints: [0.0322711  0.03336172]\n",
      "[Validate] TP Loss Across Timepoints: [0.69893098 0.89121819]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56838444 0.84951589]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022183494712226092, TP Loss: 0.546324234129861, MAE of Mem Caps Loss: 0.19722017856748889\n",
      "[Validate] MAE Loss Across Timepoints: [0.03221556 0.03318343]\n",
      "[Validate] TP Loss Across Timepoints: [0.69610019 0.87709656]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54827065 0.86734728]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022127228626050054, TP Loss: 0.544087647786364, MAE of Mem Caps Loss: 0.19983245345852674\n",
      "[Validate] MAE Loss Across Timepoints: [0.03218916 0.03312354]\n",
      "[Validate] TP Loss Across Timepoints: [0.693435   0.86983271]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53181866 0.83928578]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02205414836644195, TP Loss: 0.5386512677185238, MAE of Mem Caps Loss: 0.19610144812369945\n",
      "[Validate] MAE Loss Across Timepoints: [0.03212503 0.03301315]\n",
      "[Validate] TP Loss Across Timepoints: [0.69054313 0.85901327]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53684214 0.81621126]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.021995519963093103, TP Loss: 0.5376667451113463, MAE of Mem Caps Loss: 0.20200830310519705\n",
      "[Validate] MAE Loss Across Timepoints: [0.0321076  0.03299751]\n",
      "[Validate] TP Loss Across Timepoints: [0.68826294 0.85360365]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52172973 0.81317546]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.021936902252491564, TP Loss: 0.5322724291589112, MAE of Mem Caps Loss: 0.2055980092548464\n",
      "[Validate] MAE Loss Across Timepoints: [0.03207231 0.03294143]\n",
      "[Validate] TP Loss Across Timepoints: [0.68698096 0.85382814]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54402518 0.84861198]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.021948792407056317, TP Loss: 0.535300911590457, MAE of Mem Caps Loss: 0.20923775634459885\n",
      "[Validate] MAE Loss Across Timepoints: [0.03204168 0.03284258]\n",
      "[Validate] TP Loss Across Timepoints: [0.68445573 0.8413868 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53342916 0.85014886]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021837781346403063, TP Loss: 0.5254288206808269, MAE of Mem Caps Loss: 0.2091898797789658\n",
      "[Validate] MAE Loss Across Timepoints: [0.03202216 0.03277747]\n",
      "[Validate] TP Loss Across Timepoints: [0.68307238 0.83353348]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53770469 0.83736005]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021814620512304827, TP Loss: 0.528895721025765, MAE of Mem Caps Loss: 0.21488549989102448\n",
      "[Validate] MAE Loss Across Timepoints: [0.03197371 0.03268874]\n",
      "[Validate] TP Loss Across Timepoints: [0.68101726 0.83019238]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53532278 0.83414402]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02179013309068978, TP Loss: 0.5262728294823319, MAE of Mem Caps Loss: 0.21595001038920417\n",
      "[Validate] MAE Loss Across Timepoints: [0.03192365 0.03267528]\n",
      "[Validate] TP Loss Across Timepoints: [0.67791734 0.82967787]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52030358 0.81706422]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.021760711917886512, TP Loss: 0.5253617445472628, MAE of Mem Caps Loss: 0.21311691651469605\n",
      "[Validate] MAE Loss Across Timepoints: [0.03190634 0.03264266]\n",
      "[Validate] TP Loss Across Timepoints: [0.6763154  0.82435646]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51656411 0.80191484]\n",
      "\n",
      "epochs finished with time:3607.781128883362\n",
      "\n",
      "Current memory usage: 3405.05 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03210867 0.03240548]\n",
      "[Test] TP Loss Across Timepoints: [0.80973    0.76212379]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.51301318 0.75375104]\n",
      "------------------------------------Fold [2/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03179485355503857, TP Loss: 1.187726666778326, MAE of Mem Caps Loss: 0.27844732528730554\n",
      "[Validate] MAE Loss Across Timepoints: [0.03445201 0.03621893]\n",
      "[Validate] TP Loss Across Timepoints: [0.88181934 1.14665747]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.08807839 1.09811915]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02440594790969044, TP Loss: 0.6364643183536828, MAE of Mem Caps Loss: 0.17617982834898066\n",
      "[Validate] MAE Loss Across Timepoints: [0.03349886 0.03489157]\n",
      "[Validate] TP Loss Across Timepoints: [0.80110502 1.00050182]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02751102 1.07801246]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02355786130647175, TP Loss: 0.6099588381592185, MAE of Mem Caps Loss: 0.2269690008454126\n",
      "[Validate] MAE Loss Across Timepoints: [0.03313633 0.03453259]\n",
      "[Validate] TP Loss Across Timepoints: [0.77500296 0.97738914]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94094588 1.08010225]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.023180924577172846, TP Loss: 0.5947395571973175, MAE of Mem Caps Loss: 0.2695125555458847\n",
      "[Validate] MAE Loss Across Timepoints: [0.03290575 0.03416153]\n",
      "[Validate] TP Loss Across Timepoints: [0.75185866 0.93986549]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.86065164 1.06069866]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02287615694804117, TP Loss: 0.583462993055582, MAE of Mem Caps Loss: 0.263524406290812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.0328069  0.03408047]\n",
      "[Validate] TP Loss Across Timepoints: [0.74577198 0.9404748 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8395496  1.01555759]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022685496101621537, TP Loss: 0.574030177295208, MAE of Mem Caps Loss: 0.2645548542477699\n",
      "[Validate] MAE Loss Across Timepoints: [0.03272791 0.03405852]\n",
      "[Validate] TP Loss Across Timepoints: [0.74244881 0.94241505]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.81090065 1.00029701]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02254182437318377, TP Loss: 0.5714594021439552, MAE of Mem Caps Loss: 0.27478906998729746\n",
      "[Validate] MAE Loss Across Timepoints: [0.03260731 0.03380098]\n",
      "[Validate] TP Loss Across Timepoints: [0.73250842 0.91537142]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7892196  0.98948562]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022453562810551376, TP Loss: 0.5683274627197534, MAE of Mem Caps Loss: 0.2866262422553729\n",
      "[Validate] MAE Loss Across Timepoints: [0.0325313  0.03377879]\n",
      "[Validate] TP Loss Across Timepoints: [0.73093281 0.91930056]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77888264 0.96949535]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022346272820141167, TP Loss: 0.5621913253329694, MAE of Mem Caps Loss: 0.29343685146746185\n",
      "[Validate] MAE Loss Across Timepoints: [0.03240389 0.03349786]\n",
      "[Validate] TP Loss Across Timepoints: [0.71681323 0.87911415]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78057021 0.98669842]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02226453317562118, TP Loss: 0.560198837891221, MAE of Mem Caps Loss: 0.3005796225089535\n",
      "[Validate] MAE Loss Across Timepoints: [0.03237645 0.03348517]\n",
      "[Validate] TP Loss Across Timepoints: [0.71996255 0.88400383]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79378942 0.98883693]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022184166754595936, TP Loss: 0.5538936124648899, MAE of Mem Caps Loss: 0.3026860822042237\n",
      "[Validate] MAE Loss Across Timepoints: [0.03233124 0.03347713]\n",
      "[Validate] TP Loss Across Timepoints: [0.71954174 0.8844327 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83302117 0.99426492]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02212322983541526, TP Loss: 0.553822666592896, MAE of Mem Caps Loss: 0.3028279718867642\n",
      "[Validate] MAE Loss Across Timepoints: [0.03226996 0.03332805]\n",
      "[Validate] TP Loss Across Timepoints: [0.71436825 0.86816826]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.80372415 0.99367287]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022037311032181605, TP Loss: 0.5482585208490491, MAE of Mem Caps Loss: 0.31817342230764245\n",
      "[Validate] MAE Loss Across Timepoints: [0.03221    0.03316555]\n",
      "[Validate] TP Loss Across Timepoints: [0.7107842  0.85544424]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8290231 0.9811958]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.021988412912469356, TP Loss: 0.545713780540973, MAE of Mem Caps Loss: 0.31528815916471853\n",
      "[Validate] MAE Loss Across Timepoints: [0.03217345 0.03317304]\n",
      "[Validate] TP Loss Across Timepoints: [0.70981302 0.85565109]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83930266 0.99320546]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.021952124690869823, TP Loss: 0.5436335723847151, MAE of Mem Caps Loss: 0.3187439152679246\n",
      "[Validate] MAE Loss Across Timepoints: [0.03214719 0.03312855]\n",
      "[Validate] TP Loss Across Timepoints: [0.70807457 0.84780302]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83571437 0.97520189]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.0218968823319301, TP Loss: 0.5413322334177793, MAE of Mem Caps Loss: 0.320764443440401\n",
      "[Validate] MAE Loss Across Timepoints: [0.03211319 0.03311207]\n",
      "[Validate] TP Loss Across Timepoints: [0.70644698 0.84846611]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84327113 0.98058337]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021845422242768107, TP Loss: 0.5390926137100905, MAE of Mem Caps Loss: 0.3249839231219389\n",
      "[Validate] MAE Loss Across Timepoints: [0.03208884 0.03302168]\n",
      "[Validate] TP Loss Across Timepoints: [0.70489359 0.83962059]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82496959 0.97782563]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021824309916701166, TP Loss: 0.5364080884493887, MAE of Mem Caps Loss: 0.32567659059924287\n",
      "[Validate] MAE Loss Across Timepoints: [0.0320258  0.03290402]\n",
      "[Validate] TP Loss Across Timepoints: [0.7002388  0.82528982]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83996394 1.00238708]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.021776996488915755, TP Loss: 0.5342751758173108, MAE of Mem Caps Loss: 0.3318804456701546\n",
      "[Validate] MAE Loss Across Timepoints: [0.03203602 0.0329765 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.70365338 0.83779783]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8181792  0.98583568]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02176061863428913, TP Loss: 0.5339406423270703, MAE of Mem Caps Loss: 0.32352477482117376\n",
      "[Validate] MAE Loss Across Timepoints: [0.03199116 0.03283491]\n",
      "[Validate] TP Loss Across Timepoints: [0.6987042  0.81394234]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82379504 0.99297163]\n",
      "\n",
      "epochs finished with time:3603.733870983124\n",
      "\n",
      "Current memory usage: 3411.71 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03190626 0.03214137]\n",
      "[Test] TP Loss Across Timepoints: [0.7335228  0.75841843]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.76994033 0.97796176]\n",
      "------------------------------------Fold [3/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03367921585449949, TP Loss: 1.3365795714780688, MAE of Mem Caps Loss: 0.21774207780440175\n",
      "[Validate] MAE Loss Across Timepoints: [0.03495926 0.03698034]\n",
      "[Validate] TP Loss Across Timepoints: [0.92418146 1.23220453]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.27901816 1.53255917]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02434482517419383, TP Loss: 0.621809896081686, MAE of Mem Caps Loss: 0.18900028166997712\n",
      "[Validate] MAE Loss Across Timepoints: [0.0338322  0.03543327]\n",
      "[Validate] TP Loss Across Timepoints: [0.8367322  1.06600323]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95702102 1.07642389]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023533470107940956, TP Loss: 0.5904176142066717, MAE of Mem Caps Loss: 0.18751852582632908\n",
      "[Validate] MAE Loss Across Timepoints: [0.03344469 0.03507335]\n",
      "[Validate] TP Loss Across Timepoints: [0.81434193 1.04217453]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89848795 1.06867975]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.023103391635231674, TP Loss: 0.579857557779178, MAE of Mem Caps Loss: 0.19524010616644044\n",
      "[Validate] MAE Loss Across Timepoints: [0.03317826 0.03476751]\n",
      "[Validate] TP Loss Across Timepoints: [0.79851775 1.02159138]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.88617534 1.06173606]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02278957690577954, TP Loss: 0.5647211208939552, MAE of Mem Caps Loss: 0.2093501344062135\n",
      "[Validate] MAE Loss Across Timepoints: [0.0330231  0.03457781]\n",
      "[Validate] TP Loss Across Timepoints: [0.78487387 1.00044861]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83888099 1.06892622]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02263086154125631, TP Loss: 0.5621183044277132, MAE of Mem Caps Loss: 0.2215404570781546\n",
      "[Validate] MAE Loss Across Timepoints: [0.0328785 0.0343366]\n",
      "[Validate] TP Loss Across Timepoints: [0.77293105 0.97333508]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84449586 1.05934012]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02249655409832485, TP Loss: 0.5551272737327964, MAE of Mem Caps Loss: 0.232487776220498\n",
      "[Validate] MAE Loss Across Timepoints: [0.03280089 0.03431363]\n",
      "[Validate] TP Loss Across Timepoints: [0.77065201 0.97552681]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83127208 1.06448503]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022381290007615462, TP Loss: 0.5560117337387055, MAE of Mem Caps Loss: 0.2411016061432858\n",
      "[Validate] MAE Loss Across Timepoints: [0.03270663 0.03421845]\n",
      "[Validate] TP Loss Across Timepoints: [0.76414342 0.96503267]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82750846 1.05344293]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022284225694602356, TP Loss: 0.5498301452957094, MAE of Mem Caps Loss: 0.24998932952785094\n",
      "[Validate] MAE Loss Across Timepoints: [0.03260149 0.03407952]\n",
      "[Validate] TP Loss Across Timepoints: [0.75666127 0.95231285]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82939758 1.05457441]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022168018511729316, TP Loss: 0.5412550272420049, MAE of Mem Caps Loss: 0.25256619663746693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03249222 0.03396326]\n",
      "[Validate] TP Loss Across Timepoints: [0.75023427 0.94355545]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78270097 1.02838865]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02206845433684066, TP Loss: 0.5379932090174406, MAE of Mem Caps Loss: 0.25629938330145186\n",
      "[Validate] MAE Loss Across Timepoints: [0.0324459  0.03389789]\n",
      "[Validate] TP Loss Across Timepoints: [0.75010657 0.94228716]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77321219 0.99023617]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022001419367734344, TP Loss: 0.5349210978019983, MAE of Mem Caps Loss: 0.26634444563868737\n",
      "[Validate] MAE Loss Across Timepoints: [0.03235664 0.03377882]\n",
      "[Validate] TP Loss Across Timepoints: [0.74205952 0.9226038 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78087437 0.9905019 ]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.021926841838285326, TP Loss: 0.5335766546893865, MAE of Mem Caps Loss: 0.27210729937517\n",
      "[Validate] MAE Loss Across Timepoints: [0.03231558 0.03375683]\n",
      "[Validate] TP Loss Across Timepoints: [0.74087234 0.92335434]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77264563 0.98623258]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02187824213760905, TP Loss: 0.5288567089941353, MAE of Mem Caps Loss: 0.2718443636212121\n",
      "[Validate] MAE Loss Across Timepoints: [0.03226894 0.03369133]\n",
      "[Validate] TP Loss Across Timepoints: [0.73841805 0.92125587]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78194415 0.9964285 ]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.021818426804384217, TP Loss: 0.5253733159508556, MAE of Mem Caps Loss: 0.2772279811570012\n",
      "[Validate] MAE Loss Across Timepoints: [0.03222868 0.03359604]\n",
      "[Validate] TP Loss Across Timepoints: [0.73725419 0.91262398]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79230549 0.98648743]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02182108801207505, TP Loss: 0.5277419179212302, MAE of Mem Caps Loss: 0.28673431353799905\n",
      "[Validate] MAE Loss Across Timepoints: [0.03220343 0.03358728]\n",
      "[Validate] TP Loss Across Timepoints: [0.73678446 0.91675625]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.80207219 0.98524699]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021755508158821612, TP Loss: 0.5251056568231434, MAE of Mem Caps Loss: 0.2869955263336962\n",
      "[Validate] MAE Loss Across Timepoints: [0.03215428 0.03350917]\n",
      "[Validate] TP Loss Across Timepoints: [0.73268518 0.90610256]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7869219  0.99556953]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02174750341218896, TP Loss: 0.5246319078840316, MAE of Mem Caps Loss: 0.2870941785328184\n",
      "[Validate] MAE Loss Across Timepoints: [0.03216164 0.0335132 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.73502622 0.90782089]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78012812 0.96402329]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.021678554255049675, TP Loss: 0.5177250153850764, MAE of Mem Caps Loss: 0.28641594865414716\n",
      "[Validate] MAE Loss Across Timepoints: [0.03209673 0.03344662]\n",
      "[Validate] TP Loss Across Timepoints: [0.72906151 0.89991255]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78428199 0.94185294]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.021618358563864605, TP Loss: 0.5133958410937339, MAE of Mem Caps Loss: 0.28676752043488785\n",
      "[Validate] MAE Loss Across Timepoints: [0.03204695 0.03331435]\n",
      "[Validate] TP Loss Across Timepoints: [0.72455783 0.88345299]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78316852 0.97570452]\n",
      "\n",
      "epochs finished with time:3523.1915140151978\n",
      "\n",
      "Current memory usage: 3481.67 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03244184 0.03227188]\n",
      "[Test] TP Loss Across Timepoints: [0.79340607 0.79386734]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.77734717 0.96730102]\n",
      "------------------------------------Fold [4/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.035343921242747454, TP Loss: 1.6467828225344419, MAE of Mem Caps Loss: 0.2126899494923033\n",
      "[Validate] MAE Loss Across Timepoints: [0.03476999 0.03599974]\n",
      "[Validate] TP Loss Across Timepoints: [0.94287424 1.17819662]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.46349784 1.68380114]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.024538755568210037, TP Loss: 0.6317487366497516, MAE of Mem Caps Loss: 0.16742482404239473\n",
      "[Validate] MAE Loss Across Timepoints: [0.03374829 0.0346209 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.87006741 1.03356104]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0539154  1.08538029]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.023665110766887664, TP Loss: 0.6046498699113727, MAE of Mem Caps Loss: 0.21018113768926722\n",
      "[Validate] MAE Loss Across Timepoints: [0.03344204 0.03429934]\n",
      "[Validate] TP Loss Across Timepoints: [0.85045385 1.00531588]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01474856 1.05898847]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02326581469969824, TP Loss: 0.5939007834531367, MAE of Mem Caps Loss: 0.23443285731046792\n",
      "[Validate] MAE Loss Across Timepoints: [0.0331754  0.03388665]\n",
      "[Validate] TP Loss Across Timepoints: [0.82439127 0.96028719]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83744836 1.03567577]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.022979999129893257, TP Loss: 0.5818062764592469, MAE of Mem Caps Loss: 0.2201793023938358\n",
      "[Validate] MAE Loss Across Timepoints: [0.03305986 0.03379961]\n",
      "[Validate] TP Loss Across Timepoints: [0.81625566 0.95715609]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74116239 1.02044684]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022826229210477323, TP Loss: 0.5781127115245909, MAE of Mem Caps Loss: 0.19947810671547644\n",
      "[Validate] MAE Loss Across Timepoints: [0.03296923 0.03370089]\n",
      "[Validate] TP Loss Across Timepoints: [0.80873213 0.94838057]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67744675 1.00560466]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.022708633507136256, TP Loss: 0.5771232196129858, MAE of Mem Caps Loss: 0.18676258095227588\n",
      "[Validate] MAE Loss Across Timepoints: [0.03288981 0.03369195]\n",
      "[Validate] TP Loss Across Timepoints: [0.8076808  0.95447283]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61539863 0.99459705]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022552718746010215, TP Loss: 0.5668348393868655, MAE of Mem Caps Loss: 0.18632977168999348\n",
      "[Validate] MAE Loss Across Timepoints: [0.03272294 0.03336736]\n",
      "[Validate] TP Loss Across Timepoints: [0.78769684 0.90723763]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60878693 0.99063514]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022453317570034416, TP Loss: 0.5594379965215921, MAE of Mem Caps Loss: 0.1904720007248301\n",
      "[Validate] MAE Loss Across Timepoints: [0.03267368 0.03332478]\n",
      "[Validate] TP Loss Across Timepoints: [0.78788934 0.90553703]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57277127 0.95825211]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022338952333666385, TP Loss: 0.5571938710752875, MAE of Mem Caps Loss: 0.19126294197308608\n",
      "[Validate] MAE Loss Across Timepoints: [0.03259459 0.03317845]\n",
      "[Validate] TP Loss Across Timepoints: [0.78133106 0.88805523]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55426959 0.96028062]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022268810553941875, TP Loss: 0.5532283523119986, MAE of Mem Caps Loss: 0.18655133939575666\n",
      "[Validate] MAE Loss Across Timepoints: [0.03257609 0.03315811]\n",
      "[Validate] TP Loss Across Timepoints: [0.78350039 0.88965111]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56262308 0.95120102]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02217841219971888, TP Loss: 0.5495394706260412, MAE of Mem Caps Loss: 0.18529866580876253\n",
      "[Validate] MAE Loss Across Timepoints: [0.03248758 0.03294871]\n",
      "[Validate] TP Loss Across Timepoints: [0.77411618 0.86313267]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55146765 0.91976812]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022145435342099517, TP Loss: 0.5465326767414809, MAE of Mem Caps Loss: 0.18796839034098928\n",
      "[Validate] MAE Loss Across Timepoints: [0.03247022 0.0329692 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.77519913 0.8666193 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52899947 0.9178474 ]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.022085727547528224, TP Loss: 0.5464032252319158, MAE of Mem Caps Loss: 0.1909622965656915\n",
      "[Validate] MAE Loss Across Timepoints: [0.03245336 0.03290424]\n",
      "[Validate] TP Loss Across Timepoints: [0.77526698 0.8606741 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56266002 0.93521095]\n",
      "Epoch [15/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.022017962363315748, TP Loss: 0.5391569360624999, MAE of Mem Caps Loss: 0.1969694638183026\n",
      "[Validate] MAE Loss Across Timepoints: [0.03237071 0.03274103]\n",
      "[Validate] TP Loss Across Timepoints: [0.76637292 0.83939743]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52465248 0.91355758]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.021988080628216267, TP Loss: 0.5413698165677487, MAE of Mem Caps Loss: 0.19584818539187876\n",
      "[Validate] MAE Loss Across Timepoints: [0.03237944 0.03284668]\n",
      "[Validate] TP Loss Across Timepoints: [0.77125278 0.85492315]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53554994 0.90060014]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021958804898895325, TP Loss: 0.5356136629823596, MAE of Mem Caps Loss: 0.19960744388905538\n",
      "[Validate] MAE Loss Across Timepoints: [0.0323409  0.03278888]\n",
      "[Validate] TP Loss Across Timepoints: [0.77124104 0.85194826]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52444359 0.90310671]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021915367600740865, TP Loss: 0.5357909175101667, MAE of Mem Caps Loss: 0.20101781353606052\n",
      "[Validate] MAE Loss Across Timepoints: [0.03231111 0.03271715]\n",
      "[Validate] TP Loss Across Timepoints: [0.76805706 0.84229383]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52963691 0.92100575]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02189156601089053, TP Loss: 0.5371944698505103, MAE of Mem Caps Loss: 0.1990139174016181\n",
      "[Validate] MAE Loss Across Timepoints: [0.03227955 0.03266304]\n",
      "[Validate] TP Loss Across Timepoints: [0.76521802 0.8349906 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55103878 0.87829989]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.021814577077748254, TP Loss: 0.5291194416582584, MAE of Mem Caps Loss: 0.2071400895941705\n",
      "[Validate] MAE Loss Across Timepoints: [0.03220126 0.03246113]\n",
      "[Validate] TP Loss Across Timepoints: [0.75612674 0.80911551]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54485956 0.84964599]\n",
      "\n",
      "epochs finished with time:3540.2460396289825\n",
      "\n",
      "Current memory usage: 3480.13 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03126559 0.03314859]\n",
      "[Test] TP Loss Across Timepoints: [0.67791901 0.84539635]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.52821827 0.86422206]\n",
      "------------------------------------Fold [5/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.030971327220322566, TP Loss: 1.1397332280874253, MAE of Mem Caps Loss: 0.1826738714993456\n",
      "[Validate] MAE Loss Across Timepoints: [0.03456885 0.03437313]\n",
      "[Validate] TP Loss Across Timepoints: [0.8677844  0.96319008]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03549596 1.1079971 ]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.024036564934067427, TP Loss: 0.6074104025959969, MAE of Mem Caps Loss: 0.1874010502976618\n",
      "[Validate] MAE Loss Across Timepoints: [0.03380495 0.03357608]\n",
      "[Validate] TP Loss Across Timepoints: [0.81038446 0.87847414]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9339257  1.08693084]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02330961117404513, TP Loss: 0.5829936693422496, MAE of Mem Caps Loss: 0.21866696890126408\n",
      "[Validate] MAE Loss Across Timepoints: [0.03358639 0.03337266]\n",
      "[Validate] TP Loss Across Timepoints: [0.79614167 0.86148777]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89188642 1.06711709]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02297338919597678, TP Loss: 0.5731589231640101, MAE of Mem Caps Loss: 0.24349605407164693\n",
      "[Validate] MAE Loss Across Timepoints: [0.03348033 0.03330625]\n",
      "[Validate] TP Loss Across Timepoints: [0.79027905 0.85403404]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.87222141 1.06699252]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.022723413223866375, TP Loss: 0.560384253365919, MAE of Mem Caps Loss: 0.24645791025291883\n",
      "[Validate] MAE Loss Across Timepoints: [0.03338488 0.03320614]\n",
      "[Validate] TP Loss Across Timepoints: [0.78446665 0.84298248]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.87129209 1.07250346]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.022597492509521543, TP Loss: 0.5621891248505563, MAE of Mem Caps Loss: 0.2467744550525876\n",
      "[Validate] MAE Loss Across Timepoints: [0.03330125 0.03315358]\n",
      "[Validate] TP Loss Across Timepoints: [0.77893181 0.84064837]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.87981864 1.06136259]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.022451993316644804, TP Loss: 0.5550422671250999, MAE of Mem Caps Loss: 0.2524850005330775\n",
      "[Validate] MAE Loss Across Timepoints: [0.03321862 0.03308083]\n",
      "[Validate] TP Loss Across Timepoints: [0.77854629 0.85113688]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82531934 1.05619926]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022330408851848914, TP Loss: 0.5523450046777725, MAE of Mem Caps Loss: 0.2690189750267323\n",
      "[Validate] MAE Loss Across Timepoints: [0.03316992 0.03315669]\n",
      "[Validate] TP Loss Across Timepoints: [0.77315631 0.84274817]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79409583 1.02827572]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02223923521814868, TP Loss: 0.5468154924921691, MAE of Mem Caps Loss: 0.26325924079920215\n",
      "[Validate] MAE Loss Across Timepoints: [0.0330658  0.03295036]\n",
      "[Validate] TP Loss Across Timepoints: [0.76897292 0.83553267]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.75047009 0.9858317 ]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022146341955522075, TP Loss: 0.5419635493773967, MAE of Mem Caps Loss: 0.26705801368107773\n",
      "[Validate] MAE Loss Across Timepoints: [0.03299944 0.03291544]\n",
      "[Validate] TP Loss Across Timepoints: [0.76385975 0.82475863]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.71802379 1.00930807]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022069173865020275, TP Loss: 0.5381560086738318, MAE of Mem Caps Loss: 0.27214472730358663\n",
      "[Validate] MAE Loss Across Timepoints: [0.03296583 0.03287447]\n",
      "[Validate] TP Loss Across Timepoints: [0.75980034 0.81388845]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.72872984 0.98274422]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022017549246083946, TP Loss: 0.5372903897892684, MAE of Mem Caps Loss: 0.2794767225421462\n",
      "[Validate] MAE Loss Across Timepoints: [0.03290184 0.03276629]\n",
      "[Validate] TP Loss Across Timepoints: [0.7584208  0.81369543]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.72520285 0.93947981]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.021961835719412192, TP Loss: 0.537338186847046, MAE of Mem Caps Loss: 0.28455909283822944\n",
      "[Validate] MAE Loss Across Timepoints: [0.03286459 0.03272077]\n",
      "[Validate] TP Loss Across Timepoints: [0.75510364 0.80487509]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73867639 0.96463407]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02187249676208012, TP Loss: 0.528342273645103, MAE of Mem Caps Loss: 0.2877724659123248\n",
      "[Validate] MAE Loss Across Timepoints: [0.03282199 0.0326376 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.7535449 0.8011138]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73416728 0.89579422]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.021859940188005567, TP Loss: 0.5293851212598384, MAE of Mem Caps Loss: 0.29503840052013686\n",
      "[Validate] MAE Loss Across Timepoints: [0.03278181 0.03254565]\n",
      "[Validate] TP Loss Across Timepoints: [0.75045114 0.79536095]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.75546218 0.93543936]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02177583496668376, TP Loss: 0.5239841567818075, MAE of Mem Caps Loss: 0.29646875069306267\n",
      "[Validate] MAE Loss Across Timepoints: [0.03276089 0.03249461]\n",
      "[Validate] TP Loss Across Timepoints: [0.7480114  0.78784795]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74744182 0.93529287]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.021802811219822617, TP Loss: 0.5290687950327992, MAE of Mem Caps Loss: 0.30582257544042996\n",
      "[Validate] MAE Loss Across Timepoints: [0.03272721 0.03253562]\n",
      "[Validate] TP Loss Across Timepoints: [0.74857254 0.79878464]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74295748 0.93296606]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.021704047615639866, TP Loss: 0.5212824953254312, MAE of Mem Caps Loss: 0.3023311769470617\n",
      "[Validate] MAE Loss Across Timepoints: [0.03270989 0.03245758]\n",
      "[Validate] TP Loss Across Timepoints: [0.74488273 0.78293848]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.76923412 0.93795663]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02170836688601412, TP Loss: 0.5223880503326654, MAE of Mem Caps Loss: 0.3184656963668059\n",
      "[Validate] MAE Loss Across Timepoints: [0.03266146 0.03241051]\n",
      "[Validate] TP Loss Across Timepoints: [0.74313779 0.78672647]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.75851768 0.95054257]\n",
      "Epoch [20/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.02166383685544133, TP Loss: 0.5181394159328192, MAE of Mem Caps Loss: 0.30758788950571614\n",
      "[Validate] MAE Loss Across Timepoints: [0.03265403 0.03234463]\n",
      "[Validate] TP Loss Across Timepoints: [0.74206839 0.77903023]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73586927 0.93114493]\n",
      "\n",
      "epochs finished with time:3565.4009833335876\n",
      "\n",
      "Current memory usage: 3476.36 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03131511 0.03288807]\n",
      "[Test] TP Loss Across Timepoints: [0.68572952 0.876436  ]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.75130877 0.87988652]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_2.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "   \n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights, input_scaling=1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        mae_mem_cap_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "            mem_cap_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred, output_sig = model(data[t], X_train_res, y_train_res, X_test_res)\n",
    "                    \n",
    "                real = data[t + 1]\n",
    "     \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "                # MAE between predicted graph's mem cap and actual graph's mem cap\n",
    "                predicted_mem_cap = compute_memory_capacity_vectorized(output_sig, y_test_res)\n",
    "                actual_mem_cap = torch.tensor(train_mem_cap_subjects[data_id, t + 1], requires_grad=True).to(device)\n",
    "                mem_cap_loss += mael(predicted_mem_cap, actual_mem_cap)\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total MAE between Mem Cap Loss for the current batch\n",
    "            mem_cap_loss = mem_cap_loss / (args.num_timepoints - 1)\n",
    "            \n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            mae_mem_cap_overall.append(mem_cap_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss + args.memcap_coef * mem_cap_loss \n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        mae_mem_cap_overall = np.mean(np.array(mae_mem_cap_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}, MAE of Mem Caps Loss: {mae_mem_cap_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
