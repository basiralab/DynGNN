{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.tagnet_simple import DeepTAGNet\n",
    "from memory_capacity_utils import gen_lag_data, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=3, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "dataset = np.load('datasets/oasis_data.npy')\n",
    "#dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "dataset = np.delete(dataset,88,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_tag_oasis_t/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n",
      "TRAIN deterministic algorithms\n"
     ]
    }
   ],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.051972172285119696, TP Loss: 3.356199866036574\n",
      "[Validate] MAE Loss Across Timepoints: [0.06900554 0.05974131]\n",
      "[Validate] TP Loss Across Timepoints: [10.55288595  2.15235875]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45325584 0.83494781]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.04192946559439103, TP Loss: 2.5840425958236057\n",
      "[Validate] MAE Loss Across Timepoints: [0.06122526 0.050646  ]\n",
      "[Validate] TP Loss Across Timepoints: [9.08497721 1.73136775]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.32298353 0.63591914]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.037830965345104536, TP Loss: 2.1837370281418162\n",
      "[Validate] MAE Loss Across Timepoints: [0.05776773 0.04568907]\n",
      "[Validate] TP Loss Across Timepoints: [8.58195597 1.60464834]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45647625 0.46869213]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03554352053130667, TP Loss: 2.082121756176154\n",
      "[Validate] MAE Loss Across Timepoints: [0.05586514 0.04319567]\n",
      "[Validate] TP Loss Across Timepoints: [8.04738363 1.27618574]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47971668 0.52635618]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.03409015713259578, TP Loss: 1.9555648118257523\n",
      "[Validate] MAE Loss Across Timepoints: [0.05502109 0.04251984]\n",
      "[Validate] TP Loss Across Timepoints: [8.05878652 1.29327736]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5666738  0.81699031]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.032994126559545596, TP Loss: 1.9383329138159753\n",
      "[Validate] MAE Loss Across Timepoints: [0.05436209 0.04149583]\n",
      "[Validate] TP Loss Across Timepoints: [7.87405192 1.15854365]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51838033 0.88155721]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.03219613923380772, TP Loss: 1.864023228486379\n",
      "[Validate] MAE Loss Across Timepoints: [0.05385474 0.04095205]\n",
      "[Validate] TP Loss Across Timepoints: [7.81150411 1.1634004 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5415391  0.94690582]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.03188403273622195, TP Loss: 1.874697396159172\n",
      "[Validate] MAE Loss Across Timepoints: [0.05312428 0.04105765]\n",
      "[Validate] TP Loss Across Timepoints: [7.46491191 1.00450745]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48321596 0.85929593]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.030761582838992278, TP Loss: 1.754356077561776\n",
      "[Validate] MAE Loss Across Timepoints: [0.05270647 0.03985782]\n",
      "[Validate] TP Loss Across Timepoints: [7.44917704 0.98743903]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66793027 0.96687269]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.03056102814152837, TP Loss: 1.7773491512984037\n",
      "[Validate] MAE Loss Across Timepoints: [0.0526902  0.04048485]\n",
      "[Validate] TP Loss Across Timepoints: [7.39277852 0.99072278]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67086348 0.91107053]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.030415811017155646, TP Loss: 1.7867678788801034\n",
      "[Validate] MAE Loss Across Timepoints: [0.05272424 0.04046608]\n",
      "[Validate] TP Loss Across Timepoints: [7.37026927 0.97964967]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68684715 0.96485715]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.03009375846013427, TP Loss: 1.7541736116011937\n",
      "[Validate] MAE Loss Across Timepoints: [0.05273811 0.04035973]\n",
      "[Validate] TP Loss Across Timepoints: [7.44634705 0.97617009]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68793248 1.00214993]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.029852489630381267, TP Loss: 1.7668089270591736\n",
      "[Validate] MAE Loss Across Timepoints: [0.05246623 0.03978411]\n",
      "[Validate] TP Loss Across Timepoints: [7.47380015 0.97647756]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70220991 0.9086671 ]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.029941133068253595, TP Loss: 1.7717837216953436\n",
      "[Validate] MAE Loss Across Timepoints: [0.05253668 0.04009865]\n",
      "[Validate] TP Loss Across Timepoints: [7.40263672 0.97388032]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.69438118 0.90294596]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.029928255376095572, TP Loss: 1.7497224676112333\n",
      "[Validate] MAE Loss Across Timepoints: [0.05286588 0.04023376]\n",
      "[Validate] TP Loss Across Timepoints: [7.49312286 0.98173974]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.69816308 0.98144921]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02960153603926301, TP Loss: 1.7431982539594173\n",
      "[Validate] MAE Loss Across Timepoints: [0.05096921 0.03915533]\n",
      "[Validate] TP Loss Across Timepoints: [7.29385834 0.99199689]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.71805081 0.89270653]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02904266162465016, TP Loss: 1.7402820768455665\n",
      "[Validate] MAE Loss Across Timepoints: [0.05089207 0.03853414]\n",
      "[Validate] TP Loss Across Timepoints: [7.38550212 0.98590126]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68665723 0.93227021]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.028943520318716765, TP Loss: 1.7232325188815594\n",
      "[Validate] MAE Loss Across Timepoints: [0.0509915  0.03945262]\n",
      "[Validate] TP Loss Across Timepoints: [7.31588135 1.0096269 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70292529 1.11044755]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.028927248328303297, TP Loss: 1.7213025028506914\n",
      "[Validate] MAE Loss Across Timepoints: [0.05081264 0.03917927]\n",
      "[Validate] TP Loss Across Timepoints: [7.32391205 1.00399615]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.746541   0.93362616]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.028888505417853594, TP Loss: 1.751630679766337\n",
      "[Validate] MAE Loss Across Timepoints: [0.05097622 0.03987889]\n",
      "[Validate] TP Loss Across Timepoints: [7.26862539 1.02570108]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68279229 1.11515838]\n",
      "\n",
      "epochs finished with time:194.15240287780762\n",
      "\n",
      "Current memory usage: 2100.30 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03678189 0.04253891]\n",
      "[Test] TP Loss Across Timepoints: [1.0479133  1.58019889]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.85663249 1.01835512]\n",
      "------------------------------------Fold [2/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.05448668971657753, TP Loss: 3.806825077533722\n",
      "[Validate] MAE Loss Across Timepoints: [0.07571863 0.07784115]\n",
      "[Validate] TP Loss Across Timepoints: [11.74555868  5.13960673]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4659667  0.81793769]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.042416177907337746, TP Loss: 2.3466123322645824\n",
      "[Validate] MAE Loss Across Timepoints: [0.06153255 0.06119634]\n",
      "[Validate] TP Loss Across Timepoints: [9.16694539 3.63470968]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.32259961 0.39671721]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.036952172157665095, TP Loss: 1.7886114488045375\n",
      "[Validate] MAE Loss Across Timepoints: [0.05440466 0.05169176]\n",
      "[Validate] TP Loss Across Timepoints: [7.89232076 2.81753438]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30660989 0.40030653]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03342917871971925, TP Loss: 1.5373631611466407\n",
      "[Validate] MAE Loss Across Timepoints: [0.05090091 0.0467212 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.27348989 2.09519501]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53813856 0.552092  ]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.03135003407175342, TP Loss: 1.4488140324751535\n",
      "[Validate] MAE Loss Across Timepoints: [0.04922442 0.04476134]\n",
      "[Validate] TP Loss Across Timepoints: [6.86788177 1.69163767]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6070188  0.69921798]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.029966650654872258, TP Loss: 1.3747566528618336\n",
      "[Validate] MAE Loss Across Timepoints: [0.04860456 0.04421475]\n",
      "[Validate] TP Loss Across Timepoints: [6.84764455 1.68492355]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6280723  0.70248745]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.029316131646434467, TP Loss: 1.3531635634601116\n",
      "[Validate] MAE Loss Across Timepoints: [0.04867606 0.04429992]\n",
      "[Validate] TP Loss Across Timepoints: [6.90727997 1.76371307]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63389078 0.69248331]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02857660378019015, TP Loss: 1.2834769420325756\n",
      "[Validate] MAE Loss Across Timepoints: [0.0479023  0.04375174]\n",
      "[Validate] TP Loss Across Timepoints: [6.68735046 1.52562281]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65685259 0.7262952 ]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.028325705292324223, TP Loss: 1.3126718280216059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.04793885 0.04355171]\n",
      "[Validate] TP Loss Across Timepoints: [6.8591802 1.6989104]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59680116 0.72561641]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02805154025554657, TP Loss: 1.2766546475390592\n",
      "[Validate] MAE Loss Across Timepoints: [0.04803227 0.04352924]\n",
      "[Validate] TP Loss Across Timepoints: [6.89701589 1.70475248]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63051645 0.73969554]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.0279779768238465, TP Loss: 1.2849013162155947\n",
      "[Validate] MAE Loss Across Timepoints: [0.04815127 0.04380531]\n",
      "[Validate] TP Loss Across Timepoints: [7.00085805 1.84635468]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60563151 0.71937835]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.027857399793962637, TP Loss: 1.2642772637307644\n",
      "[Validate] MAE Loss Across Timepoints: [0.04796966 0.04363661]\n",
      "[Validate] TP Loss Across Timepoints: [6.92495575 1.75353839]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57955559 0.73755827]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.027766289096325635, TP Loss: 1.2462176660696664\n",
      "[Validate] MAE Loss Across Timepoints: [0.04801351 0.04379832]\n",
      "[Validate] TP Loss Across Timepoints: [6.81390228 1.71310234]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.630621   0.76940737]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.027611376686642566, TP Loss: 1.2660101590057213\n",
      "[Validate] MAE Loss Across Timepoints: [0.04753106 0.04309116]\n",
      "[Validate] TP Loss Across Timepoints: [6.71963959 1.60537211]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58778184 0.77019593]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.027553617085019747, TP Loss: 1.242449008176724\n",
      "[Validate] MAE Loss Across Timepoints: [0.0477956  0.04344654]\n",
      "[Validate] TP Loss Across Timepoints: [6.79030965 1.67982839]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60754663 0.76152649]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.027398745249956846, TP Loss: 1.236635947227478\n",
      "[Validate] MAE Loss Across Timepoints: [0.04762162 0.04325898]\n",
      "[Validate] TP Loss Across Timepoints: [6.73564097 1.63468094]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66480388 0.93960744]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02747333642716209, TP Loss: 1.2603877663612366\n",
      "[Validate] MAE Loss Across Timepoints: [0.04775153 0.04361269]\n",
      "[Validate] TP Loss Across Timepoints: [6.85694733 1.76597252]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61630523 0.78461275]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02729261216397087, TP Loss: 1.2199888778229555\n",
      "[Validate] MAE Loss Across Timepoints: [0.04811262 0.04401244]\n",
      "[Validate] TP Loss Across Timepoints: [6.77434438 1.7225015 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61267724 0.85214855]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.027292375328640144, TP Loss: 1.2374257266521453\n",
      "[Validate] MAE Loss Across Timepoints: [0.04784555 0.04379414]\n",
      "[Validate] TP Loss Across Timepoints: [6.82627767 1.76714007]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61668847 0.7757761 ]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.027223057486116885, TP Loss: 1.225863915681839\n",
      "[Validate] MAE Loss Across Timepoints: [0.04757167 0.04346159]\n",
      "[Validate] TP Loss Across Timepoints: [6.84773458 1.78387731]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60234449 0.76119894]\n",
      "\n",
      "epochs finished with time:195.89034938812256\n",
      "\n",
      "Current memory usage: 2097.74 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04306884 0.04723896]\n",
      "[Test] TP Loss Across Timepoints: [2.1017432  3.81828951]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.69767891 0.84404845]\n",
      "------------------------------------Fold [3/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.05133165828883648, TP Loss: 3.486637119452159\n",
      "[Validate] MAE Loss Across Timepoints: [0.0606379  0.06757484]\n",
      "[Validate] TP Loss Across Timepoints: [4.32763481 4.69495392]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48697772 0.64888913]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.04161512221520146, TP Loss: 2.4089177827040356\n",
      "[Validate] MAE Loss Across Timepoints: [0.04821387 0.05163327]\n",
      "[Validate] TP Loss Across Timepoints: [2.46497822 2.66143537]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57611068 0.74602316]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03678322862833738, TP Loss: 1.9812845677137374\n",
      "[Validate] MAE Loss Across Timepoints: [0.04282154 0.04605611]\n",
      "[Validate] TP Loss Across Timepoints: [1.73719871 1.91576219]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63875877 0.77004978]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03411087452744444, TP Loss: 1.8272040781875452\n",
      "[Validate] MAE Loss Across Timepoints: [0.04117665 0.04451355]\n",
      "[Validate] TP Loss Across Timepoints: [1.50819743 1.75258923]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67276003 0.76735195]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.03221729065602024, TP Loss: 1.714660759518544\n",
      "[Validate] MAE Loss Across Timepoints: [0.04053121 0.04418114]\n",
      "[Validate] TP Loss Across Timepoints: [1.41438532 1.64648294]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70280234 0.81930771]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.03087409700577458, TP Loss: 1.5897024852534136\n",
      "[Validate] MAE Loss Across Timepoints: [0.03974755 0.04347755]\n",
      "[Validate] TP Loss Across Timepoints: [1.32728565 1.54388738]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70916327 0.8282207 ]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.03035803521052003, TP Loss: 1.6276998609304427\n",
      "[Validate] MAE Loss Across Timepoints: [0.03942613 0.04338623]\n",
      "[Validate] TP Loss Across Timepoints: [1.34205115 1.56132412]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73486261 0.86528382]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.029662252931545178, TP Loss: 1.5814008302986622\n",
      "[Validate] MAE Loss Across Timepoints: [0.03963235 0.04349571]\n",
      "[Validate] TP Loss Across Timepoints: [1.47200286 1.72415721]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77376699 0.93130967]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02943269017462929, TP Loss: 1.6034269178907077\n",
      "[Validate] MAE Loss Across Timepoints: [0.03947403 0.04340326]\n",
      "[Validate] TP Loss Across Timepoints: [1.4740386  1.74420702]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78591517 1.03579487]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.029026425909250975, TP Loss: 1.5462123446166516\n",
      "[Validate] MAE Loss Across Timepoints: [0.03901989 0.04277543]\n",
      "[Validate] TP Loss Across Timepoints: [1.38422823 1.58091843]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.76797116 0.94127953]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.028706969693303108, TP Loss: 1.5075972244143485\n",
      "[Validate] MAE Loss Across Timepoints: [0.03898924 0.04273437]\n",
      "[Validate] TP Loss Across Timepoints: [1.33120835 1.49912214]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.80687989 1.0057019 ]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.028609673120081426, TP Loss: 1.543976896504561\n",
      "[Validate] MAE Loss Across Timepoints: [0.03897629 0.04265958]\n",
      "[Validate] TP Loss Across Timepoints: [1.41974258 1.62464142]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78573137 1.03947899]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.028386932595943413, TP Loss: 1.497577421615521\n",
      "[Validate] MAE Loss Across Timepoints: [0.03871347 0.04246631]\n",
      "[Validate] TP Loss Across Timepoints: [1.35658121 1.55697227]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77374829 0.98824474]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.028342125937342644, TP Loss: 1.5395251378417014\n",
      "[Validate] MAE Loss Across Timepoints: [0.039016   0.04281683]\n",
      "[Validate] TP Loss Across Timepoints: [1.3897295  1.58374512]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82889305 1.27252508]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.0284147709608078, TP Loss: 1.5030149464805922\n",
      "[Validate] MAE Loss Across Timepoints: [0.03885477 0.04263473]\n",
      "[Validate] TP Loss Across Timepoints: [1.34606183 1.53628731]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.81995385 1.18136636]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.028186619793996216, TP Loss: 1.4996201418340207\n",
      "[Validate] MAE Loss Across Timepoints: [0.03858715 0.04225271]\n",
      "[Validate] TP Loss Across Timepoints: [1.30962098 1.47629929]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.80223511 1.16660929]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.028186692763119935, TP Loss: 1.4847482569515704\n",
      "[Validate] MAE Loss Across Timepoints: [0.03884546 0.04257388]\n",
      "[Validate] TP Loss Across Timepoints: [1.37605834 1.56641436]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77344672 1.25115413]\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.028156833940496048, TP Loss: 1.5029547490179538\n",
      "[Validate] MAE Loss Across Timepoints: [0.03854293 0.04214585]\n",
      "[Validate] TP Loss Across Timepoints: [1.33707952 1.51559496]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7477687  0.98447191]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.028110169696932037, TP Loss: 1.4978369812170664\n",
      "[Validate] MAE Loss Across Timepoints: [0.03886937 0.04259965]\n",
      "[Validate] TP Loss Across Timepoints: [1.39985514 1.59312952]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.76079024 1.01461585]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.028044155860940615, TP Loss: 1.4872385084629058\n",
      "[Validate] MAE Loss Across Timepoints: [0.03850622 0.04227674]\n",
      "[Validate] TP Loss Across Timepoints: [1.33481884 1.52630019]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79605736 1.21450272]\n",
      "\n",
      "epochs finished with time:199.84824562072754\n",
      "\n",
      "Current memory usage: 2095.66 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04000825 0.04349364]\n",
      "[Test] TP Loss Across Timepoints: [3.42084008 3.20533402]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.81994535 1.13249419]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_oasis.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = DeepTAGNet(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "\n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
