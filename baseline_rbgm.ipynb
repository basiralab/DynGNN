{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.model_rbgm import GNN_1\n",
    "from memory_capacity_utils import gen_lag_data, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=5, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learninng rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "#dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "#dataset = np.delete(dataset,88,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_rbgm/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03682604183268268, TP Loss: 3.3837401987984776\n",
      "[Validate] MAE Loss Across Timepoints: [0.04122445 0.0428788 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.05684853 1.31210148]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.38015679 0.6119313 ]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02663071137794759, TP Loss: 0.6869233723264188\n",
      "[Validate] MAE Loss Across Timepoints: [0.03861305 0.03962728]\n",
      "[Validate] TP Loss Across Timepoints: [0.92280698 1.10231352]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.41279375 0.69727783]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02573917221161537, TP Loss: 0.6513969583902508\n",
      "[Validate] MAE Loss Across Timepoints: [0.03794999 0.03910672]\n",
      "[Validate] TP Loss Across Timepoints: [0.89690578 1.08858001]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44465315 0.70993356]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02539616341528017, TP Loss: 0.6432515233755112\n",
      "[Validate] MAE Loss Across Timepoints: [0.03751182 0.03857562]\n",
      "[Validate] TP Loss Across Timepoints: [0.88339984 1.06486452]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48789249 0.74539212]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02514931066252757, TP Loss: 0.6393231116235256\n",
      "[Validate] MAE Loss Across Timepoints: [0.03721474 0.03827211]\n",
      "[Validate] TP Loss Across Timepoints: [0.87764883 1.05390978]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51995687 0.7650505 ]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024957824891316704, TP Loss: 0.6370145329274237\n",
      "[Validate] MAE Loss Across Timepoints: [0.03697883 0.03796776]\n",
      "[Validate] TP Loss Across Timepoints: [0.87302208 1.04168487]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55014234 0.77876712]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02479407961072866, TP Loss: 0.6349951836746186\n",
      "[Validate] MAE Loss Across Timepoints: [0.03678947 0.03770255]\n",
      "[Validate] TP Loss Across Timepoints: [0.87066424 1.03033221]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58591311 0.79524046]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02465617649431806, TP Loss: 0.633391285315156\n",
      "[Validate] MAE Loss Across Timepoints: [0.0366295  0.03753522]\n",
      "[Validate] TP Loss Across Timepoints: [0.86864799 1.0225389 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60463098 0.8050334 ]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02452876220922917, TP Loss: 0.6316806185059249\n",
      "[Validate] MAE Loss Across Timepoints: [0.03649566 0.03738214]\n",
      "[Validate] TP Loss Across Timepoints: [0.86698866 1.01190543]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62580807 0.80599535]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02442611855803989, TP Loss: 0.6304961699061096\n",
      "[Validate] MAE Loss Across Timepoints: [0.0363818  0.03723266]\n",
      "[Validate] TP Loss Across Timepoints: [0.86620647 1.0088613 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64442301 0.8054679 ]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.024330539352376945, TP Loss: 0.6289084777235985\n",
      "[Validate] MAE Loss Across Timepoints: [0.03627501 0.03704841]\n",
      "[Validate] TP Loss Across Timepoints: [0.86567754 1.00444913]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64705843 0.80982552]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.024245000502560288, TP Loss: 0.6279164671432227\n",
      "[Validate] MAE Loss Across Timepoints: [0.03618191 0.03694156]\n",
      "[Validate] TP Loss Across Timepoints: [0.86558574 1.00104725]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.644993   0.80946354]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024170407268684357, TP Loss: 0.6269240600522608\n",
      "[Validate] MAE Loss Across Timepoints: [0.03607969 0.03678745]\n",
      "[Validate] TP Loss Across Timepoints: [0.86576188 0.99961841]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63784131 0.81722254]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.024105939111905172, TP Loss: 0.625883900327608\n",
      "[Validate] MAE Loss Across Timepoints: [0.03601534 0.03668657]\n",
      "[Validate] TP Loss Across Timepoints: [0.86478168 0.99334186]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63920358 0.83668668]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02404539093549829, TP Loss: 0.6253762263804674\n",
      "[Validate] MAE Loss Across Timepoints: [0.03594258 0.03659715]\n",
      "[Validate] TP Loss Across Timepoints: [0.86587381 0.99279445]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64469213 0.85203116]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.023991267531528138, TP Loss: 0.6247777708340436\n",
      "[Validate] MAE Loss Across Timepoints: [0.03589257 0.03655681]\n",
      "[Validate] TP Loss Across Timepoints: [0.86584753 0.98968679]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64892288 0.8599022 ]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02394305737107061, TP Loss: 0.6241833525709808\n",
      "[Validate] MAE Loss Across Timepoints: [0.0358303 0.0364854]\n",
      "[Validate] TP Loss Across Timepoints: [0.86616051 0.98862004]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65765818 0.86324989]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.0238999202119885, TP Loss: 0.6237505916506052\n",
      "[Validate] MAE Loss Across Timepoints: [0.03578984 0.03640786]\n",
      "[Validate] TP Loss Across Timepoints: [0.86644089 0.9882496 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65800363 0.86454696]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023862918256781995, TP Loss: 0.6231941664591432\n",
      "[Validate] MAE Loss Across Timepoints: [0.03575509 0.03638123]\n",
      "[Validate] TP Loss Across Timepoints: [0.86615443 0.98552603]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65845292 0.86508059]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023827199460356496, TP Loss: 0.6226801672019064\n",
      "[Validate] MAE Loss Across Timepoints: [0.03571669 0.03631254]\n",
      "[Validate] TP Loss Across Timepoints: [0.86655027 0.9847675 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65727273 0.87007794]\n",
      "\n",
      "epochs finished with time:334.4996266365051\n",
      "\n",
      "Current memory usage: 2585.46 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03569282 0.03555596]\n",
      "[Test] TP Loss Across Timepoints: [0.91535349 0.91886873]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.53260123 0.75257818]\n",
      "------------------------------------Fold [2/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03586873919994105, TP Loss: 3.04155390849337\n",
      "[Validate] MAE Loss Across Timepoints: [0.04016747 0.0424893 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.0028435  1.17066824]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55757475 0.81092864]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.026345154023147188, TP Loss: 0.6816153710242361\n",
      "[Validate] MAE Loss Across Timepoints: [0.03797127 0.03973917]\n",
      "[Validate] TP Loss Across Timepoints: [0.95749789 1.07072961]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.50563719 0.83837579]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.025498746646917425, TP Loss: 0.6603848596569151\n",
      "[Validate] MAE Loss Across Timepoints: [0.03731747 0.03901021]\n",
      "[Validate] TP Loss Across Timepoints: [0.94190562 1.05410588]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56323992 0.82650914]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.025155493960483, TP Loss: 0.6546091616619378\n",
      "[Validate] MAE Loss Across Timepoints: [0.03687398 0.03823366]\n",
      "[Validate] TP Loss Across Timepoints: [0.93666857 1.03919005]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59960589 0.85234901]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02492077501665335, TP Loss: 0.6523999568307772\n",
      "[Validate] MAE Loss Across Timepoints: [0.03662865 0.03787294]\n",
      "[Validate] TP Loss Across Timepoints: [0.93556839 1.03324306]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61795675 0.88298884]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024730309000005946, TP Loss: 0.6487337814178318\n",
      "[Validate] MAE Loss Across Timepoints: [0.0366329  0.03796059]\n",
      "[Validate] TP Loss Across Timepoints: [0.93744886 1.03818786]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59340144 0.89749577]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02459762127546128, TP Loss: 0.6480688051087782\n",
      "[Validate] MAE Loss Across Timepoints: [0.03632167 0.03758802]\n",
      "[Validate] TP Loss Across Timepoints: [0.93680161 1.03604841]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60812164 0.89676873]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.024473334866343066, TP Loss: 0.6467481235740706\n",
      "[Validate] MAE Loss Across Timepoints: [0.0361185  0.03727023]\n",
      "[Validate] TP Loss Across Timepoints: [0.93626398 1.02931988]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61676676 0.90698748]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024367355086724274, TP Loss: 0.6448173386743292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03605402 0.03725576]\n",
      "[Validate] TP Loss Across Timepoints: [0.93740278 1.02865267]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6166974  0.92066734]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.024281291814986616, TP Loss: 0.6443390226922929\n",
      "[Validate] MAE Loss Across Timepoints: [0.03596595 0.03709522]\n",
      "[Validate] TP Loss Across Timepoints: [0.93705809 1.02486539]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63312446 0.93238182]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02420118171721697, TP Loss: 0.6436248924583197\n",
      "[Validate] MAE Loss Across Timepoints: [0.03589679 0.03700668]\n",
      "[Validate] TP Loss Across Timepoints: [0.93607408 1.02048945]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64500465 0.93886763]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.024131237238179892, TP Loss: 0.6429999399697408\n",
      "[Validate] MAE Loss Across Timepoints: [0.03580323 0.03691182]\n",
      "[Validate] TP Loss Across Timepoints: [0.93690407 1.021222  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65019011 0.94391499]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024072881846223027, TP Loss: 0.6423612023936585\n",
      "[Validate] MAE Loss Across Timepoints: [0.03572677 0.03685742]\n",
      "[Validate] TP Loss Across Timepoints: [0.93845129 1.02370334]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65422444 0.94942614]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02402053971309215, TP Loss: 0.6420625693863258\n",
      "[Validate] MAE Loss Across Timepoints: [0.03564447 0.03672037]\n",
      "[Validate] TP Loss Across Timepoints: [0.93890804 1.02128255]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65565178 0.95745604]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.023973740258952603, TP Loss: 0.6414916615467519\n",
      "[Validate] MAE Loss Across Timepoints: [0.03561578 0.03671318]\n",
      "[Validate] TP Loss Across Timepoints: [0.93980414 1.02317274]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65086668 0.96313915]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.023933871401823126, TP Loss: 0.6413651009788737\n",
      "[Validate] MAE Loss Across Timepoints: [0.03552632 0.03655764]\n",
      "[Validate] TP Loss Across Timepoints: [0.93987358 1.0195334 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6548657  0.96632567]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.023897195918834768, TP Loss: 0.6407619051169604\n",
      "[Validate] MAE Loss Across Timepoints: [0.03553943 0.03661951]\n",
      "[Validate] TP Loss Across Timepoints: [0.94039452 1.02454722]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65146693 0.96818294]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02386590896639973, TP Loss: 0.6403777177911252\n",
      "[Validate] MAE Loss Across Timepoints: [0.03549944 0.03659825]\n",
      "[Validate] TP Loss Across Timepoints: [0.94116575 1.02462614]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65348447 0.97039101]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023833955958252773, TP Loss: 0.6400855077663437\n",
      "[Validate] MAE Loss Across Timepoints: [0.0354775 0.0365809]\n",
      "[Validate] TP Loss Across Timepoints: [0.94087583 1.02214587]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65941712 0.97000047]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023809216043446213, TP Loss: 0.6396986197214574\n",
      "[Validate] MAE Loss Across Timepoints: [0.03544771 0.03656332]\n",
      "[Validate] TP Loss Across Timepoints: [0.9426803  1.02547538]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65599739 0.96926649]\n",
      "\n",
      "epochs finished with time:335.3865599632263\n",
      "\n",
      "Current memory usage: 2585.46 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03521741 0.0371354 ]\n",
      "[Test] TP Loss Across Timepoints: [0.75680904 1.02696209]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.60799359 0.89176711]\n",
      "------------------------------------Fold [3/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.035845701131620444, TP Loss: 2.9040417266078293\n",
      "[Validate] MAE Loss Across Timepoints: [0.04190514 0.04504991]\n",
      "[Validate] TP Loss Across Timepoints: [1.05439985 1.49836171]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.38665063 0.44893161]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02630838507320732, TP Loss: 0.6577312720473856\n",
      "[Validate] MAE Loss Across Timepoints: [0.03878882 0.03948624]\n",
      "[Validate] TP Loss Across Timepoints: [0.92975914 1.12691784]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42935194 0.67938914]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.025283193070208654, TP Loss: 0.6238133974839002\n",
      "[Validate] MAE Loss Across Timepoints: [0.03804222 0.03872009]\n",
      "[Validate] TP Loss Across Timepoints: [0.9073652  1.09322143]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45558192 0.70327   ]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02489497717760969, TP Loss: 0.6151054254733026\n",
      "[Validate] MAE Loss Across Timepoints: [0.03753962 0.03822583]\n",
      "[Validate] TP Loss Across Timepoints: [0.89856732 1.07788098]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.454653   0.75558345]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02462032342737075, TP Loss: 0.610528617631644\n",
      "[Validate] MAE Loss Across Timepoints: [0.03715934 0.03800537]\n",
      "[Validate] TP Loss Across Timepoints: [0.89448088 1.07062948]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4649216  0.79129263]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024447203599265777, TP Loss: 0.6089243465103209\n",
      "[Validate] MAE Loss Across Timepoints: [0.03699088 0.03776285]\n",
      "[Validate] TP Loss Across Timepoints: [0.89807391 1.07423007]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47369018 0.8385994 ]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.024291028661536984, TP Loss: 0.6072391127236187\n",
      "[Validate] MAE Loss Across Timepoints: [0.03679362 0.03760852]\n",
      "[Validate] TP Loss Across Timepoints: [0.89901292 1.07805181]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47375279 0.86852035]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.0241964978777105, TP Loss: 0.6039436177816242\n",
      "[Validate] MAE Loss Across Timepoints: [0.03658763 0.03736262]\n",
      "[Validate] TP Loss Across Timepoints: [0.89760989 1.07209909]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48731102 0.86497625]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024017620424274355, TP Loss: 0.6019340320490301\n",
      "[Validate] MAE Loss Across Timepoints: [0.03645856 0.03724357]\n",
      "[Validate] TP Loss Across Timepoints: [0.90055275 1.07854056]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48811983 0.88599944]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.023918318533105776, TP Loss: 0.6007773361634463\n",
      "[Validate] MAE Loss Across Timepoints: [0.03634522 0.03706788]\n",
      "[Validate] TP Loss Across Timepoints: [0.90017086 1.07684255]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.50119391 0.90533154]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.023836901440517977, TP Loss: 0.599676616024226\n",
      "[Validate] MAE Loss Across Timepoints: [0.03625321 0.03697753]\n",
      "[Validate] TP Loss Across Timepoints: [0.89885861 1.07372713]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.50348969 0.90422895]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.023765665435348637, TP Loss: 0.5987056127050892\n",
      "[Validate] MAE Loss Across Timepoints: [0.03617075 0.03679099]\n",
      "[Validate] TP Loss Across Timepoints: [0.89738512 1.06409383]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51570361 0.90060749]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02370196013362147, TP Loss: 0.5978893253486603\n",
      "[Validate] MAE Loss Across Timepoints: [0.0361007  0.03674945]\n",
      "[Validate] TP Loss Across Timepoints: [0.89829302 1.06654954]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52018039 0.89587588]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02364727613166906, TP Loss: 0.5969785149209201\n",
      "[Validate] MAE Loss Across Timepoints: [0.0360388  0.03669516]\n",
      "[Validate] TP Loss Across Timepoints: [0.89642    1.06349266]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51579447 0.8945641 ]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.023598940228112042, TP Loss: 0.5961339148925617\n",
      "[Validate] MAE Loss Across Timepoints: [0.03598619 0.03662607]\n",
      "[Validate] TP Loss Across Timepoints: [0.89559424 1.06114686]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51774047 0.8996249 ]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.023555896332254633, TP Loss: 0.595648527611047\n",
      "[Validate] MAE Loss Across Timepoints: [0.03593597 0.03656569]\n",
      "[Validate] TP Loss Across Timepoints: [0.89583206 1.06206405]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52283539 0.89493212]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02351687930058688, TP Loss: 0.5950030180392787\n",
      "[Validate] MAE Loss Across Timepoints: [0.03590028 0.03653362]\n",
      "[Validate] TP Loss Across Timepoints: [0.89372885 1.0524503 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53493061 0.89902692]\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.02348191328928806, TP Loss: 0.594493483309634\n",
      "[Validate] MAE Loss Across Timepoints: [0.03585854 0.03647979]\n",
      "[Validate] TP Loss Across Timepoints: [0.89372218 1.05297899]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53011006 0.89177741]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023452922381693497, TP Loss: 0.5940079973079264\n",
      "[Validate] MAE Loss Across Timepoints: [0.03580878 0.03643662]\n",
      "[Validate] TP Loss Across Timepoints: [0.8945024  1.05466413]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52740076 0.89018551]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02342271506495308, TP Loss: 0.5934306741692126\n",
      "[Validate] MAE Loss Across Timepoints: [0.03578483 0.03638846]\n",
      "[Validate] TP Loss Across Timepoints: [0.89095449 1.04351318]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53529287 0.88866159]\n",
      "\n",
      "epochs finished with time:336.5433440208435\n",
      "\n",
      "Current memory usage: 2591.21 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.0346663 0.0371241]\n",
      "[Test] TP Loss Across Timepoints: [0.89797487 1.18694248]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.40772531 0.87107892]\n",
      "------------------------------------Fold [4/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03707956998550799, TP Loss: 3.368605009280145\n",
      "[Validate] MAE Loss Across Timepoints: [0.04157664 0.04584305]\n",
      "[Validate] TP Loss Across Timepoints: [0.99540251 1.2666111 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43793611 0.77347999]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.027479095209855586, TP Loss: 0.7101334549952298\n",
      "[Validate] MAE Loss Across Timepoints: [0.0398148 0.0437188]\n",
      "[Validate] TP Loss Across Timepoints: [0.91565859 1.17867017]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.50781792 0.82230486]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02674660515913274, TP Loss: 0.6791333255823702\n",
      "[Validate] MAE Loss Across Timepoints: [0.03878152 0.04161293]\n",
      "[Validate] TP Loss Across Timepoints: [0.88705385 1.10150015]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.37000867 0.85716379]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02593653964868281, TP Loss: 0.6578721725381911\n",
      "[Validate] MAE Loss Across Timepoints: [0.03804723 0.04054669]\n",
      "[Validate] TP Loss Across Timepoints: [0.87929797 1.06560314]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42196351 0.86678947]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.025700838727061637, TP Loss: 0.6543256242293864\n",
      "[Validate] MAE Loss Across Timepoints: [0.0378071  0.04024549]\n",
      "[Validate] TP Loss Across Timepoints: [0.8783108  1.05429721]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42371534 0.86715617]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02553666829771828, TP Loss: 0.6522149192169309\n",
      "[Validate] MAE Loss Across Timepoints: [0.03763186 0.03995788]\n",
      "[Validate] TP Loss Across Timepoints: [0.87802356 1.04118228]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44408845 0.86639906]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02539994775725063, TP Loss: 0.6496402914635837\n",
      "[Validate] MAE Loss Across Timepoints: [0.03748189 0.03971146]\n",
      "[Validate] TP Loss Across Timepoints: [0.8776269  1.03268015]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45437297 0.87076857]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.025288342832936905, TP Loss: 0.647926282370463\n",
      "[Validate] MAE Loss Across Timepoints: [0.03736039 0.03949614]\n",
      "[Validate] TP Loss Across Timepoints: [0.87732321 1.02257681]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47492318 0.89425523]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.025192796820192598, TP Loss: 0.6465077495668083\n",
      "[Validate] MAE Loss Across Timepoints: [0.03724143 0.0393381 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.87695235 1.01380491]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48517145 0.89598941]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.025106885921559297, TP Loss: 0.6452798717655241\n",
      "[Validate] MAE Loss Across Timepoints: [0.03716662 0.03917381]\n",
      "[Validate] TP Loss Across Timepoints: [0.87836212 1.01163495]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4906386  0.90348877]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.025038511856109835, TP Loss: 0.6438444869127125\n",
      "[Validate] MAE Loss Across Timepoints: [0.03711504 0.03904521]\n",
      "[Validate] TP Loss Across Timepoints: [0.87894148 1.00747812]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51077702 0.94739825]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.0249752942181658, TP Loss: 0.6426768728997558\n",
      "[Validate] MAE Loss Across Timepoints: [0.0370443  0.03894284]\n",
      "[Validate] TP Loss Across Timepoints: [0.88053203 1.00489962]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51433422 0.95937715]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02492465167597402, TP Loss: 0.6422128148842603\n",
      "[Validate] MAE Loss Across Timepoints: [0.03700219 0.03884418]\n",
      "[Validate] TP Loss Across Timepoints: [0.87973922 0.99688911]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52585327 0.94043322]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.024876800074707717, TP Loss: 0.6413554244209081\n",
      "[Validate] MAE Loss Across Timepoints: [0.03695343 0.03880325]\n",
      "[Validate] TP Loss Across Timepoints: [0.87916958 0.98780781]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52698393 0.92764253]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.024838095239829272, TP Loss: 0.6409601510968059\n",
      "[Validate] MAE Loss Across Timepoints: [0.03690613 0.0387712 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.87998104 0.98314381]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53723722 0.92972342]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02480285451747477, TP Loss: 0.6405367967672646\n",
      "[Validate] MAE Loss Across Timepoints: [0.0368752  0.03870803]\n",
      "[Validate] TP Loss Across Timepoints: [0.87945461 0.97908902]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5534701  0.94234472]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.024770891628577374, TP Loss: 0.6400366311427206\n",
      "[Validate] MAE Loss Across Timepoints: [0.03684877 0.03867134]\n",
      "[Validate] TP Loss Across Timepoints: [0.88038951 0.97660476]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53901754 0.96864526]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02474119588441681, TP Loss: 0.6395736725535244\n",
      "[Validate] MAE Loss Across Timepoints: [0.03682416 0.03864603]\n",
      "[Validate] TP Loss Across Timepoints: [0.87993401 0.97284037]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56825137 0.97707898]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02472018163825851, TP Loss: 0.6392787173390388\n",
      "[Validate] MAE Loss Across Timepoints: [0.03679979 0.03861634]\n",
      "[Validate] TP Loss Across Timepoints: [0.88091773 0.97190446]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5850233  0.97302541]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.024695014973985963, TP Loss: 0.6387593359686434\n",
      "[Validate] MAE Loss Across Timepoints: [0.03677561 0.0385718 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.88157541 0.97088951]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57503668 0.93882092]\n",
      "\n",
      "epochs finished with time:335.91599893569946\n",
      "\n",
      "Current memory usage: 2591.21 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03633716 0.03993356]\n",
      "[Test] TP Loss Across Timepoints: [0.85853119 1.13039827]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.49010082 0.99412661]\n",
      "------------------------------------Fold [5/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.0363127090386115, TP Loss: 3.3845067352522165\n",
      "[Validate] MAE Loss Across Timepoints: [0.03914249 0.04285005]\n",
      "[Validate] TP Loss Across Timepoints: [0.95883268 1.34022295]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33603804 0.64586509]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.025656007666839287, TP Loss: 0.6471084784716368\n",
      "[Validate] MAE Loss Across Timepoints: [0.03687111 0.03942597]\n",
      "[Validate] TP Loss Across Timepoints: [0.86260122 1.1316992 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44571753 0.74367918]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.024940248782513663, TP Loss: 0.6205498740309849\n",
      "[Validate] MAE Loss Across Timepoints: [0.03625202 0.03873625]\n",
      "[Validate] TP Loss Across Timepoints: [0.85028535 1.112849  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48890418 0.76758654]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.024619306685053743, TP Loss: 0.6136225635418668\n",
      "[Validate] MAE Loss Across Timepoints: [0.03588824 0.0383699 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.84906304 1.11136055]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51245353 0.78724735]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.024400238995440304, TP Loss: 0.6111914520151913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03564788 0.03808855]\n",
      "[Validate] TP Loss Across Timepoints: [0.8493067  1.10811305]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54488765 0.80380509]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024228052992839366, TP Loss: 0.6091534590814263\n",
      "[Validate] MAE Loss Across Timepoints: [0.03545565 0.03781583]\n",
      "[Validate] TP Loss Across Timepoints: [0.84969682 1.1008476 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55822966 0.82393428]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.024085988057777286, TP Loss: 0.6072659423807636\n",
      "[Validate] MAE Loss Across Timepoints: [0.03529755 0.03761618]\n",
      "[Validate] TP Loss Across Timepoints: [0.85007966 1.09794092]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56909256 0.84102008]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.023964504696778022, TP Loss: 0.6056799817597494\n",
      "[Validate] MAE Loss Across Timepoints: [0.03516733 0.03743337]\n",
      "[Validate] TP Loss Across Timepoints: [0.85091448 1.09196174]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59143298 0.85293876]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02386288055276964, TP Loss: 0.6043634417001158\n",
      "[Validate] MAE Loss Across Timepoints: [0.0350551  0.03724644]\n",
      "[Validate] TP Loss Across Timepoints: [0.85179043 1.08997798]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59968369 0.86491101]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.023775263471179642, TP Loss: 0.6032649262342602\n",
      "[Validate] MAE Loss Across Timepoints: [0.03495104 0.03711371]\n",
      "[Validate] TP Loss Across Timepoints: [0.85312456 1.0874815 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61704981 0.88033446]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.023700384437688626, TP Loss: 0.6023119892925024\n",
      "[Validate] MAE Loss Across Timepoints: [0.03487064 0.03704325]\n",
      "[Validate] TP Loss Across Timepoints: [0.85353827 1.08647954]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62878852 0.87916014]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.023631444608327, TP Loss: 0.6015018266625702\n",
      "[Validate] MAE Loss Across Timepoints: [0.0347972  0.03695469]\n",
      "[Validate] TP Loss Across Timepoints: [0.85447145 1.08694983]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63896505 0.88636866]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.023575318497023545, TP Loss: 0.6008952824631706\n",
      "[Validate] MAE Loss Across Timepoints: [0.03473447 0.03684016]\n",
      "[Validate] TP Loss Across Timepoints: [0.85548806 1.0857265 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64610975 0.88765199]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.023525803771917708, TP Loss: 0.6001810691086575\n",
      "[Validate] MAE Loss Across Timepoints: [0.03471677 0.0367902 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.85635889 1.08370042]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65255666 0.87682127]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02348194405203685, TP Loss: 0.5997641417197883\n",
      "[Validate] MAE Loss Across Timepoints: [0.03466925 0.03672618]\n",
      "[Validate] TP Loss Across Timepoints: [0.85732919 1.08663988]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65458243 0.86109247]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.023442396020982414, TP Loss: 0.599422098021023\n",
      "[Validate] MAE Loss Across Timepoints: [0.03462644 0.03665557]\n",
      "[Validate] TP Loss Across Timepoints: [0.85784227 1.08659971]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65758104 0.85696168]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.023409714951412752, TP Loss: 0.5990581187652424\n",
      "[Validate] MAE Loss Across Timepoints: [0.03463053 0.03669927]\n",
      "[Validate] TP Loss Across Timepoints: [0.85855633 1.08847964]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66420404 0.87101588]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.023378685815259814, TP Loss: 0.5984896160662174\n",
      "[Validate] MAE Loss Across Timepoints: [0.03459046 0.03655278]\n",
      "[Validate] TP Loss Across Timepoints: [0.85944378 1.08676898]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66012642 0.84833077]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023349893905106, TP Loss: 0.5982639027060941\n",
      "[Validate] MAE Loss Across Timepoints: [0.03457265 0.03652269]\n",
      "[Validate] TP Loss Across Timepoints: [0.86017954 1.08850682]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6623409  0.85278918]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023326081587583758, TP Loss: 0.5980569300008938\n",
      "[Validate] MAE Loss Across Timepoints: [0.03454932 0.03649911]\n",
      "[Validate] TP Loss Across Timepoints: [0.86107981 1.09194684]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6547393  0.84933436]\n",
      "\n",
      "epochs finished with time:334.4753737449646\n",
      "\n",
      "Current memory usage: 2591.21 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03686985 0.03765171]\n",
      "[Test] TP Loss Across Timepoints: [0.95109921 1.15473976]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.66650861 0.82200963]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_2.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = GNN_1(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "       \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
