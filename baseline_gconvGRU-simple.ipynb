{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU_simple import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "dataset = np.delete(dataset,88,axis=0)\n",
    "\n",
    "# dataset = np.load(\"multivariate_simulation_data_3.npy\")\n",
    "# dataset = torch.from_numpy(dataset).squeeze()\n",
    "# dataset = dataset.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=3, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learninng rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_t/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04047726597636938, TP Loss: 2.7933480749527613\n",
      "[Validate] MAE Loss Across Timepoints: [0.05328962 0.03976158]\n",
      "[Validate] TP Loss Across Timepoints: [7.43238932 1.06244106]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52534905 0.47694714]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.03140417902419965, TP Loss: 1.8092364107569059\n",
      "[Validate] MAE Loss Across Timepoints: [0.05153271 0.0385108 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.2849645  0.95206788]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45077817 0.65922807]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03016704609617591, TP Loss: 1.7796531741817792\n",
      "[Validate] MAE Loss Across Timepoints: [0.05114193 0.03807404]\n",
      "[Validate] TP Loss Across Timepoints: [7.28689067 0.92457956]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4611794  0.65127847]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.0295861534619083, TP Loss: 1.7682382089396318\n",
      "[Validate] MAE Loss Across Timepoints: [0.05087974 0.03768343]\n",
      "[Validate] TP Loss Across Timepoints: [7.27026164 0.9221866 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47594579 0.58038912]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.029139918088912965, TP Loss: 1.7729418374598027\n",
      "[Validate] MAE Loss Across Timepoints: [0.05103684 0.03771375]\n",
      "[Validate] TP Loss Across Timepoints: [7.37925873 0.93817501]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45734262 0.57167208]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02890475777288278, TP Loss: 1.7618385871251425\n",
      "[Validate] MAE Loss Across Timepoints: [0.05089609 0.0375525 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.50942027 0.98096612]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.40208785 0.58085438]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.028690470832710466, TP Loss: 1.744155482451121\n",
      "[Validate] MAE Loss Across Timepoints: [0.05101149 0.03745497]\n",
      "[Validate] TP Loss Across Timepoints: [7.4814799  0.95381546]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43023287 0.65264251]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.028398997507368524, TP Loss: 1.7085297224422296\n",
      "[Validate] MAE Loss Across Timepoints: [0.05071183 0.03782541]\n",
      "[Validate] TP Loss Across Timepoints: [7.36962026 0.95304597]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45775485 0.6504862 ]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.028308094789584477, TP Loss: 1.7176765489081542\n",
      "[Validate] MAE Loss Across Timepoints: [0.05068225 0.03754479]\n",
      "[Validate] TP Loss Across Timepoints: [7.53386383 0.99247913]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.40854333 0.59576633]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02814171913390358, TP Loss: 1.695061873892943\n",
      "[Validate] MAE Loss Across Timepoints: [0.05064518 0.03771574]\n",
      "[Validate] TP Loss Across Timepoints: [7.44881897 0.98404554]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43419096 0.61154258]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.0280924660153687, TP Loss: 1.6827263034880162\n",
      "[Validate] MAE Loss Across Timepoints: [0.05051627 0.03753973]\n",
      "[Validate] TP Loss Across Timepoints: [7.42312826 0.96846619]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.41541231 0.58972153]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.0280514899486055, TP Loss: 1.7075351521372795\n",
      "[Validate] MAE Loss Across Timepoints: [0.05052738 0.03755575]\n",
      "[Validate] TP Loss Across Timepoints: [7.40264435 0.96741835]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4351025  0.61369883]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.027831190017362437, TP Loss: 1.663258327295383\n",
      "[Validate] MAE Loss Across Timepoints: [0.05051167 0.03767786]\n",
      "[Validate] TP Loss Across Timepoints: [7.3772644  0.94662361]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44849243 0.64701992]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.027950626146048308, TP Loss: 1.6969513778885206\n",
      "[Validate] MAE Loss Across Timepoints: [0.05049968 0.03791566]\n",
      "[Validate] TP Loss Across Timepoints: [7.39755809 0.97441966]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4718513  0.67397175]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.027852499407405654, TP Loss: 1.6746275818596283\n",
      "[Validate] MAE Loss Across Timepoints: [0.05052181 0.03754541]\n",
      "[Validate] TP Loss Across Timepoints: [7.49449666 0.98437138]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45457391 0.61218836]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02769843377172947, TP Loss: 1.6920584805309773\n",
      "[Validate] MAE Loss Across Timepoints: [0.05028934 0.03749242]\n",
      "[Validate] TP Loss Across Timepoints: [7.45285288 0.96377563]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42231987 0.61065626]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02768697120870153, TP Loss: 1.6681507552663486\n",
      "[Validate] MAE Loss Across Timepoints: [0.05045243 0.03757107]\n",
      "[Validate] TP Loss Across Timepoints: [7.52030131 0.99992167]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43518613 0.61670618]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.027684622102727492, TP Loss: 1.666122109691302\n",
      "[Validate] MAE Loss Across Timepoints: [0.05045558 0.03768   ]\n",
      "[Validate] TP Loss Across Timepoints: [7.52318319 1.01118609]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44644829 0.67614202]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.027478840233137212, TP Loss: 1.6414859478672346\n",
      "[Validate] MAE Loss Across Timepoints: [0.05054199 0.03772639]\n",
      "[Validate] TP Loss Across Timepoints: [7.46235809 1.00858428]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.37673982 0.56905013]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02758134373774131, TP Loss: 1.6646379905442397\n",
      "[Validate] MAE Loss Across Timepoints: [0.05016309 0.03750063]\n",
      "[Validate] TP Loss Across Timepoints: [7.40823313 0.98567333]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43781682 0.65259621]\n",
      "\n",
      "epochs finished with time:178.28541731834412\n",
      "\n",
      "Current memory usage: 3317.88 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03537279 0.04013096]\n",
      "[Test] TP Loss Across Timepoints: [0.99349323 1.59587459]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.57613729 0.57193678]\n",
      "------------------------------------Fold [2/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.037785658271362384, TP Loss: 1.987805262207985\n",
      "[Validate] MAE Loss Across Timepoints: [0.0506271  0.04820367]\n",
      "[Validate] TP Loss Across Timepoints: [7.29323222 2.57953161]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44387737 0.62023555]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.028922048055877288, TP Loss: 1.3289916401108106\n",
      "[Validate] MAE Loss Across Timepoints: [0.04900261 0.04576641]\n",
      "[Validate] TP Loss Across Timepoints: [7.18491567 2.3060084 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.40601347 0.44980986]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.027764080123354993, TP Loss: 1.283231541266044\n",
      "[Validate] MAE Loss Across Timepoints: [0.04779756 0.04367313]\n",
      "[Validate] TP Loss Across Timepoints: [6.92477926 2.01371282]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43805042 0.39420962]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.027133254210154216, TP Loss: 1.2367125389476616\n",
      "[Validate] MAE Loss Across Timepoints: [0.0472468  0.04262183]\n",
      "[Validate] TP Loss Across Timepoints: [6.74861348 1.82602946]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4293022  0.37699066]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02676574923098087, TP Loss: 1.2301012588044007\n",
      "[Validate] MAE Loss Across Timepoints: [0.04776925 0.04400414]\n",
      "[Validate] TP Loss Across Timepoints: [7.04828949 2.09631704]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.39859123 0.34304167]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.026432513538748027, TP Loss: 1.210840155556798\n",
      "[Validate] MAE Loss Across Timepoints: [0.04715169 0.04271333]\n",
      "[Validate] TP Loss Across Timepoints: [6.87654724 1.8677578 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51001532 0.37975454]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.026325872788826626, TP Loss: 1.211754364023606\n",
      "[Validate] MAE Loss Across Timepoints: [0.04710594 0.04290143]\n",
      "[Validate] TP Loss Across Timepoints: [6.83454488 1.87465235]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.46639034 0.41660923]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02616601108262936, TP Loss: 1.191208816319704\n",
      "[Validate] MAE Loss Across Timepoints: [0.0471609  0.04284836]\n",
      "[Validate] TP Loss Across Timepoints: [6.93819478 1.920725  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.41533978 0.37221635]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02611128504698475, TP Loss: 1.1968807871143023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.04732082 0.04342159]\n",
      "[Validate] TP Loss Across Timepoints: [7.06113434 2.02854589]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45586485 0.40646846]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02594663224493464, TP Loss: 1.1866750836372375\n",
      "[Validate] MAE Loss Across Timepoints: [0.04726782 0.04351747]\n",
      "[Validate] TP Loss Across Timepoints: [6.96811574 1.990264  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42999338 0.38307034]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.025910249321411054, TP Loss: 1.1851562534769375\n",
      "[Validate] MAE Loss Across Timepoints: [0.04713336 0.04304344]\n",
      "[Validate] TP Loss Across Timepoints: [6.98820292 1.93671964]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.44407625 0.42377413]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.025763408405085404, TP Loss: 1.1834316648542882\n",
      "[Validate] MAE Loss Across Timepoints: [0.04702867 0.04288356]\n",
      "[Validate] TP Loss Across Timepoints: [6.93155111 1.92898407]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42599231 0.4143895 ]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.025699339030931394, TP Loss: 1.154451601455609\n",
      "[Validate] MAE Loss Across Timepoints: [0.04667524 0.0424941 ]\n",
      "[Validate] TP Loss Across Timepoints: [6.80835978 1.80686353]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48420281 0.4010785 ]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.0256602397809426, TP Loss: 1.1759896675745647\n",
      "[Validate] MAE Loss Across Timepoints: [0.04685413 0.04288214]\n",
      "[Validate] TP Loss Across Timepoints: [6.93172048 1.91446711]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4789416  0.49603627]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.025620897517850003, TP Loss: 1.1716019997994105\n",
      "[Validate] MAE Loss Across Timepoints: [0.04688829 0.04302556]\n",
      "[Validate] TP Loss Across Timepoints: [6.99043935 1.95530523]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48793865 0.37234275]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02560564372688532, TP Loss: 1.1637646712362766\n",
      "[Validate] MAE Loss Across Timepoints: [0.04709485 0.04353116]\n",
      "[Validate] TP Loss Across Timepoints: [7.04871318 2.02859891]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4980555  0.42486477]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.0256017635576427, TP Loss: 1.187109464406967\n",
      "[Validate] MAE Loss Across Timepoints: [0.04678115 0.04301639]\n",
      "[Validate] TP Loss Across Timepoints: [6.93317668 1.91854375]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.42996315 0.44778694]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02541801566258073, TP Loss: 1.1511205977449814\n",
      "[Validate] MAE Loss Across Timepoints: [0.04679228 0.04303282]\n",
      "[Validate] TP Loss Across Timepoints: [6.94344838 1.94659538]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.46976697 0.38106776]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.025419191922992468, TP Loss: 1.1561525764564673\n",
      "[Validate] MAE Loss Across Timepoints: [0.04651998 0.04284629]\n",
      "[Validate] TP Loss Across Timepoints: [6.89975026 1.90171979]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47267583 0.47464867]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.025323529820889236, TP Loss: 1.1534488085657357\n",
      "[Validate] MAE Loss Across Timepoints: [0.04662571 0.0431254 ]\n",
      "[Validate] TP Loss Across Timepoints: [6.89044749 1.90386111]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47088742 0.45195193]\n",
      "\n",
      "epochs finished with time:177.55358123779297\n",
      "\n",
      "Current memory usage: 3316.64 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04215918 0.04754254]\n",
      "[Test] TP Loss Across Timepoints: [2.24828298 4.14479667]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.5636614  0.55054961]\n",
      "------------------------------------Fold [3/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.038192347747584184, TP Loss: 2.4307788096368315\n",
      "[Validate] MAE Loss Across Timepoints: [0.04015288 0.04358755]\n",
      "[Validate] TP Loss Across Timepoints: [1.35933721 1.7184236 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58081473 0.62540493]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.030255142506211995, TP Loss: 1.5990782782435418\n",
      "[Validate] MAE Loss Across Timepoints: [0.0398701  0.04289857]\n",
      "[Validate] TP Loss Across Timepoints: [1.35326231 1.58427727]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64345939 0.67137126]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.028996956751992306, TP Loss: 1.552678509304921\n",
      "[Validate] MAE Loss Across Timepoints: [0.03927898 0.04243924]\n",
      "[Validate] TP Loss Across Timepoints: [1.36978447 1.58965278]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55457187 0.56832329]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02832185843338569, TP Loss: 1.4843185049792131\n",
      "[Validate] MAE Loss Across Timepoints: [0.03950509 0.04279607]\n",
      "[Validate] TP Loss Across Timepoints: [1.38012755 1.61168122]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57693383 0.70107537]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.028162463614717127, TP Loss: 1.4977637968957425\n",
      "[Validate] MAE Loss Across Timepoints: [0.03933486 0.04268745]\n",
      "[Validate] TP Loss Across Timepoints: [1.43145847 1.65371776]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54623029 0.59776719]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.027873444246749084, TP Loss: 1.4873918198049068\n",
      "[Validate] MAE Loss Across Timepoints: [0.03893881 0.04211966]\n",
      "[Validate] TP Loss Across Timepoints: [1.32577646 1.52520955]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6125481  0.61754036]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.027636244908596078, TP Loss: 1.462351737668117\n",
      "[Validate] MAE Loss Across Timepoints: [0.03909068 0.04234998]\n",
      "[Validate] TP Loss Across Timepoints: [1.3748101  1.58545506]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59554917 0.60057637]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.027624957278991738, TP Loss: 1.4640622969716788\n",
      "[Validate] MAE Loss Across Timepoints: [0.03891744 0.04215602]\n",
      "[Validate] TP Loss Across Timepoints: [1.37622082 1.56277907]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63193169 0.64877779]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.027387865399941803, TP Loss: 1.4590604116519292\n",
      "[Validate] MAE Loss Across Timepoints: [0.03905953 0.04222112]\n",
      "[Validate] TP Loss Across Timepoints: [1.3580898  1.55818152]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62179964 0.69066235]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02735246540978551, TP Loss: 1.445870528742671\n",
      "[Validate] MAE Loss Across Timepoints: [0.0390803 0.0423046]\n",
      "[Validate] TP Loss Across Timepoints: [1.36168957 1.54589427]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62674231 0.66069132]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.027309215410302082, TP Loss: 1.4567621807257334\n",
      "[Validate] MAE Loss Across Timepoints: [0.03864651 0.04182837]\n",
      "[Validate] TP Loss Across Timepoints: [1.30327988 1.46507502]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61571329 0.67378688]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02712920242920518, TP Loss: 1.4259650311122338\n",
      "[Validate] MAE Loss Across Timepoints: [0.03859115 0.04175942]\n",
      "[Validate] TP Loss Across Timepoints: [1.31675065 1.48073399]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62332404 0.68706209]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.027105912767971554, TP Loss: 1.4618849689761797\n",
      "[Validate] MAE Loss Across Timepoints: [0.03859408 0.0419695 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.31171823 1.50141311]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62438321 0.63544288]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02699586582990984, TP Loss: 1.4360213063657283\n",
      "[Validate] MAE Loss Across Timepoints: [0.03858675 0.04200934]\n",
      "[Validate] TP Loss Across Timepoints: [1.32151794 1.50255489]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56390755 0.58574211]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.026886534535636504, TP Loss: 1.4143735714256764\n",
      "[Validate] MAE Loss Across Timepoints: [0.03872028 0.0419535 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.29717016 1.46192408]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56591112 0.62640371]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.026974282739683986, TP Loss: 1.4017291039228439\n",
      "[Validate] MAE Loss Across Timepoints: [0.0383775  0.04176723]\n",
      "[Validate] TP Loss Across Timepoints: [1.27642858 1.47157037]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60125755 0.67760692]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02679691567706565, TP Loss: 1.410341802984476\n",
      "[Validate] MAE Loss Across Timepoints: [0.03859245 0.04199528]\n",
      "[Validate] TP Loss Across Timepoints: [1.28827119 1.45287752]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52286562 0.56713339]\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.026795811050881944, TP Loss: 1.3992107778787612\n",
      "[Validate] MAE Loss Across Timepoints: [0.0385219  0.04186235]\n",
      "[Validate] TP Loss Across Timepoints: [1.30207098 1.48606443]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51854808 0.60042809]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.026761791637788215, TP Loss: 1.396154560893774\n",
      "[Validate] MAE Loss Across Timepoints: [0.0381143  0.04132783]\n",
      "[Validate] TP Loss Across Timepoints: [1.25296032 1.39512658]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54539847 0.59880398]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02664947845041752, TP Loss: 1.390572576969862\n",
      "[Validate] MAE Loss Across Timepoints: [0.03823723 0.04137992]\n",
      "[Validate] TP Loss Across Timepoints: [1.24824333 1.3822844 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62967833 0.64276896]\n",
      "\n",
      "epochs finished with time:183.25348567962646\n",
      "\n",
      "Current memory usage: 3316.21 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03958857 0.04273708]\n",
      "[Test] TP Loss Across Timepoints: [3.30753924 3.08042908]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.53119355 0.62258869]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_oasis.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    # Create model instance\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "                # print(pred)\n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap, \n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
