{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU_simple import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data, compute_memory_capacity_vectorized, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=3, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0.00005, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "dataset = np.delete(dataset,88,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([113, 3, 35, 35])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_t/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.05094839483499527, TP Loss: 3.404314124584198, MAE of Mem Caps Loss: 0.21535666954777496\n",
      "[Validate] MAE Loss Across Timepoints: [0.0768711  0.06449318]\n",
      "[Validate] TP Loss Across Timepoints: [11.10978597  2.19295807]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58827517 0.96114863]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.04332901205246647, TP Loss: 2.7390817160407703, MAE of Mem Caps Loss: 0.18753290818542928\n",
      "[Validate] MAE Loss Across Timepoints: [0.0653088  0.05354968]\n",
      "[Validate] TP Loss Across Timepoints: [9.27441813 1.54202385]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54964615 0.87466238]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03854758872961005, TP Loss: 2.310478690514962, MAE of Mem Caps Loss: 0.19689558895469253\n",
      "[Validate] MAE Loss Across Timepoints: [0.06133409 0.04943677]\n",
      "[Validate] TP Loss Across Timepoints: [8.76549072 1.36646042]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2288251  0.78510842]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03585490168382724, TP Loss: 2.1490009064475695, MAE of Mem Caps Loss: 0.22522051696252568\n",
      "[Validate] MAE Loss Across Timepoints: [0.05734899 0.04426697]\n",
      "[Validate] TP Loss Across Timepoints: [8.09183655 1.17128932]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.24030298 0.735601  ]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.034231994890918334, TP Loss: 2.030268434683482, MAE of Mem Caps Loss: 0.2124716692173264\n",
      "[Validate] MAE Loss Across Timepoints: [0.05716459 0.04350501]\n",
      "[Validate] TP Loss Across Timepoints: [8.2134613  1.24205373]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26997366 0.68435506]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.03370035570114851, TP Loss: 2.0578133220473926, MAE of Mem Caps Loss: 0.1740081421332768\n",
      "[Validate] MAE Loss Across Timepoints: [0.05657953 0.04257896]\n",
      "[Validate] TP Loss Across Timepoints: [8.07251434 1.15561002]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26295971 0.52634564]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.033573728799819944, TP Loss: 2.0519225989778835, MAE of Mem Caps Loss: 0.17312252080787188\n",
      "[Validate] MAE Loss Across Timepoints: [0.05641411 0.04230127]\n",
      "[Validate] TP Loss Across Timepoints: [8.02687225 1.13944461]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27883775 0.46328847]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.03323352979496121, TP Loss: 1.9925299597283204, MAE of Mem Caps Loss: 0.18148051880773183\n",
      "[Validate] MAE Loss Across Timepoints: [0.05637093 0.04240352]\n",
      "[Validate] TP Loss Across Timepoints: [8.01945394 1.1389445 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.20905456 0.59386429]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.03316606994097431, TP Loss: 2.0475980093081794, MAE of Mem Caps Loss: 0.17029306455952314\n",
      "[Validate] MAE Loss Across Timepoints: [0.05617449 0.04209615]\n",
      "[Validate] TP Loss Across Timepoints: [7.98857422 1.10493533]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.22300679 0.52193313]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.03290356773262223, TP Loss: 2.0120837057630223, MAE of Mem Caps Loss: 0.16618543756977391\n",
      "[Validate] MAE Loss Across Timepoints: [0.05608019 0.04203893]\n",
      "[Validate] TP Loss Across Timepoints: [7.9474767  1.07484271]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.13711198 0.4562575 ]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.03291895960768064, TP Loss: 1.9861161693930627, MAE of Mem Caps Loss: 0.16385733863544205\n",
      "[Validate] MAE Loss Across Timepoints: [0.05584991 0.04185962]\n",
      "[Validate] TP Loss Across Timepoints: [7.95921478 1.08892085]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23752219 0.47343169]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.03279656013473868, TP Loss: 2.0104352886478107, MAE of Mem Caps Loss: 0.15834919162317673\n",
      "[Validate] MAE Loss Across Timepoints: [0.0558158  0.04181422]\n",
      "[Validate] TP Loss Across Timepoints: [7.95570272 1.07890231]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2343342  0.51031958]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.03258009230097135, TP Loss: 2.018177449206511, MAE of Mem Caps Loss: 0.1708493885462783\n",
      "[Validate] MAE Loss Across Timepoints: [0.05597417 0.04182156]\n",
      "[Validate] TP Loss Across Timepoints: [8.02686412 1.09239947]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2174721  0.48146723]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.0324844328686595, TP Loss: 1.938088488827149, MAE of Mem Caps Loss: 0.15926781766900103\n",
      "[Validate] MAE Loss Across Timepoints: [0.05569149 0.04170541]\n",
      "[Validate] TP Loss Across Timepoints: [7.89551239 1.04735336]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.1626746  0.44109787]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.032579058626045786, TP Loss: 1.9758975031475225, MAE of Mem Caps Loss: 0.14677978712621254\n",
      "[Validate] MAE Loss Across Timepoints: [0.05565845 0.0416815 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.88793284 1.04287669]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.17190445 0.45647124]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.03258908006052176, TP Loss: 1.9969824952383837, MAE of Mem Caps Loss: 0.16241266183040554\n",
      "[Validate] MAE Loss Across Timepoints: [0.05573541 0.04168577]\n",
      "[Validate] TP Loss Across Timepoints: [7.9307663  1.04624379]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.22607199 0.40512166]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.03248989200219512, TP Loss: 1.9820467700560889, MAE of Mem Caps Loss: 0.15625967110148478\n",
      "[Validate] MAE Loss Across Timepoints: [0.05572722 0.0417347 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.92519124 1.0280297 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.20757266 0.43870656]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.03238352630287409, TP Loss: 1.949767490228017, MAE of Mem Caps Loss: 0.16150616036463772\n",
      "[Validate] MAE Loss Across Timepoints: [0.05576096 0.04167279]\n",
      "[Validate] TP Loss Across Timepoints: [7.98763529 1.07867978]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.20164452 0.50570586]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.03243979134907325, TP Loss: 2.0024853900074957, MAE of Mem Caps Loss: 0.1632808997940802\n",
      "[Validate] MAE Loss Across Timepoints: [0.05576269 0.04167143]\n",
      "[Validate] TP Loss Across Timepoints: [7.97262726 1.04568392]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.20478502 0.55030755]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.032274596641461054, TP Loss: 1.9606770783662797, MAE of Mem Caps Loss: 0.15592126411887264\n",
      "[Validate] MAE Loss Across Timepoints: [0.05562544 0.04155684]\n",
      "[Validate] TP Loss Across Timepoints: [7.96008199 1.06521759]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23740906 0.56678001]\n",
      "\n",
      "epochs finished with time:642.211656332016\n",
      "\n",
      "Current memory usage: 3323.10 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04035504 0.04489495]\n",
      "[Test] TP Loss Across Timepoints: [1.23163424 1.84594144]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.32718002 0.52937408]\n",
      "------------------------------------Fold [2/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04796052537858486, TP Loss: 2.9961951235930124, MAE of Mem Caps Loss: 0.16731186587921332\n",
      "[Validate] MAE Loss Across Timepoints: [0.07430028 0.06980515]\n",
      "[Validate] TP Loss Across Timepoints: [11.3384613   4.46040904]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74092838 0.91246168]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.04144076211377978, TP Loss: 2.4898487110932668, MAE of Mem Caps Loss: 0.1725310573587234\n",
      "[Validate] MAE Loss Across Timepoints: [0.06518483 0.06088803]\n",
      "[Validate] TP Loss Across Timepoints: [9.8675059  3.69755249]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70447529 0.7482593 ]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.037395286529014506, TP Loss: 1.9965837520857652, MAE of Mem Caps Loss: 0.15634079806629295\n",
      "[Validate] MAE Loss Across Timepoints: [0.06208028 0.05831065]\n",
      "[Validate] TP Loss Across Timepoints: [9.18940735 3.5165741 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43475264 0.76657338]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03557297152777513, TP Loss: 1.7825572927792868, MAE of Mem Caps Loss: 0.14238757091614127\n",
      "[Validate] MAE Loss Across Timepoints: [0.05946316 0.05562723]\n",
      "[Validate] TP Loss Across Timepoints: [8.6456014  3.13317515]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.4986397  0.70579872]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.0344793246127665, TP Loss: 1.7044576240082583, MAE of Mem Caps Loss: 0.149826544410198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.05872123 0.05481744]\n",
      "[Validate] TP Loss Across Timepoints: [8.47408498 3.00945002]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.50332834 0.64515168]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.033454102495064336, TP Loss: 1.6567892198761305, MAE of Mem Caps Loss: 0.18964640375411482\n",
      "[Validate] MAE Loss Across Timepoints: [0.05578137 0.05182543]\n",
      "[Validate] TP Loss Across Timepoints: [7.98954315 2.645578  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.41195098 0.69209119]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.032488804496824744, TP Loss: 1.5879916677872339, MAE of Mem Caps Loss: 0.1603063301146405\n",
      "[Validate] MAE Loss Across Timepoints: [0.05545097 0.0514492 ]\n",
      "[Validate] TP Loss Across Timepoints: [8.03735504 2.61292826]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.40032419 0.67066019]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.031189000885933637, TP Loss: 1.487103994190693, MAE of Mem Caps Loss: 0.1523794432894539\n",
      "[Validate] MAE Loss Across Timepoints: [0.05292836 0.0490785 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.67875977 2.3444753 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.36695189 0.49833137]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.03038773275911808, TP Loss: 1.462834855914116, MAE of Mem Caps Loss: 0.15273751206419545\n",
      "[Validate] MAE Loss Across Timepoints: [0.05317    0.04951996]\n",
      "[Validate] TP Loss Across Timepoints: [7.79460704 2.47251231]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.22499563 0.49390285]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.030267725791782142, TP Loss: 1.4631754125157992, MAE of Mem Caps Loss: 0.15308324854875813\n",
      "[Validate] MAE Loss Across Timepoints: [0.05254105 0.04839021]\n",
      "[Validate] TP Loss Across Timepoints: [7.64359487 2.30319138]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.21723896 0.39278318]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.030378775174419084, TP Loss: 1.4573716615637144, MAE of Mem Caps Loss: 0.15315848488717157\n",
      "[Validate] MAE Loss Across Timepoints: [0.05218617 0.04786571]\n",
      "[Validate] TP Loss Across Timepoints: [7.51123199 2.17556661]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.21339988 0.34455763]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.0302697843251129, TP Loss: 1.468408104777336, MAE of Mem Caps Loss: 0.1466294885565029\n",
      "[Validate] MAE Loss Across Timepoints: [0.05274686 0.04872266]\n",
      "[Validate] TP Loss Across Timepoints: [7.74555461 2.35769145]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.19472767 0.4552489 ]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.03017571127663056, TP Loss: 1.451276112596194, MAE of Mem Caps Loss: 0.15243906896814746\n",
      "[Validate] MAE Loss Across Timepoints: [0.05230958 0.04796453]\n",
      "[Validate] TP Loss Across Timepoints: [7.65643311 2.25048523]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.19494623 0.35385406]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.030014051869511605, TP Loss: 1.468379620462656, MAE of Mem Caps Loss: 0.153484198949351\n",
      "[Validate] MAE Loss Across Timepoints: [0.05237339 0.0482024 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.62318217 2.24645793]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.18471907 0.45572114]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.030018556925157706, TP Loss: 1.4507417306303978, MAE of Mem Caps Loss: 0.14081319047476787\n",
      "[Validate] MAE Loss Across Timepoints: [0.05230331 0.04795534]\n",
      "[Validate] TP Loss Across Timepoints: [7.58653005 2.20740891]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.162211   0.45527022]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.029881913773715497, TP Loss: 1.3936654277145863, MAE of Mem Caps Loss: 0.1463013973532029\n",
      "[Validate] MAE Loss Across Timepoints: [0.05197864 0.04751452]\n",
      "[Validate] TP Loss Across Timepoints: [7.47309621 2.10082423]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.20803648 0.49094756]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.029790593838940064, TP Loss: 1.4039540196458498, MAE of Mem Caps Loss: 0.1477223321827062\n",
      "[Validate] MAE Loss Across Timepoints: [0.05233439 0.04794086]\n",
      "[Validate] TP Loss Across Timepoints: [7.63141022 2.21586126]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25346505 0.50659603]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.029793924527863662, TP Loss: 1.3905620745072762, MAE of Mem Caps Loss: 0.15148238699176214\n",
      "[Validate] MAE Loss Across Timepoints: [0.05194579 0.04717373]\n",
      "[Validate] TP Loss Across Timepoints: [7.5010554  2.07230237]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23584497 0.39787308]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02981188918153445, TP Loss: 1.4311477998892466, MAE of Mem Caps Loss: 0.1407747494535334\n",
      "[Validate] MAE Loss Across Timepoints: [0.05212143 0.0474763 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.52392731 2.09396744]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.21482146 0.43664493]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02978319867203633, TP Loss: 1.4226101207236448, MAE of Mem Caps Loss: 0.14167917747419287\n",
      "[Validate] MAE Loss Across Timepoints: [0.05218509 0.04755968]\n",
      "[Validate] TP Loss Across Timepoints: [7.62293498 2.16298955]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23393083 0.4018371 ]\n",
      "\n",
      "epochs finished with time:648.1730999946594\n",
      "\n",
      "Current memory usage: 3326.97 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04686576 0.05113392]\n",
      "[Test] TP Loss Across Timepoints: [2.58411387 4.35326225]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.35007541 0.31810359]\n",
      "------------------------------------Fold [3/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04881558899457256, TP Loss: 2.6553579077124594, MAE of Mem Caps Loss: 0.19440919341190963\n",
      "[Validate] MAE Loss Across Timepoints: [0.06140368 0.0637156 ]\n",
      "[Validate] TP Loss Across Timepoints: [3.18003535 2.97029877]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96984038 1.63641361]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.04041927773505449, TP Loss: 2.209002085030079, MAE of Mem Caps Loss: 0.17646351809073338\n",
      "[Validate] MAE Loss Across Timepoints: [0.05220669 0.05717374]\n",
      "[Validate] TP Loss Across Timepoints: [2.4007957  2.48051405]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53013614 1.05216441]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03674795466164748, TP Loss: 1.9930668209989866, MAE of Mem Caps Loss: 0.18729760086550937\n",
      "[Validate] MAE Loss Across Timepoints: [0.04735484 0.05186594]\n",
      "[Validate] TP Loss Across Timepoints: [2.02173877 2.20926809]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48326077 0.82877027]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03389532969643672, TP Loss: 1.8251844756305218, MAE of Mem Caps Loss: 0.16638362742729684\n",
      "[Validate] MAE Loss Across Timepoints: [0.04297101 0.0466308 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.69384336 1.85659802]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63501466 0.70068067]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.03209437616169453, TP Loss: 1.7079594443241755, MAE of Mem Caps Loss: 0.17868254750784762\n",
      "[Validate] MAE Loss Across Timepoints: [0.04227491 0.04578799]\n",
      "[Validate] TP Loss Across Timepoints: [1.67740679 1.82892215]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63944071 0.68591458]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.03135938383638859, TP Loss: 1.6831210367381573, MAE of Mem Caps Loss: 0.2017030811244063\n",
      "[Validate] MAE Loss Across Timepoints: [0.04198551 0.04532579]\n",
      "[Validate] TP Loss Across Timepoints: [1.63965023 1.76365113]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63460904 0.68084064]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.03107227428505818, TP Loss: 1.690995125969251, MAE of Mem Caps Loss: 0.2103792338051373\n",
      "[Validate] MAE Loss Across Timepoints: [0.04205662 0.04546965]\n",
      "[Validate] TP Loss Across Timepoints: [1.67104173 1.79391968]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62837832 0.69987446]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.03081207020829121, TP Loss: 1.6452823584278424, MAE of Mem Caps Loss: 0.2160632252372544\n",
      "[Validate] MAE Loss Across Timepoints: [0.04138296 0.04435287]\n",
      "[Validate] TP Loss Across Timepoints: [1.56300592 1.64332008]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65262972 0.66804546]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.030649972862253586, TP Loss: 1.6666967878739039, MAE of Mem Caps Loss: 0.22555188404387175\n",
      "[Validate] MAE Loss Across Timepoints: [0.04137719 0.04450934]\n",
      "[Validate] TP Loss Across Timepoints: [1.57287419 1.68469429]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62493516 0.67499824]\n",
      "Epoch [10/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.030435808065036932, TP Loss: 1.6540501333773137, MAE of Mem Caps Loss: 0.21131433407366745\n",
      "[Validate] MAE Loss Across Timepoints: [0.04149675 0.04467349]\n",
      "[Validate] TP Loss Across Timepoints: [1.65308249 1.77500248]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6059683  0.62696106]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.030288539143900076, TP Loss: 1.628926435112953, MAE of Mem Caps Loss: 0.21889586569062613\n",
      "[Validate] MAE Loss Across Timepoints: [0.04132172 0.04438901]\n",
      "[Validate] TP Loss Across Timepoints: [1.59604812 1.70661378]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62007723 0.60197215]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.03027976133550207, TP Loss: 1.6222622953355312, MAE of Mem Caps Loss: 0.21909706740823864\n",
      "[Validate] MAE Loss Across Timepoints: [0.0413506  0.04440737]\n",
      "[Validate] TP Loss Across Timepoints: [1.60766804 1.72674608]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58000034 0.60906532]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.03008533806229631, TP Loss: 1.6456652767956257, MAE of Mem Caps Loss: 0.23588371400482525\n",
      "[Validate] MAE Loss Across Timepoints: [0.04124046 0.04424481]\n",
      "[Validate] TP Loss Across Timepoints: [1.58476627 1.68143904]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63498768 0.62400785]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.030042827874422074, TP Loss: 1.6600188913444678, MAE of Mem Caps Loss: 0.23965540436889404\n",
      "[Validate] MAE Loss Across Timepoints: [0.0410845  0.04402686]\n",
      "[Validate] TP Loss Across Timepoints: [1.58300161 1.67082345]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61224811 0.61574296]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.030119756795465948, TP Loss: 1.6340226295093696, MAE of Mem Caps Loss: 0.22842926682857465\n",
      "[Validate] MAE Loss Across Timepoints: [0.04095615 0.04383894]\n",
      "[Validate] TP Loss Across Timepoints: [1.56679273 1.65644705]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64398312 0.6125039 ]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02998895589262247, TP Loss: 1.6284635826945304, MAE of Mem Caps Loss: 0.2654047375002896\n",
      "[Validate] MAE Loss Across Timepoints: [0.04119038 0.0441199 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.60808623 1.70616984]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64558162 0.62811922]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02989374700312813, TP Loss: 1.6048745336631933, MAE of Mem Caps Loss: 0.2552453914628388\n",
      "[Validate] MAE Loss Across Timepoints: [0.0409683 0.0437902]\n",
      "[Validate] TP Loss Across Timepoints: [1.54730213 1.61981738]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62374288 0.59529335]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.029982933898766835, TP Loss: 1.6130976920326552, MAE of Mem Caps Loss: 0.22814928942624138\n",
      "[Validate] MAE Loss Across Timepoints: [0.0409626  0.04386244]\n",
      "[Validate] TP Loss Across Timepoints: [1.55330789 1.63199782]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67595384 0.62635129]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02980263947198788, TP Loss: 1.6278171387811502, MAE of Mem Caps Loss: 0.24087393310071992\n",
      "[Validate] MAE Loss Across Timepoints: [0.04117427 0.04408704]\n",
      "[Validate] TP Loss Across Timepoints: [1.60215795 1.6935091 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60116114 0.58185511]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02994614259029428, TP Loss: 1.613158791512251, MAE of Mem Caps Loss: 0.23534752600664977\n",
      "[Validate] MAE Loss Across Timepoints: [0.0408352  0.04373075]\n",
      "[Validate] TP Loss Across Timepoints: [1.51346695 1.57022703]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64984911 0.63826397]\n",
      "\n",
      "epochs finished with time:653.4297585487366\n",
      "\n",
      "Current memory usage: 3326.79 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04210979 0.04487563]\n",
      "[Test] TP Loss Across Timepoints: [3.57825697 3.23984424]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.54776786 0.58799736]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_oasis.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "   \n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights, input_scaling=1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        mae_mem_cap_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "            mem_cap_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred, output_sig = model(data[t], X_train_res, y_train_res, X_test_res)\n",
    "                    \n",
    "                real = data[t + 1]\n",
    "        \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "                # MAE between predicted graph's mem cap and actual graph's mem cap\n",
    "                predicted_mem_cap = compute_memory_capacity_vectorized(output_sig, y_test_res)\n",
    "                actual_mem_cap = torch.tensor(train_mem_cap_subjects[data_id, t + 1], requires_grad=True).to(device)\n",
    "                mem_cap_loss += mael(predicted_mem_cap, actual_mem_cap)\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total MAE between Mem Cap Loss for the current batch\n",
    "            mem_cap_loss = mem_cap_loss / (args.num_timepoints - 1)\n",
    "            \n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            mae_mem_cap_overall.append(mem_cap_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss + args.memcap_coef * mem_cap_loss \n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        mae_mem_cap_overall = np.mean(np.array(mae_mem_cap_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}, MAE of Mem Caps Loss: {mae_mem_cap_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
