{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.model_rbgm import GNN_1\n",
    "from memory_capacity_utils import gen_lag_data, compute_memory_capacity_vectorized, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=5, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0.0005, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_rbgm/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n",
      "TRAIN deterministic algorithms\n"
     ]
    }
   ],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03707144242071081, TP Loss: 3.508642232744023, MAE of Mem Caps Loss: 0.2915014259763035\n",
      "[Validate] MAE Loss Across Timepoints: [0.04091657 0.04338468]\n",
      "[Validate] TP Loss Across Timepoints: [1.13029826 1.57897723]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27634506 0.62171657]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.026529635913902894, TP Loss: 0.718762926524505, MAE of Mem Caps Loss: 0.21003925708391546\n",
      "[Validate] MAE Loss Across Timepoints: [0.03837866 0.04055791]\n",
      "[Validate] TP Loss Across Timepoints: [1.01133311 1.33522296]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27531138 0.64003869]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.025520707815303467, TP Loss: 0.6762160551734269, MAE of Mem Caps Loss: 0.17943341783704286\n",
      "[Validate] MAE Loss Across Timepoints: [0.03778297 0.04009748]\n",
      "[Validate] TP Loss Across Timepoints: [0.9805401  1.29271722]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28882223 0.69951044]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.025194364483468235, TP Loss: 0.6673384550958872, MAE of Mem Caps Loss: 0.21153107818494607\n",
      "[Validate] MAE Loss Across Timepoints: [0.03737933 0.03932346]\n",
      "[Validate] TP Loss Across Timepoints: [0.93966401 1.16587353]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.34971695 0.78823573]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.024958247115137056, TP Loss: 0.6623265859670937, MAE of Mem Caps Loss: 0.20044799196693563\n",
      "[Validate] MAE Loss Across Timepoints: [0.03706434 0.03907504]\n",
      "[Validate] TP Loss Across Timepoints: [0.94934428 1.19432819]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.37380329 0.77263741]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02477067123982124, TP Loss: 0.6619007550179958, MAE of Mem Caps Loss: 0.21277167798024682\n",
      "[Validate] MAE Loss Across Timepoints: [0.03695036 0.0390057 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.95199913 1.21436024]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30205014 0.76321611]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.024610031774500385, TP Loss: 0.6568607906810939, MAE of Mem Caps Loss: 0.18249984331114238\n",
      "[Validate] MAE Loss Across Timepoints: [0.03661447 0.03824082]\n",
      "[Validate] TP Loss Across Timepoints: [0.93155712 1.11990738]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.36602938 0.81357733]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02447707936516963, TP Loss: 0.6550648345146328, MAE of Mem Caps Loss: 0.21360142081333897\n",
      "[Validate] MAE Loss Across Timepoints: [0.0364938  0.03809557]\n",
      "[Validate] TP Loss Across Timepoints: [0.93020362 1.12209499]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.32805403 0.81169628]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024389659170992672, TP Loss: 0.654293216066435, MAE of Mem Caps Loss: 0.19076913766542175\n",
      "[Validate] MAE Loss Across Timepoints: [0.03634562 0.03775036]\n",
      "[Validate] TP Loss Across Timepoints: [0.91902399 1.06281376]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33766404 0.81376161]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.024270213209092617, TP Loss: 0.6505938027985394, MAE of Mem Caps Loss: 0.19037634631979966\n",
      "[Validate] MAE Loss Across Timepoints: [0.03622679 0.037477  ]\n",
      "[Validate] TP Loss Across Timepoints: [0.92109215 1.07416928]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33723365 0.79430863]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02419051378092263, TP Loss: 0.6499422248452902, MAE of Mem Caps Loss: 0.21443521844166513\n",
      "[Validate] MAE Loss Across Timepoints: [0.03618604 0.03735851]\n",
      "[Validate] TP Loss Across Timepoints: [0.92083752 1.06977654]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.34315145 0.78385667]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02411312481854111, TP Loss: 0.6489260464441031, MAE of Mem Caps Loss: 0.1881852172131651\n",
      "[Validate] MAE Loss Across Timepoints: [0.03603817 0.0371477 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.91842717 1.05538154]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.3636211  0.80208868]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024043648576480336, TP Loss: 0.6462865835055709, MAE of Mem Caps Loss: 0.1806651414750046\n",
      "[Validate] MAE Loss Across Timepoints: [0.03597462 0.03709171]\n",
      "[Validate] TP Loss Across Timepoints: [0.92104    1.06561375]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.35801895 0.82347662]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.0239814663073048, TP Loss: 0.6451448989100754, MAE of Mem Caps Loss: 0.17439762643996698\n",
      "[Validate] MAE Loss Across Timepoints: [0.0358809  0.03688689]\n",
      "[Validate] TP Loss Across Timepoints: [0.91831321 1.05303431]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.36163198 0.81024607]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.023935252567753196, TP Loss: 0.6451295290607959, MAE of Mem Caps Loss: 0.17050589920251452\n",
      "[Validate] MAE Loss Across Timepoints: [0.03585259 0.03686456]\n",
      "[Validate] TP Loss Across Timepoints: [0.9256562  1.07776737]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33374549 0.79211922]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02388657844858244, TP Loss: 0.6446120366454124, MAE of Mem Caps Loss: 0.16851122526912726\n",
      "[Validate] MAE Loss Across Timepoints: [0.03578487 0.03672533]\n",
      "[Validate] TP Loss Across Timepoints: [0.92029029 1.05703211]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33075342 0.79071264]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.023847147851483896, TP Loss: 0.644299294333905, MAE of Mem Caps Loss: 0.16648201870855983\n",
      "[Validate] MAE Loss Across Timepoints: [0.03575529 0.03669455]\n",
      "[Validate] TP Loss Across Timepoints: [0.92012471 1.05301523]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.31216059 0.77663922]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.0238124038442038, TP Loss: 0.6441497290506959, MAE of Mem Caps Loss: 0.16611407864207212\n",
      "[Validate] MAE Loss Across Timepoints: [0.03567829 0.03652661]\n",
      "[Validate] TP Loss Across Timepoints: [0.91544074 1.0348295 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.31633792 0.7682241 ]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023780057948897593, TP Loss: 0.643938533263281, MAE of Mem Caps Loss: 0.16474018617380864\n",
      "[Validate] MAE Loss Across Timepoints: [0.03568217 0.03656354]\n",
      "[Validate] TP Loss Across Timepoints: [0.91429758 1.0256635 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30409053 0.76320192]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023754965644911863, TP Loss: 0.6440134844742715, MAE of Mem Caps Loss: 0.1641333886283013\n",
      "[Validate] MAE Loss Across Timepoints: [0.03565291 0.03653456]\n",
      "[Validate] TP Loss Across Timepoints: [0.91403872 1.02111316]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30140604 0.7603766 ]\n",
      "\n",
      "epochs finished with time:1865.8931694030762\n",
      "\n",
      "Current memory usage: 2621.08 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03561225 0.03531091]\n",
      "[Test] TP Loss Across Timepoints: [0.93929148 0.92687826]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.26189332 0.68975431]\n",
      "------------------------------------Fold [2/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03659332505776547, TP Loss: 3.194907904136926, MAE of Mem Caps Loss: 0.37901614476293427\n",
      "[Validate] MAE Loss Across Timepoints: [0.04079979 0.04352563]\n",
      "[Validate] TP Loss Across Timepoints: [1.09232962 1.47831655]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.32661181 0.66589914]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.026988593046553433, TP Loss: 0.7457787510938942, MAE of Mem Caps Loss: 0.17584828632261104\n",
      "[Validate] MAE Loss Across Timepoints: [0.03893105 0.04167505]\n",
      "[Validate] TP Loss Across Timepoints: [0.98582387 1.28036582]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26437476 0.52802706]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02637263049837202, TP Loss: 0.7167434913571924, MAE of Mem Caps Loss: 0.15938312199406257\n",
      "[Validate] MAE Loss Across Timepoints: [0.03837533 0.04117439]\n",
      "[Validate] TP Loss Across Timepoints: [0.96853065 1.28949344]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.24365962 0.4930291 ]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.026037032672320493, TP Loss: 0.7067051120102406, MAE of Mem Caps Loss: 0.15161634812444544\n",
      "[Validate] MAE Loss Across Timepoints: [0.03803531 0.04085275]\n",
      "[Validate] TP Loss Across Timepoints: [0.96621573 1.27912951]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25025582 0.51130124]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.025826161363511346, TP Loss: 0.7043143096379936, MAE of Mem Caps Loss: 0.1509442211248784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03781157 0.04060908]\n",
      "[Validate] TP Loss Across Timepoints: [0.9626565  1.26418066]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.24267667 0.49905352]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02565018278255593, TP Loss: 0.7012145915068686, MAE of Mem Caps Loss: 0.14935659977326493\n",
      "[Validate] MAE Loss Across Timepoints: [0.03756969 0.04025608]\n",
      "[Validate] TP Loss Across Timepoints: [0.95496166 1.21965861]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25260803 0.50691601]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.025506245263386518, TP Loss: 0.6995925593655556, MAE of Mem Caps Loss: 0.1515105808080516\n",
      "[Validate] MAE Loss Across Timepoints: [0.03740263 0.04012098]\n",
      "[Validate] TP Loss Across Timepoints: [0.95885867 1.22674716]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.24986475 0.5017409 ]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.025312214449513704, TP Loss: 0.6942429153714329, MAE of Mem Caps Loss: 0.15779332393261986\n",
      "[Validate] MAE Loss Across Timepoints: [0.03685262 0.03835022]\n",
      "[Validate] TP Loss Across Timepoints: [0.94539952 1.09536803]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28655024 0.64207882]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02470199480012525, TP Loss: 0.6804958849679679, MAE of Mem Caps Loss: 0.1672461152547945\n",
      "[Validate] MAE Loss Across Timepoints: [0.03628461 0.03750547]\n",
      "[Validate] TP Loss Across Timepoints: [0.93783349 1.0754087 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.29375855 0.64560649]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.024582841724622995, TP Loss: 0.6781355778221041, MAE of Mem Caps Loss: 0.16508115527146117\n",
      "[Validate] MAE Loss Across Timepoints: [0.03615724 0.03732635]\n",
      "[Validate] TP Loss Across Timepoints: [0.93384933 1.05543351]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.29450477 0.67589785]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.024494370809406973, TP Loss: 0.6767237628810108, MAE of Mem Caps Loss: 0.16413292330547902\n",
      "[Validate] MAE Loss Across Timepoints: [0.03607739 0.03734147]\n",
      "[Validate] TP Loss Across Timepoints: [0.94002575 1.06999099]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30189415 0.69659387]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.024417974142124876, TP Loss: 0.6758305132389069, MAE of Mem Caps Loss: 0.16227407671054978\n",
      "[Validate] MAE Loss Across Timepoints: [0.03597262 0.03717815]\n",
      "[Validate] TP Loss Across Timepoints: [0.94045496 1.06039929]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.29559241 0.70787797]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024348788312636316, TP Loss: 0.6740214908495545, MAE of Mem Caps Loss: 0.1606295239728461\n",
      "[Validate] MAE Loss Across Timepoints: [0.03587346 0.03708101]\n",
      "[Validate] TP Loss Across Timepoints: [0.94512993 1.070292  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.29120548 0.71077837]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.024285075967782177, TP Loss: 0.6735556747298688, MAE of Mem Caps Loss: 0.15867130686681358\n",
      "[Validate] MAE Loss Across Timepoints: [0.03579517 0.03699733]\n",
      "[Validate] TP Loss Across Timepoints: [0.94565034 1.07454836]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28929141 0.70522226]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.024234651718870737, TP Loss: 0.6724579576402903, MAE of Mem Caps Loss: 0.15854360264042766\n",
      "[Validate] MAE Loss Across Timepoints: [0.03570838 0.03692253]\n",
      "[Validate] TP Loss Across Timepoints: [0.94349939 1.06478429]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28559032 0.70944791]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.024184010238968767, TP Loss: 0.6715501896105707, MAE of Mem Caps Loss: 0.15727533246885733\n",
      "[Validate] MAE Loss Across Timepoints: [0.03564224 0.03687711]\n",
      "[Validate] TP Loss Across Timepoints: [0.94452101 1.06750154]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28390064 0.71070384]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02414066347409971, TP Loss: 0.6713259138632566, MAE of Mem Caps Loss: 0.155910943439234\n",
      "[Validate] MAE Loss Across Timepoints: [0.03559483 0.03680784]\n",
      "[Validate] TP Loss Across Timepoints: [0.94460142 1.06672037]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28011975 0.72518566]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02410160709405318, TP Loss: 0.6711550352629274, MAE of Mem Caps Loss: 0.15401288175448602\n",
      "[Validate] MAE Loss Across Timepoints: [0.0355189  0.03669407]\n",
      "[Validate] TP Loss Across Timepoints: [0.94407761 1.05571544]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2783035  0.74288188]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.024058995652012527, TP Loss: 0.6692070357967168, MAE of Mem Caps Loss: 0.15334376573551095\n",
      "[Validate] MAE Loss Across Timepoints: [0.03546844 0.03665951]\n",
      "[Validate] TP Loss Across Timepoints: [0.94204783 1.05635166]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27244923 0.75252626]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.024022860859986395, TP Loss: 0.6681227385997772, MAE of Mem Caps Loss: 0.1538200532262904\n",
      "[Validate] MAE Loss Across Timepoints: [0.03543792 0.036622  ]\n",
      "[Validate] TP Loss Across Timepoints: [0.94257069 1.05646288]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2695994  0.76862609]\n",
      "\n",
      "epochs finished with time:1820.701001882553\n",
      "\n",
      "Current memory usage: 2621.08 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03540211 0.0374297 ]\n",
      "[Test] TP Loss Across Timepoints: [0.79590282 1.04092035]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.29173399 0.71702364]\n",
      "------------------------------------Fold [3/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.035875496483640745, TP Loss: 3.0250778349582106, MAE of Mem Caps Loss: 0.25343092775907944\n",
      "[Validate] MAE Loss Across Timepoints: [0.04225054 0.04903532]\n",
      "[Validate] TP Loss Across Timepoints: [1.283849   2.43773961]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23312896 0.3245806 ]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02658195560798049, TP Loss: 0.6973120989277959, MAE of Mem Caps Loss: 0.2210126050513703\n",
      "[Validate] MAE Loss Across Timepoints: [0.03872133 0.03985409]\n",
      "[Validate] TP Loss Across Timepoints: [1.02193022 1.3794111 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33088464 0.50332418]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02537941154150758, TP Loss: 0.6468311662320048, MAE of Mem Caps Loss: 0.21022718254845063\n",
      "[Validate] MAE Loss Across Timepoints: [0.03788923 0.03873071]\n",
      "[Validate] TP Loss Across Timepoints: [0.95307118 1.19810903]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26837328 0.48332336]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.0248542778135743, TP Loss: 0.629004324786365, MAE of Mem Caps Loss: 0.184897314736724\n",
      "[Validate] MAE Loss Across Timepoints: [0.03736874 0.03833102]\n",
      "[Validate] TP Loss Across Timepoints: [0.9642179  1.22704494]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26475008 0.45831985]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.024609734857222065, TP Loss: 0.6277342622634023, MAE of Mem Caps Loss: 0.1953275281208681\n",
      "[Validate] MAE Loss Across Timepoints: [0.03710763 0.03801288]\n",
      "[Validate] TP Loss Across Timepoints: [0.96590966 1.2127912 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2695199  0.48430294]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024430908146314323, TP Loss: 0.6249823373509571, MAE of Mem Caps Loss: 0.18989675300823822\n",
      "[Validate] MAE Loss Across Timepoints: [0.03693033 0.03786147]\n",
      "[Validate] TP Loss Across Timepoints: [0.96887976 1.21430159]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27078854 0.46969869]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.024290534071042202, TP Loss: 0.6226316594984382, MAE of Mem Caps Loss: 0.18557564473056842\n",
      "[Validate] MAE Loss Across Timepoints: [0.03676139 0.03772505]\n",
      "[Validate] TP Loss Across Timepoints: [0.96735537 1.20654905]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27360164 0.47594803]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.024147140778950416, TP Loss: 0.6204744224669412, MAE of Mem Caps Loss: 0.1792866917600081\n",
      "[Validate] MAE Loss Across Timepoints: [0.03658798 0.03749398]\n",
      "[Validate] TP Loss Across Timepoints: [0.96283257 1.18532598]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28421512 0.50226167]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024035079404711723, TP Loss: 0.6184046851703897, MAE of Mem Caps Loss: 0.17638528462378672\n",
      "[Validate] MAE Loss Across Timepoints: [0.03645296 0.03736885]\n",
      "[Validate] TP Loss Across Timepoints: [0.96342993 1.18305659]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28678283 0.51054254]\n",
      "Epoch [10/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.02394853564328514, TP Loss: 0.6182166746584699, MAE of Mem Caps Loss: 0.17315191028651114\n",
      "[Validate] MAE Loss Across Timepoints: [0.03636267 0.03720339]\n",
      "[Validate] TP Loss Across Timepoints: [0.96403456 1.16950428]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28325746 0.50497992]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.023872714300523512, TP Loss: 0.6180718176765367, MAE of Mem Caps Loss: 0.1710770323860284\n",
      "[Validate] MAE Loss Across Timepoints: [0.03630058 0.03716778]\n",
      "[Validate] TP Loss Across Timepoints: [0.96507257 1.17058563]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27837828 0.50346921]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02380338220973499, TP Loss: 0.6172150245402008, MAE of Mem Caps Loss: 0.16727103041217095\n",
      "[Validate] MAE Loss Across Timepoints: [0.03622915 0.03701572]\n",
      "[Validate] TP Loss Across Timepoints: [0.96241122 1.15480375]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26910844 0.50648161]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.023747213432216085, TP Loss: 0.6164841123390943, MAE of Mem Caps Loss: 0.16516495705153017\n",
      "[Validate] MAE Loss Across Timepoints: [0.03621139 0.0371262 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.97252023 1.18405652]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25619946 0.49395602]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.023696611504419707, TP Loss: 0.61626677273307, MAE of Mem Caps Loss: 0.16248318269933376\n",
      "[Validate] MAE Loss Across Timepoints: [0.03616315 0.03699763]\n",
      "[Validate] TP Loss Across Timepoints: [0.96674913 1.16186845]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25179406 0.49803991]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.0236519782920368, TP Loss: 0.6151906787417829, MAE of Mem Caps Loss: 0.1620800969732435\n",
      "[Validate] MAE Loss Across Timepoints: [0.03614116 0.03695738]\n",
      "[Validate] TP Loss Across Timepoints: [0.9689154  1.16031039]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25113895 0.49738385]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02361375633336138, TP Loss: 0.6143928659148514, MAE of Mem Caps Loss: 0.16266689843184945\n",
      "[Validate] MAE Loss Across Timepoints: [0.0360838  0.03686349]\n",
      "[Validate] TP Loss Across Timepoints: [0.96398282 1.14448035]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25579231 0.50925247]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02357701510482002, TP Loss: 0.613605551654473, MAE of Mem Caps Loss: 0.1627165869063646\n",
      "[Validate] MAE Loss Across Timepoints: [0.03607881 0.03684271]\n",
      "[Validate] TP Loss Across Timepoints: [0.96719331 1.14645302]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25448492 0.50439704]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02354690087668132, TP Loss: 0.6134849877562374, MAE of Mem Caps Loss: 0.16077381237715116\n",
      "[Validate] MAE Loss Across Timepoints: [0.03601518 0.03676085]\n",
      "[Validate] TP Loss Across Timepoints: [0.96178818 1.13264549]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26088979 0.51400869]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023515948036219925, TP Loss: 0.6130753690376878, MAE of Mem Caps Loss: 0.1607853832457456\n",
      "[Validate] MAE Loss Across Timepoints: [0.03599878 0.03680627]\n",
      "[Validate] TP Loss Across Timepoints: [0.96611392 1.14691806]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25691035 0.49351635]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023489325132686645, TP Loss: 0.6123254705453292, MAE of Mem Caps Loss: 0.16077162723509097\n",
      "[Validate] MAE Loss Across Timepoints: [0.0359625  0.03674312]\n",
      "[Validate] TP Loss Across Timepoints: [0.96214247 1.13660491]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25983933 0.50531021]\n",
      "\n",
      "epochs finished with time:1817.8984680175781\n",
      "\n",
      "Current memory usage: 2621.08 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03496165 0.0370778 ]\n",
      "[Test] TP Loss Across Timepoints: [0.94175768 1.25231657]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.22689132 0.55566638]\n",
      "------------------------------------Fold [4/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.03728446284367237, TP Loss: 3.5074143121019006, MAE of Mem Caps Loss: 0.3031047454250308\n",
      "[Validate] MAE Loss Across Timepoints: [0.04181028 0.04575779]\n",
      "[Validate] TP Loss Across Timepoints: [1.15042114 1.88611555]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.29812413 0.52791015]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.027168063184944913, TP Loss: 0.7605557364877313, MAE of Mem Caps Loss: 0.22536760286208674\n",
      "[Validate] MAE Loss Across Timepoints: [0.03885918 0.04149068]\n",
      "[Validate] TP Loss Across Timepoints: [0.94113076 1.34608316]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.3597477  0.72520983]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.026140653368202038, TP Loss: 0.7062986134551466, MAE of Mem Caps Loss: 0.23683854735344334\n",
      "[Validate] MAE Loss Across Timepoints: [0.03809921 0.0412048 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.92419118 1.37301064]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.33899266 0.58743914]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.025494431451079436, TP Loss: 0.6728327181190252, MAE of Mem Caps Loss: 0.21569198326533118\n",
      "[Validate] MAE Loss Across Timepoints: [0.03694392 0.03955936]\n",
      "[Validate] TP Loss Across Timepoints: [0.87443745 1.24064386]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.31686234 0.60762466]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02498888889385853, TP Loss: 0.6541503719054163, MAE of Mem Caps Loss: 0.18791611793731489\n",
      "[Validate] MAE Loss Across Timepoints: [0.0366789  0.03928407]\n",
      "[Validate] TP Loss Across Timepoints: [0.87867916 1.25230432]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.31068753 0.54846993]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024766638787696138, TP Loss: 0.6495339842513204, MAE of Mem Caps Loss: 0.17623192424257383\n",
      "[Validate] MAE Loss Across Timepoints: [0.03647296 0.03883391]\n",
      "[Validate] TP Loss Across Timepoints: [0.86763757 1.22553349]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25658211 0.58254988]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.024616682407213375, TP Loss: 0.646238895598799, MAE of Mem Caps Loss: 0.17196594396792575\n",
      "[Validate] MAE Loss Across Timepoints: [0.03623566 0.03850788]\n",
      "[Validate] TP Loss Across Timepoints: [0.86951059 1.21188426]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25184846 0.55882491]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.024474707883200608, TP Loss: 0.6452334290370345, MAE of Mem Caps Loss: 0.16522974927706569\n",
      "[Validate] MAE Loss Across Timepoints: [0.03605039 0.03830997]\n",
      "[Validate] TP Loss Across Timepoints: [0.87063378 1.2056222 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25078036 0.5597631 ]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024363003933103755, TP Loss: 0.6416569196153432, MAE of Mem Caps Loss: 0.15945679329354853\n",
      "[Validate] MAE Loss Across Timepoints: [0.03591459 0.03819702]\n",
      "[Validate] TP Loss Across Timepoints: [0.87222135 1.19991481]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26766066 0.56678535]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.024277390199131332, TP Loss: 0.6407192253973335, MAE of Mem Caps Loss: 0.15964849328017172\n",
      "[Validate] MAE Loss Across Timepoints: [0.03590077 0.038316  ]\n",
      "[Validate] TP Loss Across Timepoints: [0.87815309 1.2262218 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27707097 0.51104757]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02418767538620159, TP Loss: 0.6396454046480358, MAE of Mem Caps Loss: 0.1674549203740402\n",
      "[Validate] MAE Loss Across Timepoints: [0.03570333 0.0378233 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.86915517 1.17330754]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26084015 0.58590593]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02410511467314791, TP Loss: 0.6380950566381216, MAE of Mem Caps Loss: 0.15968304356037782\n",
      "[Validate] MAE Loss Across Timepoints: [0.03564376 0.03772278]\n",
      "[Validate] TP Loss Across Timepoints: [0.87210596 1.17125082]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25567475 0.58073051]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024041325275902636, TP Loss: 0.6373239324893802, MAE of Mem Caps Loss: 0.15897937551893138\n",
      "[Validate] MAE Loss Across Timepoints: [0.03559358 0.03741771]\n",
      "[Validate] TP Loss Across Timepoints: [0.87084687 1.14218736]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27292547 0.62049496]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02397694915998727, TP Loss: 0.6378061138093472, MAE of Mem Caps Loss: 0.16395300057065143\n",
      "[Validate] MAE Loss Across Timepoints: [0.03556789 0.03772497]\n",
      "[Validate] TP Loss Across Timepoints: [0.87533391 1.1795963 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2353623  0.53319989]\n",
      "Epoch [15/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.023932820724439807, TP Loss: 0.6357814292423427, MAE of Mem Caps Loss: 0.15613954874577424\n",
      "[Validate] MAE Loss Across Timepoints: [0.03551    0.03754488]\n",
      "[Validate] TP Loss Across Timepoints: [0.87702101 1.17298222]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26593406 0.63441426]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02388371191045735, TP Loss: 0.6359179597347975, MAE of Mem Caps Loss: 0.15677859148125256\n",
      "[Validate] MAE Loss Across Timepoints: [0.0354106  0.03735739]\n",
      "[Validate] TP Loss Across Timepoints: [0.87694407 1.15786397]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26290471 0.64523321]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.023828690958907828, TP Loss: 0.6338146571069956, MAE of Mem Caps Loss: 0.14996698628957014\n",
      "[Validate] MAE Loss Across Timepoints: [0.03540295 0.03738119]\n",
      "[Validate] TP Loss Across Timepoints: [0.87624639 1.16096866]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23488938 0.60337412]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.023828729186789133, TP Loss: 0.6379022656474262, MAE of Mem Caps Loss: 0.15980182104906554\n",
      "[Validate] MAE Loss Across Timepoints: [0.03540198 0.03744397]\n",
      "[Validate] TP Loss Across Timepoints: [0.87726319 1.15873015]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.28945049 0.55005185]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023781544252415188, TP Loss: 0.6335178150329739, MAE of Mem Caps Loss: 0.1542691332872827\n",
      "[Validate] MAE Loss Across Timepoints: [0.0353167  0.03724602]\n",
      "[Validate] TP Loss Across Timepoints: [0.87686902 1.1495806 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23724481 0.57916048]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023737085255561396, TP Loss: 0.6340145664289594, MAE of Mem Caps Loss: 0.14699250300863043\n",
      "[Validate] MAE Loss Across Timepoints: [0.03529103 0.03727933]\n",
      "[Validate] TP Loss Across Timepoints: [0.87848836 1.1620971 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23642793 0.58666966]\n",
      "\n",
      "epochs finished with time:1821.547191619873\n",
      "\n",
      "Current memory usage: 2621.08 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03496121 0.03908591]\n",
      "[Test] TP Loss Across Timepoints: [0.86594954 1.29954948]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.18814157 0.65047636]\n",
      "------------------------------------Fold [5/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.037292900757165626, TP Loss: 3.563977557932958, MAE of Mem Caps Loss: 0.3378324247928789\n",
      "[Validate] MAE Loss Across Timepoints: [0.04099696 0.04557625]\n",
      "[Validate] TP Loss Across Timepoints: [1.04206157 1.70811021]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30515572 0.67288577]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02723089545906987, TP Loss: 0.7342612377833575, MAE of Mem Caps Loss: 0.2229344194022984\n",
      "[Validate] MAE Loss Across Timepoints: [0.03919918 0.04312259]\n",
      "[Validate] TP Loss Across Timepoints: [0.95029408 1.45774078]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.29844458 0.68387326]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02615985387819819, TP Loss: 0.6855225095059723, MAE of Mem Caps Loss: 0.18602348228032983\n",
      "[Validate] MAE Loss Across Timepoints: [0.03713579 0.04063237]\n",
      "[Validate] TP Loss Across Timepoints: [0.88963681 1.30993509]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.2799944  0.64472977]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.025329550553578883, TP Loss: 0.6571920672431588, MAE of Mem Caps Loss: 0.17259127144614334\n",
      "[Validate] MAE Loss Across Timepoints: [0.03675533 0.04013556]\n",
      "[Validate] TP Loss Across Timepoints: [0.87562066 1.27043831]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30079633 0.61415811]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.025076591424294747, TP Loss: 0.6488957714755088, MAE of Mem Caps Loss: 0.16013299962743205\n",
      "[Validate] MAE Loss Across Timepoints: [0.0364617  0.03983261]\n",
      "[Validate] TP Loss Across Timepoints: [0.87619627 1.28365517]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26455557 0.60272431]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02489814937871415, TP Loss: 0.6462460446637124, MAE of Mem Caps Loss: 0.1567035528358426\n",
      "[Validate] MAE Loss Across Timepoints: [0.03626057 0.03966486]\n",
      "[Validate] TP Loss Across Timepoints: [0.88036281 1.30562031]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23909738 0.60029233]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02474543258722406, TP Loss: 0.6426491325255483, MAE of Mem Caps Loss: 0.15212611307954824\n",
      "[Validate] MAE Loss Across Timepoints: [0.03606404 0.03931838]\n",
      "[Validate] TP Loss Across Timepoints: [0.87551057 1.26558137]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26763115 0.62692051]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.024621240227133967, TP Loss: 0.640815676888451, MAE of Mem Caps Loss: 0.15139262750208515\n",
      "[Validate] MAE Loss Across Timepoints: [0.0359192  0.03913765]\n",
      "[Validate] TP Loss Across Timepoints: [0.87601113 1.26521504]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26774731 0.63688387]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024517668221960776, TP Loss: 0.639054375467822, MAE of Mem Caps Loss: 0.15143468690327655\n",
      "[Validate] MAE Loss Across Timepoints: [0.035784   0.03898059]\n",
      "[Validate] TP Loss Across Timepoints: [0.87455016 1.25299037]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26922812 0.64418857]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02442900577443652, TP Loss: 0.6376577911432832, MAE of Mem Caps Loss: 0.1516661165484844\n",
      "[Validate] MAE Loss Across Timepoints: [0.03567908 0.03889591]\n",
      "[Validate] TP Loss Across Timepoints: [0.87532449 1.24809754]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26586474 0.65358808]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02435288587003015, TP Loss: 0.636834051227197, MAE of Mem Caps Loss: 0.15242182456300474\n",
      "[Validate] MAE Loss Across Timepoints: [0.03557849 0.03879534]\n",
      "[Validate] TP Loss Across Timepoints: [0.8764841  1.25380409]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.26544388 0.65035019]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.024290478293551132, TP Loss: 0.6352969624567777, MAE of Mem Caps Loss: 0.15811162189284028\n",
      "[Validate] MAE Loss Across Timepoints: [0.03551251 0.03876245]\n",
      "[Validate] TP Loss Across Timepoints: [0.87487656 1.25027931]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30770731 0.62554572]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024233521064161323, TP Loss: 0.6359970588237047, MAE of Mem Caps Loss: 0.1506715142892998\n",
      "[Validate] MAE Loss Across Timepoints: [0.03545146 0.03868574]\n",
      "[Validate] TP Loss Across Timepoints: [0.87722188 1.24780834]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.30666937 0.62575701]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.024180171894840896, TP Loss: 0.6339708515442908, MAE of Mem Caps Loss: 0.15432216018792225\n",
      "[Validate] MAE Loss Across Timepoints: [0.0353904  0.03865897]\n",
      "[Validate] TP Loss Across Timepoints: [0.87584984 1.24592018]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.27447142 0.61323593]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.024135643849149346, TP Loss: 0.6332000021357089, MAE of Mem Caps Loss: 0.1551647104768757\n",
      "[Validate] MAE Loss Across Timepoints: [0.03535084 0.03857955]\n",
      "[Validate] TP Loss Across Timepoints: [0.87822086 1.25002599]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.3107674  0.60397591]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.024103171497699805, TP Loss: 0.6331300300080329, MAE of Mem Caps Loss: 0.15065814159389884\n",
      "[Validate] MAE Loss Across Timepoints: [0.03532566 0.03850281]\n",
      "[Validate] TP Loss Across Timepoints: [0.87495595 1.22669685]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.31127904 0.6026754 ]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02406429246184416, TP Loss: 0.631909602554515, MAE of Mem Caps Loss: 0.15135057220166093\n",
      "[Validate] MAE Loss Across Timepoints: [0.03530141 0.03850177]\n",
      "[Validate] TP Loss Across Timepoints: [0.87527812 1.23111081]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.31360215 0.60720485]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.023606999500771053, TP Loss: 0.6159417757298797, MAE of Mem Caps Loss: 0.1653285436402428\n",
      "[Validate] MAE Loss Across Timepoints: [0.03435172 0.03652113]\n",
      "[Validate] TP Loss Across Timepoints: [0.85351413 1.10529959]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23841496 0.55239042]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02341121762583498, TP Loss: 0.6087473906809464, MAE of Mem Caps Loss: 0.14307029376461847\n",
      "[Validate] MAE Loss Across Timepoints: [0.03429161 0.03645523]\n",
      "[Validate] TP Loss Across Timepoints: [0.8562187  1.11056173]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.23939692 0.55040496]\n",
      "Epoch [20/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.023372006413410418, TP Loss: 0.6090615567518398, MAE of Mem Caps Loss: 0.14187208894661382\n",
      "[Validate] MAE Loss Across Timepoints: [0.03426684 0.03655614]\n",
      "[Validate] TP Loss Across Timepoints: [0.85983974 1.13774872]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.24451119 0.52904664]\n",
      "\n",
      "epochs finished with time:1819.3014245033264\n",
      "\n",
      "Current memory usage: 2621.08 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03688241 0.0375134 ]\n",
      "[Test] TP Loss Across Timepoints: [0.95847626 1.18116455]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.26133065 0.52405778]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_2.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = GNN_1(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        mae_mem_cap_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "            mem_cap_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                \n",
    "                pred, output_sig = model(data[t], X_train_res, y_train_res, X_test_res)\n",
    "                    \n",
    "                real = data[t + 1]\n",
    "    \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "                \n",
    "                # MAE between predicted graph's mem cap and actual graph's mem cap\n",
    "                predicted_mem_cap = compute_memory_capacity_vectorized(output_sig, y_test_res)\n",
    "                actual_mem_cap = torch.tensor(train_mem_cap_subjects[data_id, t + 1], requires_grad=True).to(device)\n",
    "                mem_cap_loss += mael(predicted_mem_cap, actual_mem_cap)\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total MAE between Mem Cap Loss for the current batch\n",
    "            mem_cap_loss = mem_cap_loss / (args.num_timepoints - 1)\n",
    "            \n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            mae_mem_cap_overall.append(mem_cap_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss + args.memcap_coef * mem_cap_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        mae_mem_cap_overall = np.mean(np.array(mae_mem_cap_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}, MAE of Mem Caps Loss: {mae_mem_cap_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
