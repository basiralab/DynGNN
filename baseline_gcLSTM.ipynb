{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gcLSTM import GCLSTMModel\n",
    "from memory_capacity_utils import gen_lag_data, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "#dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "#dataset = np.delete(dataset,88,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=5, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04677099737455137, TP Loss: 3.661306921392679\n",
      "[Validate] MAE Loss Across Timepoints: [0.06696117 0.06803638]\n",
      "[Validate] TP Loss Across Timepoints: [4.10382175 4.67362261]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.86400893 2.07992801]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.039179364510346204, TP Loss: 1.6579744890332222\n",
      "[Validate] MAE Loss Across Timepoints: [0.05038001 0.05493538]\n",
      "[Validate] TP Loss Across Timepoints: [1.63474607 2.31778955]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.08201098 1.68635282]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.030160663460264914, TP Loss: 0.8307209035847336\n",
      "[Validate] MAE Loss Across Timepoints: [0.03890918 0.04042028]\n",
      "[Validate] TP Loss Across Timepoints: [0.99292862 1.22154868]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06761541 1.11660334]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02606405963888392, TP Loss: 0.6347104308661073\n",
      "[Validate] MAE Loss Across Timepoints: [0.03590557 0.03678032]\n",
      "[Validate] TP Loss Across Timepoints: [0.89837521 1.11641312]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06441149 1.14934496]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.025181357326800935, TP Loss: 0.616595711093396\n",
      "[Validate] MAE Loss Across Timepoints: [0.03569919 0.03646554]\n",
      "[Validate] TP Loss Across Timepoints: [0.88730198 1.09503019]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05990008 1.12650516]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.024996679814648814, TP Loss: 0.6185450844932348\n",
      "[Validate] MAE Loss Across Timepoints: [0.03563512 0.03652127]\n",
      "[Validate] TP Loss Across Timepoints: [0.90149194 1.11862516]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05608925 1.09975814]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02484305480902549, TP Loss: 0.614716496434994\n",
      "[Validate] MAE Loss Across Timepoints: [0.03552408 0.03643003]\n",
      "[Validate] TP Loss Across Timepoints: [0.89055222 1.10270858]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05754426 1.10118883]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.024708847602596506, TP Loss: 0.6066692939493805\n",
      "[Validate] MAE Loss Across Timepoints: [0.03540645 0.03633043]\n",
      "[Validate] TP Loss Across Timepoints: [0.88170093 1.08919537]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05458192 1.09344162]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024615417409222573, TP Loss: 0.6098132815677673\n",
      "[Validate] MAE Loss Across Timepoints: [0.03532903 0.03631455]\n",
      "[Validate] TP Loss Across Timepoints: [0.88270247 1.0949738 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05398561 1.10140039]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.024482831431669183, TP Loss: 0.6017362612765282\n",
      "[Validate] MAE Loss Across Timepoints: [0.03523647 0.03625709]\n",
      "[Validate] TP Loss Across Timepoints: [0.87885576 1.09485948]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05186029 1.09254085]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.024404070907621644, TP Loss: 0.6052952641621232\n",
      "[Validate] MAE Loss Across Timepoints: [0.0351713  0.03621706]\n",
      "[Validate] TP Loss Across Timepoints: [0.87555039 1.09291399]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05945924 1.11816409]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.024293888636748306, TP Loss: 0.595619244966656\n",
      "[Validate] MAE Loss Across Timepoints: [0.03508621 0.03614893]\n",
      "[Validate] TP Loss Across Timepoints: [0.87340343 1.09033895]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05823459 1.11967369]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.024212790027377196, TP Loss: 0.5976349539123476\n",
      "[Validate] MAE Loss Across Timepoints: [0.03502913 0.03615826]\n",
      "[Validate] TP Loss Across Timepoints: [0.87016988 1.09316945]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05632017 1.14762775]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02411641538492404, TP Loss: 0.5883815276902169\n",
      "[Validate] MAE Loss Across Timepoints: [0.03493255 0.03597394]\n",
      "[Validate] TP Loss Across Timepoints: [0.85729599 1.06773508]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0570129 1.1364523]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.024085901968646795, TP Loss: 0.5860360243823379\n",
      "[Validate] MAE Loss Across Timepoints: [0.03488315 0.03592294]\n",
      "[Validate] TP Loss Across Timepoints: [0.85358012 1.06522369]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05256571 1.15005787]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.024001557772862725, TP Loss: 0.5860853635240346\n",
      "[Validate] MAE Loss Across Timepoints: [0.03484314 0.03586118]\n",
      "[Validate] TP Loss Across Timepoints: [0.84975851 1.06086552]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05387341 1.13692015]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02396068452799227, TP Loss: 0.5869686800288036\n",
      "[Validate] MAE Loss Across Timepoints: [0.03480057 0.03579108]\n",
      "[Validate] TP Loss Across Timepoints: [0.84630758 1.05387473]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05630786 1.18341965]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.023930155264679343, TP Loss: 0.5824447190389037\n",
      "[Validate] MAE Loss Across Timepoints: [0.03480034 0.03584705]\n",
      "[Validate] TP Loss Across Timepoints: [0.8546502  1.07209647]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05597828 1.17716822]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023951459195814095, TP Loss: 0.5836153974523768\n",
      "[Validate] MAE Loss Across Timepoints: [0.03476731 0.03576692]\n",
      "[Validate] TP Loss Across Timepoints: [0.84822369 1.0605675 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06553204 1.18341981]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023844464391004294, TP Loss: 0.5718653672374785\n",
      "[Validate] MAE Loss Across Timepoints: [0.03471932 0.03570604]\n",
      "[Validate] TP Loss Across Timepoints: [0.84248298 1.05092108]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06320274 1.15536183]\n",
      "\n",
      "epochs finished with time:481.92717576026917\n",
      "\n",
      "Current memory usage: 2658.81 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.0347647  0.03481355]\n",
      "[Test] TP Loss Across Timepoints: [0.88881855 0.91217642]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [1.05386811 1.10987164]\n",
      "------------------------------------Fold [2/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04546779935481027, TP Loss: 3.3247079495340586\n",
      "[Validate] MAE Loss Across Timepoints: [0.06332184 0.06491473]\n",
      "[Validate] TP Loss Across Timepoints: [3.53707004 3.88811469]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.57001253 1.98302347]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.037161633765208535, TP Loss: 1.4325302792713046\n",
      "[Validate] MAE Loss Across Timepoints: [0.0462823 0.0511132]\n",
      "[Validate] TP Loss Across Timepoints: [1.35038829 1.80562043]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.18247378 1.85997931]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02943224941554945, TP Loss: 0.7916215846780688\n",
      "[Validate] MAE Loss Across Timepoints: [0.03856215 0.04061932]\n",
      "[Validate] TP Loss Across Timepoints: [1.01931691 1.29274654]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07232357 1.11419071]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.027104205146315508, TP Loss: 0.7018425998976454\n",
      "[Validate] MAE Loss Across Timepoints: [0.03784981 0.03987689]\n",
      "[Validate] TP Loss Across Timepoints: [1.03541207 1.31509483]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07949379 1.11903831]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.026805588335264474, TP Loss: 0.6963405339047313\n",
      "[Validate] MAE Loss Across Timepoints: [0.0376189 0.0395223]\n",
      "[Validate] TP Loss Across Timepoints: [1.01420021 1.27547479]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.08025797 1.09459039]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.026594866620143875, TP Loss: 0.6887106742942706\n",
      "[Validate] MAE Loss Across Timepoints: [0.03748849 0.03949102]\n",
      "[Validate] TP Loss Across Timepoints: [1.01554513 1.27683866]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.08260942 1.08403777]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02642894853488542, TP Loss: 0.6819455773802474\n",
      "[Validate] MAE Loss Across Timepoints: [0.03738074 0.03939409]\n",
      "[Validate] TP Loss Across Timepoints: [1.02157044 1.28416359]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0828274  1.08342458]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.026323862257413566, TP Loss: 0.6854907844681293\n",
      "[Validate] MAE Loss Across Timepoints: [0.0372467  0.03923452]\n",
      "[Validate] TP Loss Across Timepoints: [1.00936842 1.26492536]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07621528 1.08630392]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.026159130415180698, TP Loss: 0.6745314440922812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03710365 0.03908427]\n",
      "[Validate] TP Loss Across Timepoints: [0.99365693 1.24163198]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06298135 1.10988197]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.026013816022896208, TP Loss: 0.669226398691535\n",
      "[Validate] MAE Loss Across Timepoints: [0.03701044 0.03898271]\n",
      "[Validate] TP Loss Across Timepoints: [0.99457103 1.24458945]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03559453 1.08486274]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.025957643942092545, TP Loss: 0.6707138873171061\n",
      "[Validate] MAE Loss Across Timepoints: [0.03696469 0.03897787]\n",
      "[Validate] TP Loss Across Timepoints: [1.00337148 1.2603898 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00713492 1.07903757]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02584619290428236, TP Loss: 0.6607519760727882\n",
      "[Validate] MAE Loss Across Timepoints: [0.03688768 0.03881317]\n",
      "[Validate] TP Loss Across Timepoints: [0.99214005 1.24105048]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99756125 1.09750859]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.025384230437339284, TP Loss: 0.6464327666908503\n",
      "[Validate] MAE Loss Across Timepoints: [0.03581033 0.03758693]\n",
      "[Validate] TP Loss Across Timepoints: [0.93462425 1.14777875]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.29355617 1.7251516 ]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02499823491962161, TP Loss: 0.6235784402815625\n",
      "[Validate] MAE Loss Across Timepoints: [0.03576127 0.03750882]\n",
      "[Validate] TP Loss Across Timepoints: [0.93426251 1.14593327]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.09910576 1.23447931]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.024933732900535688, TP Loss: 0.6214977867202833\n",
      "[Validate] MAE Loss Across Timepoints: [0.0357311  0.03743434]\n",
      "[Validate] TP Loss Across Timepoints: [0.92851543 1.13662028]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.10753822 1.26529955]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02497461039456539, TP Loss: 0.6301621060119942\n",
      "[Validate] MAE Loss Across Timepoints: [0.03569411 0.03746634]\n",
      "[Validate] TP Loss Across Timepoints: [0.92920804 1.14495647]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.12282441 1.27618537]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.024857351003447548, TP Loss: 0.6210345989093184\n",
      "[Validate] MAE Loss Across Timepoints: [0.03567309 0.03738511]\n",
      "[Validate] TP Loss Across Timepoints: [0.92432266 1.13413429]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.08122038 1.18985597]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02478178769524675, TP Loss: 0.616465492756106\n",
      "[Validate] MAE Loss Across Timepoints: [0.0356459  0.03736124]\n",
      "[Validate] TP Loss Across Timepoints: [0.92370045 1.13318884]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07100418 1.19687989]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.024821296392474324, TP Loss: 0.6179176876321435\n",
      "[Validate] MAE Loss Across Timepoints: [0.03566476 0.03741292]\n",
      "[Validate] TP Loss Across Timepoints: [0.92928714 1.14452314]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.10705478 1.20447165]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02474130512564443, TP Loss: 0.611086790682748\n",
      "[Validate] MAE Loss Across Timepoints: [0.03562411 0.03729909]\n",
      "[Validate] TP Loss Across Timepoints: [0.92154402 1.12899029]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.08039405 1.15793548]\n",
      "\n",
      "epochs finished with time:481.12403655052185\n",
      "\n",
      "Current memory usage: 2683.01 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03545955 0.03663746]\n",
      "[Test] TP Loss Across Timepoints: [0.75351644 1.05924129]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [1.04383386 1.12572524]\n",
      "------------------------------------Fold [3/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04542520295944996, TP Loss: 3.258857754059136\n",
      "[Validate] MAE Loss Across Timepoints: [0.06423778 0.06592301]\n",
      "[Validate] TP Loss Across Timepoints: [3.54092264 4.0658474 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.24809445 2.10712854]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.038167623584740795, TP Loss: 1.6167910029180348\n",
      "[Validate] MAE Loss Across Timepoints: [0.0503928  0.05449969]\n",
      "[Validate] TP Loss Across Timepoints: [1.83776212 2.51795292]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.12665671 1.64969698]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03248254362551961, TP Loss: 1.1166304433718324\n",
      "[Validate] MAE Loss Across Timepoints: [0.0459295  0.04822331]\n",
      "[Validate] TP Loss Across Timepoints: [1.54187739 2.1012032 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.1274279  1.70433316]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.029491718829376623, TP Loss: 0.8570900897029787\n",
      "[Validate] MAE Loss Across Timepoints: [0.0411229  0.04217612]\n",
      "[Validate] TP Loss Across Timepoints: [1.11543107 1.43405366]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07652425 1.12108249]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.027487842351547442, TP Loss: 0.7073769965209067\n",
      "[Validate] MAE Loss Across Timepoints: [0.04033261 0.04150803]\n",
      "[Validate] TP Loss Across Timepoints: [1.07732737 1.36834967]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00512459 1.06067423]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02726960052677896, TP Loss: 0.7030950193293393\n",
      "[Validate] MAE Loss Across Timepoints: [0.040156  0.0413461]\n",
      "[Validate] TP Loss Across Timepoints: [1.06397581 1.34957373]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94546823 1.05989053]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.0270736724633025, TP Loss: 0.6901318053714931\n",
      "[Validate] MAE Loss Across Timepoints: [0.0400493  0.04134186]\n",
      "[Validate] TP Loss Across Timepoints: [1.0821321  1.38114369]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8454506  1.07311019]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.026968427046085708, TP Loss: 0.6855748435482383\n",
      "[Validate] MAE Loss Across Timepoints: [0.0399501  0.04130423]\n",
      "[Validate] TP Loss Across Timepoints: [1.0847621  1.39364183]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77172731 1.04748429]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02682595406076871, TP Loss: 0.6706851236522198\n",
      "[Validate] MAE Loss Across Timepoints: [0.03984706 0.04116083]\n",
      "[Validate] TP Loss Across Timepoints: [1.07367671 1.37387431]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66936293 1.0346692 ]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02672491733392235, TP Loss: 0.6720387651585042\n",
      "[Validate] MAE Loss Across Timepoints: [0.03976382 0.04097443]\n",
      "[Validate] TP Loss Across Timepoints: [1.05438006 1.33450639]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65927111 1.00774724]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.02667281292087864, TP Loss: 0.6725406473269686\n",
      "[Validate] MAE Loss Across Timepoints: [0.03878355 0.04011158]\n",
      "[Validate] TP Loss Across Timepoints: [1.02106774 1.31283784]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.88649403 1.30863999]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.024282913596834987, TP Loss: 0.5858484159689397\n",
      "[Validate] MAE Loss Across Timepoints: [0.03489336 0.03620494]\n",
      "[Validate] TP Loss Across Timepoints: [0.89527464 1.15743554]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96156244 1.07230563]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02353846484038513, TP Loss: 0.5778570848051459\n",
      "[Validate] MAE Loss Across Timepoints: [0.0346826  0.03596867]\n",
      "[Validate] TP Loss Across Timepoints: [0.88801956 1.13829803]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98958386 1.07578778]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.023438211748725735, TP Loss: 0.5778659019852057\n",
      "[Validate] MAE Loss Across Timepoints: [0.03461484 0.03583784]\n",
      "[Validate] TP Loss Across Timepoints: [0.87848693 1.11856735]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98526846 1.08454579]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.023381129940389656, TP Loss: 0.579555285628885\n",
      "[Validate] MAE Loss Across Timepoints: [0.0346246  0.03587439]\n",
      "[Validate] TP Loss Across Timepoints: [0.89088988 1.13745797]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99096622 1.08801968]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02330313721904531, TP Loss: 0.5714037138968706\n",
      "[Validate] MAE Loss Across Timepoints: [0.0345869  0.03582479]\n",
      "[Validate] TP Loss Across Timepoints: [0.88954824 1.13539803]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99786372 1.10390916]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.023259408553713, TP Loss: 0.5685356548056006\n",
      "[Validate] MAE Loss Across Timepoints: [0.03455405 0.03578809]\n",
      "[Validate] TP Loss Across Timepoints: [0.88650441 1.1310041 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00462782 1.10059878]\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.02320525111281313, TP Loss: 0.5707033798098564\n",
      "[Validate] MAE Loss Across Timepoints: [0.03453543 0.03576404]\n",
      "[Validate] TP Loss Across Timepoints: [0.88757187 1.1319859 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01984783 1.09699812]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.023194420398795046, TP Loss: 0.5661744906101376\n",
      "[Validate] MAE Loss Across Timepoints: [0.03451803 0.03578267]\n",
      "[Validate] TP Loss Across Timepoints: [0.88841575 1.13621879]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0397661  1.10915617]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.023152149427914992, TP Loss: 0.5649141110479832\n",
      "[Validate] MAE Loss Across Timepoints: [0.03446662 0.03568168]\n",
      "[Validate] TP Loss Across Timepoints: [0.87983239 1.11986578]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05299652 1.12509311]\n",
      "\n",
      "epochs finished with time:471.75124287605286\n",
      "\n",
      "Current memory usage: 2697.98 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.032822   0.03529743]\n",
      "[Test] TP Loss Across Timepoints: [0.7919394  1.04249277]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.93478889 1.17053016]\n",
      "------------------------------------Fold [4/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.046422622312093154, TP Loss: 3.6573541797697544\n",
      "[Validate] MAE Loss Across Timepoints: [0.06151563 0.06405336]\n",
      "[Validate] TP Loss Across Timepoints: [3.17598915 3.83536386]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.27510546 2.0027804 ]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.03609518903249409, TP Loss: 1.2187732011079788\n",
      "[Validate] MAE Loss Across Timepoints: [0.04397039 0.04882561]\n",
      "[Validate] TP Loss Across Timepoints: [1.02165902 1.37425876]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.09078977 1.51626039]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.028597266820725054, TP Loss: 0.7205242647323757\n",
      "[Validate] MAE Loss Across Timepoints: [0.03870913 0.04030808]\n",
      "[Validate] TP Loss Across Timepoints: [0.92113405 1.15216792]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99787402 1.06112276]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.026930939275189303, TP Loss: 0.6731002861633897\n",
      "[Validate] MAE Loss Across Timepoints: [0.03729078 0.03836022]\n",
      "[Validate] TP Loss Across Timepoints: [0.87244707 1.05784619]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05733854 1.07439745]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02621279023878742, TP Loss: 0.651420802809298\n",
      "[Validate] MAE Loss Across Timepoints: [0.03710042 0.03811492]\n",
      "[Validate] TP Loss Across Timepoints: [0.87521017 1.06289566]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05242337 1.07165109]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.026060278905788437, TP Loss: 0.6528399270027876\n",
      "[Validate] MAE Loss Across Timepoints: [0.03700329 0.03795505]\n",
      "[Validate] TP Loss Across Timepoints: [0.86625588 1.04494834]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04745854 1.0654984 ]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02587830158881843, TP Loss: 0.6363013865193352\n",
      "[Validate] MAE Loss Across Timepoints: [0.03692167 0.03792849]\n",
      "[Validate] TP Loss Across Timepoints: [0.87842149 1.06451321]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04834637 1.06698612]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02574849886877928, TP Loss: 0.6327995080500841\n",
      "[Validate] MAE Loss Across Timepoints: [0.03682406 0.03776792]\n",
      "[Validate] TP Loss Across Timepoints: [0.86918062 1.04103136]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02923183 1.06572884]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.025713579714647494, TP Loss: 0.6382026476785541\n",
      "[Validate] MAE Loss Across Timepoints: [0.03674748 0.03765623]\n",
      "[Validate] TP Loss Across Timepoints: [0.86188978 1.02386665]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01685463 1.06562798]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02558081949246116, TP Loss: 0.6371999646071345\n",
      "[Validate] MAE Loss Across Timepoints: [0.03668179 0.03754973]\n",
      "[Validate] TP Loss Across Timepoints: [0.8619321  1.01686656]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0012932  1.06400101]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.025522118332446553, TP Loss: 0.6349365354981273\n",
      "[Validate] MAE Loss Across Timepoints: [0.0366313 0.0374077]\n",
      "[Validate] TP Loss Across Timepoints: [0.85378599 0.99875546]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98942116 1.07376939]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.025375116791110486, TP Loss: 0.6179840919794515\n",
      "[Validate] MAE Loss Across Timepoints: [0.03659599 0.03736722]\n",
      "[Validate] TP Loss Across Timepoints: [0.85708225 1.0013417 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94789963 1.06899343]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02535172396164853, TP Loss: 0.6221990658668801\n",
      "[Validate] MAE Loss Across Timepoints: [0.03655425 0.03727768]\n",
      "[Validate] TP Loss Across Timepoints: [0.8511647  0.98804355]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92607469 1.06050829]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.024686369390110485, TP Loss: 0.6019201606977731\n",
      "[Validate] MAE Loss Across Timepoints: [0.03360568 0.0342766 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.77889609 0.89881688]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.17787783 1.09352942]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.022956553104449995, TP Loss: 0.5755107114091516\n",
      "[Validate] MAE Loss Across Timepoints: [0.03260768 0.03332948]\n",
      "[Validate] TP Loss Across Timepoints: [0.78073239 0.91183043]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01564248 1.05045207]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.022678548528347164, TP Loss: 0.5689108343794942\n",
      "[Validate] MAE Loss Across Timepoints: [0.03253667 0.03331776]\n",
      "[Validate] TP Loss Across Timepoints: [0.78434706 0.92182118]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01416609 1.05063805]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02262013992003631, TP Loss: 0.5695659292396158\n",
      "[Validate] MAE Loss Across Timepoints: [0.03248334 0.03314089]\n",
      "[Validate] TP Loss Across Timepoints: [0.77643573 0.89903808]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01795035 1.06146489]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.022567721200175583, TP Loss: 0.5644799896981567\n",
      "[Validate] MAE Loss Across Timepoints: [0.0324674  0.03325396]\n",
      "[Validate] TP Loss Across Timepoints: [0.78179038 0.91861957]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01554552 1.04794205]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02252975395822432, TP Loss: 0.5635266862809658\n",
      "[Validate] MAE Loss Across Timepoints: [0.03244392 0.03320153]\n",
      "[Validate] TP Loss Across Timepoints: [0.7800194  0.91400552]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01729611 1.05253864]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.022530448375619017, TP Loss: 0.5693712399806827\n",
      "[Validate] MAE Loss Across Timepoints: [0.03241707 0.03310015]\n",
      "[Validate] TP Loss Across Timepoints: [0.77683026 0.90257239]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01290048 1.05679514]\n",
      "\n",
      "epochs finished with time:461.0948073863983\n",
      "\n",
      "Current memory usage: 2699.42 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03183899 0.03422553]\n",
      "[Test] TP Loss Across Timepoints: [0.75249987 0.93937807]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [1.01179265 1.09552819]\n",
      "------------------------------------Fold [5/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04383235267596319, TP Loss: 3.0049488423392177\n",
      "[Validate] MAE Loss Across Timepoints: [0.06097098 0.06395773]\n",
      "[Validate] TP Loss Across Timepoints: [3.10997581 3.61032844]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.5168585  2.10916195]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.03742139568203129, TP Loss: 1.5225883317179978\n",
      "[Validate] MAE Loss Across Timepoints: [0.0454836  0.05056439]\n",
      "[Validate] TP Loss Across Timepoints: [1.18987608 1.70852482]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99074391 1.09365501]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.028668594313785434, TP Loss: 0.7094867590349168\n",
      "[Validate] MAE Loss Across Timepoints: [0.03765082 0.04027251]\n",
      "[Validate] TP Loss Across Timepoints: [0.87721443 1.27896404]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05370422 1.0819538 ]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.025440330573474057, TP Loss: 0.6219543531769887\n",
      "[Validate] MAE Loss Across Timepoints: [0.0346586  0.03647411]\n",
      "[Validate] TP Loss Across Timepoints: [0.79595792 1.06027722]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03095634 1.12452006]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.024705890376935713, TP Loss: 0.6041791485622525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03443354 0.03641258]\n",
      "[Validate] TP Loss Across Timepoints: [0.80787843 1.08545804]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02290818 1.12831669]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02444961731089279, TP Loss: 0.5951605634763837\n",
      "[Validate] MAE Loss Across Timepoints: [0.03428371 0.03623625]\n",
      "[Validate] TP Loss Across Timepoints: [0.79576814 1.0584172 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02570556 1.14191045]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.024262270366307348, TP Loss: 0.5920110042206943\n",
      "[Validate] MAE Loss Across Timepoints: [0.03414367 0.03618566]\n",
      "[Validate] TP Loss Across Timepoints: [0.7976017  1.06375659]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01403437 1.11614744]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.024099015616229735, TP Loss: 0.5846646104473621\n",
      "[Validate] MAE Loss Across Timepoints: [0.03402381 0.0361252 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.79793638 1.0633204 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9994182  1.12831483]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.024043324185186066, TP Loss: 0.5817767279222608\n",
      "[Validate] MAE Loss Across Timepoints: [0.03392994 0.03592798]\n",
      "[Validate] TP Loss Across Timepoints: [0.78594154 1.03570509]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99009434 1.11209223]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.023949386697495356, TP Loss: 0.5862144626444206\n",
      "[Validate] MAE Loss Across Timepoints: [0.03382243 0.03596048]\n",
      "[Validate] TP Loss Across Timepoints: [0.79436272 1.05434775]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99774935 1.10072493]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.023803067233529873, TP Loss: 0.5759818066144362\n",
      "[Validate] MAE Loss Across Timepoints: [0.03377027 0.03576919]\n",
      "[Validate] TP Loss Across Timepoints: [0.78877425 1.03531528]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98861841 1.11040999]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.023778324815793894, TP Loss: 0.5841021346859634\n",
      "[Validate] MAE Loss Across Timepoints: [0.03371469 0.03569989]\n",
      "[Validate] TP Loss Across Timepoints: [0.78917754 1.03185499]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98592404 1.11536847]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.023678304758504964, TP Loss: 0.5742886152584106\n",
      "[Validate] MAE Loss Across Timepoints: [0.03368223 0.03569127]\n",
      "[Validate] TP Loss Across Timepoints: [0.79454541 1.04201233]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97183871 1.10675177]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.023672996801906265, TP Loss: 0.5768021838739514\n",
      "[Validate] MAE Loss Across Timepoints: [0.03365407 0.03561861]\n",
      "[Validate] TP Loss Across Timepoints: [0.79271948 1.03526187]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9849802  1.10798854]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.023600086497026496, TP Loss: 0.5737891481257975\n",
      "[Validate] MAE Loss Across Timepoints: [0.03363528 0.03549406]\n",
      "[Validate] TP Loss Across Timepoints: [0.7795347  1.00506699]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98374632 1.11375074]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02354192225902807, TP Loss: 0.5756833233172074\n",
      "[Validate] MAE Loss Across Timepoints: [0.03359218 0.03554462]\n",
      "[Validate] TP Loss Across Timepoints: [0.79132396 1.03007579]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.982776   1.13091912]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02352337552292738, TP Loss: 0.5710539213614538\n",
      "[Validate] MAE Loss Across Timepoints: [0.03356429 0.03548626]\n",
      "[Validate] TP Loss Across Timepoints: [0.78821349 1.02171969]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9849023  1.11081229]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02296477097843308, TP Loss: 0.5589695796370506\n",
      "[Validate] MAE Loss Across Timepoints: [0.03184994 0.03375294]\n",
      "[Validate] TP Loss Across Timepoints: [0.75374997 0.96439171]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99645969 1.13956715]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02234509623667691, TP Loss: 0.5479093843605369\n",
      "[Validate] MAE Loss Across Timepoints: [0.03174379 0.03365221]\n",
      "[Validate] TP Loss Across Timepoints: [0.75379634 0.96767569]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01147121 1.14875045]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.022317228227620944, TP Loss: 0.5451810585800558\n",
      "[Validate] MAE Loss Across Timepoints: [0.03173306 0.03364558]\n",
      "[Validate] TP Loss Across Timepoints: [0.75487787 0.97096884]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01435017 1.14462199]\n",
      "\n",
      "epochs finished with time:461.46156883239746\n",
      "\n",
      "Current memory usage: 2702.69 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03429144 0.03385571]\n",
      "[Test] TP Loss Across Timepoints: [0.88609676 0.93706112]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [1.06823332 1.1370019 ]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_2.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    # Create model instance\n",
    "    model = GCLSTMModel(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "                # print(pred)\n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
