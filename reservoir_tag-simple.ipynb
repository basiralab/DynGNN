{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.tagnet_simple import DeepTAGNet\n",
    "from memory_capacity_utils import gen_lag_data, compute_memory_capacity_vectorized, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=3, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0.001, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "dataset = np.delete(dataset,88,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_tag_oasis_t/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n",
      "TRAIN deterministic algorithms\n"
     ]
    }
   ],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data(1000, 41, args.max_lag)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data(500, 42, args.max_lag)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.051869647266964115, TP Loss: 2.7909322972098987, MAE of Mem Caps Loss: 0.3469158399047822\n",
      "[Validate] MAE Loss Across Timepoints: [0.06756175 0.0587244 ]\n",
      "[Validate] TP Loss Across Timepoints: [9.07310893 1.58566043]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59894944 1.05358912]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.042006098789473374, TP Loss: 2.1680755148331325, MAE of Mem Caps Loss: 0.26041093938888343\n",
      "[Validate] MAE Loss Across Timepoints: [0.0597182 0.0491255]\n",
      "[Validate] TP Loss Across Timepoints: [8.05749613 1.32148768]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48321863 0.67330141]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03752154273291429, TP Loss: 1.9044502516587576, MAE of Mem Caps Loss: 0.2132657896545903\n",
      "[Validate] MAE Loss Across Timepoints: [0.05650959 0.04462663]\n",
      "[Validate] TP Loss Across Timepoints: [7.67097371 1.17447637]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54892219 0.61724461]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.035472336566696565, TP Loss: 1.9481055031220118, MAE of Mem Caps Loss: 0.17146264054345814\n",
      "[Validate] MAE Loss Across Timepoints: [0.055534   0.04392744]\n",
      "[Validate] TP Loss Across Timepoints: [7.45874837 1.06627712]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61065872 0.93946696]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.033946716816474994, TP Loss: 1.8539487262566885, MAE of Mem Caps Loss: 0.16771209541102725\n",
      "[Validate] MAE Loss Across Timepoints: [0.0541335  0.04197527]\n",
      "[Validate] TP Loss Across Timepoints: [7.50545095 1.03545132]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58490507 0.83433964]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.032867351950456695, TP Loss: 1.8786891532440981, MAE of Mem Caps Loss: 0.14957739777907544\n",
      "[Validate] MAE Loss Across Timepoints: [0.05344203 0.04168954]\n",
      "[Validate] TP Loss Across Timepoints: [7.3728241  1.01585077]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57137214 0.8323543 ]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.031323545550306635, TP Loss: 1.7890291497111321, MAE of Mem Caps Loss: 0.15204171540535238\n",
      "[Validate] MAE Loss Across Timepoints: [0.05157731 0.03957789]\n",
      "[Validate] TP Loss Across Timepoints: [7.37579549 1.00483932]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59545936 0.84062495]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.030761763794968526, TP Loss: 1.8405986527601879, MAE of Mem Caps Loss: 0.14478463733672448\n",
      "[Validate] MAE Loss Across Timepoints: [0.05146769 0.04016257]\n",
      "[Validate] TP Loss Across Timepoints: [7.30677745 1.0540685 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6482905  0.86177936]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.030161612574011086, TP Loss: 1.7516392022371292, MAE of Mem Caps Loss: 0.15980008214525002\n",
      "[Validate] MAE Loss Across Timepoints: [0.05146951 0.04073429]\n",
      "[Validate] TP Loss Across Timepoints: [7.22878876 1.10089315]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64134387 0.85634831]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.029956725348408025, TP Loss: 1.749788835644722, MAE of Mem Caps Loss: 0.14801914024634158\n",
      "[Validate] MAE Loss Across Timepoints: [0.0516917  0.04226642]\n",
      "[Validate] TP Loss Across Timepoints: [7.10944722 1.2318573 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65885876 0.84381222]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.029715904655555885, TP Loss: 1.7499606020748615, MAE of Mem Caps Loss: 0.1543721794759071\n",
      "[Validate] MAE Loss Across Timepoints: [0.05142803 0.03936251]\n",
      "[Validate] TP Loss Across Timepoints: [7.32361705 1.00561727]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63763505 0.83477879]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02939083695722123, TP Loss: 1.7343421796957652, MAE of Mem Caps Loss: 0.154878250741914\n",
      "[Validate] MAE Loss Across Timepoints: [0.05123138 0.03907392]\n",
      "[Validate] TP Loss Across Timepoints: [7.32769521 0.99160646]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66233567 0.84130579]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02917902263191839, TP Loss: 1.7624302722513676, MAE of Mem Caps Loss: 0.15960524551785263\n",
      "[Validate] MAE Loss Across Timepoints: [0.05123567 0.03888066]\n",
      "[Validate] TP Loss Across Timepoints: [7.41073659 0.9889733 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63424234 0.85049353]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.029286181864639122, TP Loss: 1.7613418983916442, MAE of Mem Caps Loss: 0.1523514201494842\n",
      "[Validate] MAE Loss Across Timepoints: [0.05131962 0.04026463]\n",
      "[Validate] TP Loss Across Timepoints: [7.22705027 1.05971247]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66740749 0.8339209 ]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02925477015475432, TP Loss: 1.739000370601813, MAE of Mem Caps Loss: 0.14386732222965276\n",
      "[Validate] MAE Loss Across Timepoints: [0.05112834 0.03878307]\n",
      "[Validate] TP Loss Across Timepoints: [7.35759125 0.97966633]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65761428 0.83536677]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.0290491062682122, TP Loss: 1.7479973842700323, MAE of Mem Caps Loss: 0.14580727456937312\n",
      "[Validate] MAE Loss Across Timepoints: [0.05077585 0.03797669]\n",
      "[Validate] TP Loss Across Timepoints: [7.40687307 0.9474343 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64789235 0.83459719]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02908674708257119, TP Loss: 1.7873195255796115, MAE of Mem Caps Loss: 0.15335078050501874\n",
      "[Validate] MAE Loss Across Timepoints: [0.05102379 0.03824703]\n",
      "[Validate] TP Loss Across Timepoints: [7.44768626 0.96767985]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65335344 0.87377129]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.029007323070739707, TP Loss: 1.7354573202629884, MAE of Mem Caps Loss: 0.17003477759874355\n",
      "[Validate] MAE Loss Across Timepoints: [0.05077975 0.03834378]\n",
      "[Validate] TP Loss Across Timepoints: [7.39641622 0.96419156]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65533372 0.83763538]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02905050542516013, TP Loss: 1.7656219581762949, MAE of Mem Caps Loss: 0.15298412990252222\n",
      "[Validate] MAE Loss Across Timepoints: [0.05107778 0.03988091]\n",
      "[Validate] TP Loss Across Timepoints: [7.26079356 1.04942137]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67810801 0.8443892 ]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.029112665712212524, TP Loss: 1.785362652440866, MAE of Mem Caps Loss: 0.15544876507029273\n",
      "[Validate] MAE Loss Across Timepoints: [0.05092277 0.03843788]\n",
      "[Validate] TP Loss Across Timepoints: [7.42377828 0.96737709]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70577522 0.91200158]\n",
      "\n",
      "epochs finished with time:977.2556505203247\n",
      "\n",
      "Current memory usage: 2119.45 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03637959 0.04151104]\n",
      "[Test] TP Loss Across Timepoints: [1.050795  1.6073242]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.80499644 0.87036397]\n",
      "------------------------------------Fold [2/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.054249047425885995, TP Loss: 2.816766268014908, MAE of Mem Caps Loss: 0.5227056035816198\n",
      "[Validate] MAE Loss Across Timepoints: [0.06991274 0.07002289]\n",
      "[Validate] TP Loss Across Timepoints: [9.48010559 3.31666285]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70486835 0.74265155]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.04222860320781668, TP Loss: 1.7604740396142007, MAE of Mem Caps Loss: 0.3787095138739861\n",
      "[Validate] MAE Loss Across Timepoints: [0.05744088 0.05451663]\n",
      "[Validate] TP Loss Across Timepoints: [7.34751231 2.18223775]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.25119179 0.57751602]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.036516270413994786, TP Loss: 1.5153039361039797, MAE of Mem Caps Loss: 0.2787115665764164\n",
      "[Validate] MAE Loss Across Timepoints: [0.05152743 0.04726513]\n",
      "[Validate] TP Loss Across Timepoints: [6.85210317 1.72345022]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65888081 0.65035097]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.03332223258912563, TP Loss: 1.4246273490289847, MAE of Mem Caps Loss: 0.20171857357954445\n",
      "[Validate] MAE Loss Across Timepoints: [0.0501751  0.04585348]\n",
      "[Validate] TP Loss Across Timepoints: [6.75680847 1.59791985]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68219096 0.76392782]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.031675398194541536, TP Loss: 1.3997575148940087, MAE of Mem Caps Loss: 0.17183742217650047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.04925236 0.04544659]\n",
      "[Validate] TP Loss Across Timepoints: [6.51850789 1.47541339]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70525191 0.74941318]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.030281432314465444, TP Loss: 1.3462646630903086, MAE of Mem Caps Loss: 0.1536133036965618\n",
      "[Validate] MAE Loss Across Timepoints: [0.04853174 0.04430558]\n",
      "[Validate] TP Loss Across Timepoints: [6.65085042 1.5210804 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62381232 0.73376525]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02969870769108335, TP Loss: 1.3502998006840548, MAE of Mem Caps Loss: 0.1620227542858638\n",
      "[Validate] MAE Loss Across Timepoints: [0.04842243 0.04420375]\n",
      "[Validate] TP Loss Across Timepoints: [6.67119598 1.55056127]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65365684 0.71358729]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.028842964923630157, TP Loss: 1.2871869919200738, MAE of Mem Caps Loss: 0.14408286745279705\n",
      "[Validate] MAE Loss Across Timepoints: [0.04808362 0.04453624]\n",
      "[Validate] TP Loss Across Timepoints: [6.53359019 1.46021512]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66058871 0.73224577]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02859901829312245, TP Loss: 1.3251460914810498, MAE of Mem Caps Loss: 0.14991244653623617\n",
      "[Validate] MAE Loss Across Timepoints: [0.04719278 0.04249566]\n",
      "[Validate] TP Loss Across Timepoints: [6.7762736  1.60701892]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64415453 0.71608482]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.027838940421740215, TP Loss: 1.2594657510519027, MAE of Mem Caps Loss: 0.1454777606717209\n",
      "[Validate] MAE Loss Across Timepoints: [0.04657391 0.04208708]\n",
      "[Validate] TP Loss Across Timepoints: [6.56071269 1.48542137]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64562498 0.72987726]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.027627944573760034, TP Loss: 1.2934981890022754, MAE of Mem Caps Loss: 0.13935328676577557\n",
      "[Validate] MAE Loss Across Timepoints: [0.0466652 0.0422278]\n",
      "[Validate] TP Loss Across Timepoints: [6.62414042 1.53593419]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62305197 0.72527674]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.027385595751305423, TP Loss: 1.2507697209715842, MAE of Mem Caps Loss: 0.1316718590622622\n",
      "[Validate] MAE Loss Across Timepoints: [0.04671882 0.0425605 ]\n",
      "[Validate] TP Loss Across Timepoints: [6.52266591 1.47487106]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57766155 0.73866347]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.027324574471761783, TP Loss: 1.244197170312206, MAE of Mem Caps Loss: 0.149559908893708\n",
      "[Validate] MAE Loss Across Timepoints: [0.04690147 0.04289452]\n",
      "[Validate] TP Loss Across Timepoints: [6.51468048 1.47021942]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6063314  0.75116351]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.027268438972532748, TP Loss: 1.2673528683682282, MAE of Mem Caps Loss: 0.1429876621605496\n",
      "[Validate] MAE Loss Across Timepoints: [0.04641644 0.04209497]\n",
      "[Validate] TP Loss Across Timepoints: [6.47154032 1.40075811]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62958435 0.74636668]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.02713740955417355, TP Loss: 1.229090403020382, MAE of Mem Caps Loss: 0.1369695799444533\n",
      "[Validate] MAE Loss Across Timepoints: [0.04647664 0.04210016]\n",
      "[Validate] TP Loss Across Timepoints: [6.71307882 1.60632617]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57165828 0.73726153]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02692694210757812, TP Loss: 1.234302998582522, MAE of Mem Caps Loss: 0.14566871969122624\n",
      "[Validate] MAE Loss Across Timepoints: [0.04687097 0.04294151]\n",
      "[Validate] TP Loss Across Timepoints: [6.43303477 1.39513245]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63686339 0.77301993]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02705573020502925, TP Loss: 1.2467271365225314, MAE of Mem Caps Loss: 0.15317716935300327\n",
      "[Validate] MAE Loss Across Timepoints: [0.0464737  0.04218334]\n",
      "[Validate] TP Loss Across Timepoints: [6.54575755 1.45768445]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62124318 0.73890457]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.026748848054558037, TP Loss: 1.216828124721845, MAE of Mem Caps Loss: 0.15567133207281797\n",
      "[Validate] MAE Loss Across Timepoints: [0.04678062 0.04258112]\n",
      "[Validate] TP Loss Across Timepoints: [6.48883006 1.43842506]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61531203 0.74473971]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.0268578851595521, TP Loss: 1.2282917839785417, MAE of Mem Caps Loss: 0.13936346979837344\n",
      "[Validate] MAE Loss Across Timepoints: [0.04676066 0.04269644]\n",
      "[Validate] TP Loss Across Timepoints: [6.55165304 1.46561572]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61143222 0.74958351]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.026750301259259382, TP Loss: 1.2148469092945258, MAE of Mem Caps Loss: 0.14472207553498564\n",
      "[Validate] MAE Loss Across Timepoints: [0.04633768 0.04195691]\n",
      "[Validate] TP Loss Across Timepoints: [6.47202454 1.41208076]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60913824 0.73310234]\n",
      "\n",
      "epochs finished with time:972.3035883903503\n",
      "\n",
      "Current memory usage: 2121.70 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04194718 0.04570309]\n",
      "[Test] TP Loss Across Timepoints: [1.92489504 3.32437756]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.67485653 0.77678491]\n",
      "------------------------------------Fold [3/3]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.051422391273081305, TP Loss: 2.6659281479815644, MAE of Mem Caps Loss: 0.4470910172635059\n",
      "[Validate] MAE Loss Across Timepoints: [0.05845169 0.06540249]\n",
      "[Validate] TP Loss Across Timepoints: [3.35831022 3.85299802]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.71268028 0.82585637]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.041660736904790004, TP Loss: 2.0007946252822877, MAE of Mem Caps Loss: 0.29120376403489445\n",
      "[Validate] MAE Loss Across Timepoints: [0.04655255 0.05023665]\n",
      "[Validate] TP Loss Across Timepoints: [1.81732452 2.0348382 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79329214 1.14058768]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.03701258565609654, TP Loss: 1.8104878450433413, MAE of Mem Caps Loss: 0.20010920251048533\n",
      "[Validate] MAE Loss Across Timepoints: [0.04396636 0.04841832]\n",
      "[Validate] TP Loss Across Timepoints: [1.64879501 1.93002236]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63207404 0.74262256]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.034719107175866765, TP Loss: 1.76752467751503, MAE of Mem Caps Loss: 0.1801709739540575\n",
      "[Validate] MAE Loss Across Timepoints: [0.04156425 0.04505598]\n",
      "[Validate] TP Loss Across Timepoints: [1.43111968 1.62545097]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68725488 0.88179241]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.03272368830318252, TP Loss: 1.6636824235320091, MAE of Mem Caps Loss: 0.1806669899913856\n",
      "[Validate] MAE Loss Across Timepoints: [0.04080626 0.04451887]\n",
      "[Validate] TP Loss Across Timepoints: [1.28606713 1.47632468]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7731644  0.84334894]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.03146799427146713, TP Loss: 1.6144256979227065, MAE of Mem Caps Loss: 0.15657597461784348\n",
      "[Validate] MAE Loss Across Timepoints: [0.04016056 0.04378305]\n",
      "[Validate] TP Loss Across Timepoints: [1.38004994 1.5373745 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.72638421 0.85246316]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.030863451336820922, TP Loss: 1.6568435629208882, MAE of Mem Caps Loss: 0.1562399577363862\n",
      "[Validate] MAE Loss Across Timepoints: [0.03996479 0.04386443]\n",
      "[Validate] TP Loss Across Timepoints: [1.36094308 1.50389051]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73530532 0.86996715]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.03014656233911713, TP Loss: 1.6333648594717185, MAE of Mem Caps Loss: 0.16359147520864523\n",
      "[Validate] MAE Loss Across Timepoints: [0.03989294 0.04366809]\n",
      "[Validate] TP Loss Across Timepoints: [1.37795568 1.51366079]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74974118 0.91377451]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02970025761363407, TP Loss: 1.6141456678509711, MAE of Mem Caps Loss: 0.15387745241085965\n",
      "[Validate] MAE Loss Across Timepoints: [0.03941344 0.04291043]\n",
      "[Validate] TP Loss Across Timepoints: [1.37682641 1.52293849]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.75799575 0.88216467]\n",
      "Epoch [10/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.029347951523959637, TP Loss: 1.5542741266389688, MAE of Mem Caps Loss: 0.15442234599647026\n",
      "[Validate] MAE Loss Across Timepoints: [0.03925946 0.04315714]\n",
      "[Validate] TP Loss Across Timepoints: [1.28736341 1.41692686]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.76180198 0.82601963]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.029128542418281236, TP Loss: 1.5393408415218195, MAE of Mem Caps Loss: 0.15521880615232428\n",
      "[Validate] MAE Loss Across Timepoints: [0.03923756 0.04313397]\n",
      "[Validate] TP Loss Across Timepoints: [1.31493962 1.43334937]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7554889  0.81381496]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.029136485404645404, TP Loss: 1.5725595712661744, MAE of Mem Caps Loss: 0.15204986128241776\n",
      "[Validate] MAE Loss Across Timepoints: [0.03961353 0.04308587]\n",
      "[Validate] TP Loss Across Timepoints: [1.62611711 1.79081643]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63231879 0.79571783]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.028642309193188945, TP Loss: 1.5195537433028221, MAE of Mem Caps Loss: 0.15609035033387153\n",
      "[Validate] MAE Loss Across Timepoints: [0.03911734 0.04278917]\n",
      "[Validate] TP Loss Across Timepoints: [1.50762451 1.69030833]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66017582 0.78403807]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.028675249218940733, TP Loss: 1.5578219719231128, MAE of Mem Caps Loss: 0.15319585250422352\n",
      "[Validate] MAE Loss Across Timepoints: [0.03909511 0.04276787]\n",
      "[Validate] TP Loss Across Timepoints: [1.44862688 1.61210036]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.72836963 0.80986946]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.028555240388959645, TP Loss: 1.5273570515215398, MAE of Mem Caps Loss: 0.15619037437362707\n",
      "[Validate] MAE Loss Across Timepoints: [0.03908825 0.0427125 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.52109814 1.71205008]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64831742 0.78208469]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.028401326139767966, TP Loss: 1.5292993791401386, MAE of Mem Caps Loss: 0.14931740576683677\n",
      "[Validate] MAE Loss Across Timepoints: [0.03912837 0.04276566]\n",
      "[Validate] TP Loss Across Timepoints: [1.50679541 1.71476543]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67698689 0.78187898]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.028342295500139395, TP Loss: 1.5168928898870946, MAE of Mem Caps Loss: 0.1419811100688084\n",
      "[Validate] MAE Loss Across Timepoints: [0.03891328 0.04256755]\n",
      "[Validate] TP Loss Across Timepoints: [1.45127678 1.63586664]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7442825  0.79750305]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.028344460933779677, TP Loss: 1.5235201358795165, MAE of Mem Caps Loss: 0.15886692823454523\n",
      "[Validate] MAE Loss Across Timepoints: [0.03869377 0.04230882]\n",
      "[Validate] TP Loss Across Timepoints: [1.38785911 1.55769384]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70559839 0.80123596]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02822226860250036, TP Loss: 1.5183080203831196, MAE of Mem Caps Loss: 0.16028280837276437\n",
      "[Validate] MAE Loss Across Timepoints: [0.03859212 0.04236686]\n",
      "[Validate] TP Loss Across Timepoints: [1.29417682 1.42376602]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.75879999 0.8081044 ]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02823836843793591, TP Loss: 1.4963487508396307, MAE of Mem Caps Loss: 0.14365301591630622\n",
      "[Validate] MAE Loss Across Timepoints: [0.03883227 0.04254438]\n",
      "[Validate] TP Loss Across Timepoints: [1.42748201 1.62767649]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.71417436 0.80787798]\n",
      "\n",
      "epochs finished with time:1092.4115209579468\n",
      "\n",
      "Current memory usage: 2120.31 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04031232 0.04391793]\n",
      "[Test] TP Loss Across Timepoints: [3.50524861 3.3137271 ]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.65896748 0.77614618]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_oasis.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = DeepTAGNet(device=device, input_weights=input_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        mae_mem_cap_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "            mem_cap_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred, output_sig = model(data[t], X_train_res, y_train_res, X_test_res)\n",
    "                real = data[t + 1]\n",
    "        \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "                # MAE between predicted graph's mem cap and actual graph's mem cap\n",
    "                predicted_mem_cap = compute_memory_capacity_vectorized(output_sig, y_test_res)\n",
    "                actual_mem_cap = torch.tensor(train_mem_cap_subjects[data_id, t + 1], requires_grad=True).to(device)\n",
    "                mem_cap_loss += mael(predicted_mem_cap, actual_mem_cap)\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total MAE between Mem Cap Loss for the current batch\n",
    "            mem_cap_loss = mem_cap_loss / (args.num_timepoints - 1)\n",
    "            \n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            mae_mem_cap_overall.append(mem_cap_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss + args.memcap_coef * mem_cap_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        mae_mem_cap_overall = np.mean(np.array(mae_mem_cap_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}, MAE of Mem Caps Loss: {mae_mem_cap_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
